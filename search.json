[{"title":"基于Cmake的VsCode下的C/C++环境搭建日志","date":"2024-11-01T05:32:21.000Z","url":"/2024/11/01/About-Configure-Cmake-with-VsCode/","tags":[["Cmake","/tags/Cmake/"]],"categories":[["VsCode","/categories/VsCode/"]],"content":"单文件Debug时，调试窗口看不见变量 直接打断点，点击“Run and Debug”就会弹出 VsCode 配置环境文件配置tasks.json文件 配置launch.json文件 基于Cmake进行多文件编译首先在源文件所在工作区目录中添加一个Cmake文件叫做CmakeLists.txt 编辑完成后按快捷键：Ctrl+Shift+P，弹出下拉框搜索CMake Config 选择GCC 编译器，等待配置完成，会生成一个build文件夹 在下方终端进行命令行输入，移动到build目录，使用”cmake ..“命令，在输入”mingw32-make.exe“(该程序为你下载的C&#x2F;C++编译器自带的make程序，如我所下载的时mingw)； 命令完成后，build目录中会出现一个.exe文件 ps.调试时记得修改launch.json中的调试路径，因为.exe在build目录中 pps.如果.h文件统一放入了include目录或者一些.cpp文件放入src目录中，需要修改task.json文件引入目录路径 "},{"title":"优先队列与堆","date":"2020-02-01T02:52:00.000Z","url":"/2020/02/01/PriorityQueueAndHeap/","tags":[["Python","/tags/Python/"]],"categories":[["数据结构与算法","/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"什么是优先队列首先让我们来看一个场景 例子： 医院看病，重症患者往往优先治疗，即使他是后来者 可以看出优先队列相对于普通队列，他是根据元素的优先级进行出队的，与入队顺序无关 也许有人会说把元素进行排序也是可以实现的，道理是没错，如果我们是要选出班级中总成绩最高的同学；但对于医院这种情况，你无法预知今天会有多少个病人和其病症程度，每来一个病人你都重新排序的话就显得麻烦了 参考： 优先队列的主要操作优先队列根据优先级的排序分为，最大优先队列和最小优先队列。而优先队列主要有两大操作，即入队和出对（优先级最高的元素） 我们通常可以最基本的数组这种数据结构来实现优先队列 普通数组可直接加入元素，复杂度为$O(1)$；而出队时需要保证最大，所以需要比较全部元素，所以复杂度为$O(n)$ 有序数组当我们插入一个元素时，需要维护数组的元素顺序，时间复杂度为$O(n)$，而出队只需获取头部元素即可，复杂度为$O(1)$ 可以看出两种形式的数组作为优先队列，复杂度都无法低于$O(n)$，伟大的计算机科学家平衡了入队和出队这两个操作的时间复杂度，这种数据结构就是堆 什么是堆堆的本质其实是完全二叉树 完全二叉树的性质，父结点的值大于（或小于）其子节点，而根节点即为最大值（或最小） 并且完全二叉树可以使用数组实现而无需树结构，这样既可以利用数组元素可以快速访问的特点，又让结点和结点之间形成了“父”与“子”的结构关系。而最大优先队列我们也可称为最大堆，最小堆也是这样 关系公式： 大顶堆：arr[i] &gt;&#x3D; arr[2i+1] &amp;&amp; arr[i] &gt;&#x3D; arr[2i+2] 小顶堆：arr[i] &lt;&#x3D; arr[2i+1] &amp;&amp; arr[i] &lt;&#x3D; arr[2i+2] 父结点：parent[i&#x2F;2] ps.以上均为向下取整 排序思想入队先将元素加入数组尾端（为什么我们要在数组的末尾添加一个元素呢？可不可以在开头、中间？既然我们使用数组来实现堆，对数组添加一个元素来说，实现复杂度最低的操作就是在数组的末尾添加元素，如若不然，要让数组中一部分的元素逐个后移，因此在数组的末尾加入元素是最自然的想法），随后与父结点比较，若大于（或小于）父结点则进行交换，再对父结点进行相同操作，直到其父结点大于它或其为根结点，堆调整结束，这个过程称为“上升” 出队直接获取数组头部元素，之后调整堆： 根结点取出以后，根节点位置为空，于是我们将当前数组的最后一个元素放到 根节点的位置，这样做是因为交换和移动的次数最少；回到数组头部，先从的它的左右结点中选取最大的（或最小的），若比自身大（或小）则交换，再对交换的子节点进行相同操作，反复执行，直到子节点都大于（或小于自身）或没有子节点 堆的入队和出队充分利用的二叉树的二分特性，其复杂度都为$O(log n)$ 构建一个最大堆现在让我们来实现一个最大堆 测试数据 打印结果 现在我们就算完成了最大堆的入队和出队操作，最小堆将比较更改即可获得 优先队列的应用场景总结下来，优先队列比较适合需要动态排序的数据，如上文提到的医院随时会来患者，而患者们的症状程度各有不同的情况，就可以使用优先队列来进行排序；又或者当数据量过于庞大且要相互组合进行比较，而你只需要前第几位或后第几位时，这是也可以使用优先队列减少排序次数 如leedcode 第 719 题：找到第k小的距离对"},{"title":"树和二叉树","date":"2019-11-10T04:55:51.000Z","url":"/2019/11/10/Algorithm-TreeAndBinaryTree/","tags":[["Java","/tags/Java/"]],"categories":[["数据结构与算法","/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"树(Tree)的基本概念树是由结点或顶点和边组成的(可能是非线性的)且不存在着任何环的一种数据结构。没有结点的树称为空(null或empty)树。一棵非空的树包括一个根结点，还(很可能)有多个附加结点，所有结点构成一个多级分层结构 二叉树每个结点至多拥有两棵子树(即二叉树中不存在度大于2的结点)，并且，二叉树的子树有左右之分，其次序不能任意颠倒，二叉树具有一下性质 二叉树在i层上的结点数目最多 $2^{i - 1}$ (i &gt;&#x3D; 1) 深度为k的二叉树至多有 $2^{k} - 1$ 个结点 (k &gt;&#x3D; 1) 由以上两点可推出叶子结点（度为0）数为m，度为2的结点数为n，则m &#x3D; 1 + n 包含n个结点的二叉树的高度至少为 $\\log_2 (n + 1)$ 二叉树的遍历可根据根所在的位置顺序命名： 前序遍历：根-&gt;左子树-&gt;右子树 中序遍历：左子树-&gt;根-&gt;右子树 后序遍历：左子树-&gt;右子树-&gt;根 完美二叉树一个深度为k(&gt;&#x3D;1)且有 $2^{k} - 1$ 个结点的二叉树称为完美二叉树 完全二叉树换句话说，完全二叉树从根结点到倒数第二层满足完美二叉树，最后一层可以不完全填充，其叶子结点都靠左对齐 完全二叉树的应用：堆排序 对于完全二叉树的结点数n，我们根据从上到下、从左到右的顺序排序，从0开始，可轻松地算出它的父结点、孩子结点的位置。比如编号为i的结点： 其父结点编号为$\\frac{i - 1}{2}$ 如果$2 * i + 1 &lt; n$，其左子树的根结点编号为$2 * i + 1$，否则没有左子树 如果$2 * i + 2 &lt; n$，其左子树的根结点编号为$2 * i + 2$，否则没有左子树 完满二叉树换句话说，所有非叶子结点的度都是2（只要你有孩子，你就必然是有两个孩子） 二叉查找树二叉查找树也称为有序二叉查找树,满足二叉查找树的一般性质,是指一棵空树具有如下性质： 任意结点左子树不为空,则左子树的值均小于根结点的值 任意结点右子树不为空,则右子树的值均大于于根结点的值 任意结点的左右子树也分别是二叉查找树 没有键值相等的结点 实现：构建 增加结点递归 迭代 原理其实和递归一样，都是获取最佳结点，在该结点上进行操作。 论起性能，肯定迭代版本最佳，所以一般情况下，都是选择迭代版本进行操作数据。 查找查找比较简单 删除可以说在二叉搜索树的操作中，删除是最复杂的，要考虑的情况也相对多，在常规思路中，删除二叉搜索树的某一个结点，肯定会想到以下四种情况 要删除的结点没有左右子结点，如上图的D、E、G结点 要删除的结点只有左子结点，如B结点 要删除的结点只有右子结点，如F结点 要删除的结点既有左子结点，又有右子结点，如 A、C结点 先来分析第一种比如 删除D结点，则可以将B结点的左子结点设置为null，若删除G结点，则可将F结点的右子结点设置为null 第二种，删除B结点，则只需将A结点的左结点设置成D结点，将D结点的父结点设置成A即可。具体设置哪一边，也是看删除的结点位于父结点的哪一边 第三种，同第二种 第四种，比如要删除C结点，将F结点的父结点设置成A结点，F结点左结点设置成E结点，将A的右结点设置成F，E的父结点设置F结点(也就是将F结点替换C结点)，还有一种，直接将E结点替换C结点。那采用哪一种呢，如果删除结点为根结点，又该怎么删除？对于第四种情况，可以这样想，找到C或者A结点的后继结点，删除后继结点，且将后继结点的值设置为C或A结点的值。先来补充下后继结点的概念。一个结点在整棵树中的后继结点必满足，大于该结点值得所有结点集合中值最小的那个结点，即为后继结点，当然，也有可能不存在后继结点。但是对于第四种情况，后继结点一定存在，且一定在其右子树中，而且还满足，只有一个子结点或者没有子结点两者情况之一。具体原因可以这样想，因为后继结点要比C结点大，又因为C结点左右子节一定存在，所以一定存在右子树中的左子结点中。就比如C的后继结点是F，A的后继结点是E。 除了上述实现，在算法导论书中，提供了另外一种实现 局限性及应用：一个二叉查找树是由n个结点随机构成,所以，对于某些情况,二叉查找树会退化成一个有n个结点的线性链.如下图: 平衡二叉树（AVL树）AVL树是带有平衡条件的二叉查找树，和红黑树相比,它是严格的平衡二叉树,平衡条件必须满足(所有结点的左右子树高度差不超过1).不管我们是执行插入还是删除操作,只要不满足上面的条件,就要通过旋转来保持平衡,而旋转是非常耗时的 使用场景AVL树适合用于插入删除次数比较少，但查找多的情况，也在Windows进程地址空间管理中得到了使用，旋转的目的是为了降低树的高度，使其平衡 插入在谈及平衡二叉树的增加，先来考虑什么样的情况会打破这个平衡，假如A树已经是一颗平衡二叉树，但现在要往里面插入一个元素，有这两种结果，一、平衡未打破，这种肯定皆大欢喜，二、平衡被打破了。那一般要考虑三个问题 平衡被打破之前是什么状态？ 被打破之后又是一个什么样的状态？ 平衡被打破了，该怎么调整，使它又重新成为一个平衡二叉树呢？ 这里截取打破平衡后左子树的高度比右子树高度高2的所有可能情况(若右子树高，情况一样，这里只选取一种分析)，下面的图，只是代表着那个被打破平衡的子树(被打破平衡的点就是这个结点的左右子树高度差的绝对值大于或等于2，当然，这里只能等于2)，不代表整棵树。 这是第一种情况，其中A结点和B结点只是平衡二叉树的某一个子集合，要想打破这个平衡，那么插入的结点C必然在B的子结点上，即左右子结点 要使A结点的左右子树差的绝对值小于2，此时只需将B结点来替换A结点，A结点成为B结点的右孩子。若A结点有父结点，则A的父结点的子结点要去指向B结点，而A结点的父结点要去指向B结点，这段操作也就是右旋操作 以上代码无法应对另一种情况： 如果将C结点替换B结点位置，而B结点成为C结点的左结点，这样就成为了上一段代码的那种情况。这段B结点替换成为C结点的代码如下，这里操作也就是，先左旋后右旋 将两种情况综合一下 这是第二种情况，其中A、B、C、D、E五个结点也是该平衡树的某个子集合，同样要打破这个平衡，那么，插入的结点F必然在D结点和E结点上。 至此，打破平衡后，经过一系列操作达到平衡，由以上可知，大致有以下四种操作情况: 只需要经过一次右旋即可达到平衡 只需要经过一次左旋即可达到平衡 需先经过左旋，再经过右旋也可达到平衡 需先经过右旋，再经过左旋也可达到平衡 那问题就来了，怎么判断被打破的平衡要经历哪种操作才能达到平衡呢？ 经过了解，这四种情况，还可大致分为两大类，如下(以下的A结点就是被打破平衡的那个结点) 第一大类，A结点的左子树高度比右子树高度高2，最终需要经过右旋操作(可能需要先左后右) 第二大类，A结点的左子树高度比右子树高度低2，最终需要经过左旋操作(可能需要先右后左) 所以很容易想到，在插入结点后，判断插入的结点是在A结点的左子树还是右子树（因为插入之前已经是平衡二叉树）再决定采用哪个大类操作，在大类操作里再去细分要不要经历两步操作。 删除 红黑树红黑树(Red-Black Tree，简称R-B Tree)，它一种特殊的二叉查找树。红黑树是一棵二叉搜索树，它在每个结点增加了一个存储位记录结点的颜色，可以是RED,也可以是BLACK；通过任意一条从根到叶子简单路径上颜色的约束，红黑树保证最长路径不超过最短路径的二倍，因而近似平衡。 特性: 每个结点或者是黑色，或者是红色。 根结点是黑色。 每个叶子结点是黑色。 [注意：这里叶子结点，是指为空的叶子结点！] 如果一个结点是红色的，则它的子结点必须是黑色的 （没有连续的红结点） 从一个结点到该结点的子孙结点的所有路径上包含相同数目的黑结点。 那么为什么当满足以上性质时，就能保证最长路径不超过最短路径的二倍了呢？我们分析一下： 你的最短路径就是全黑结点，最长路径就是一个红结点一个黑结点，最后黑色结点相同时，最长路径刚好是最短路径的两倍 证明红黑树的时间复杂度为：O($\\log_2 n$) 定理：一颗含有n个结点的红黑树的高度之多为$2\\log_2 (n + 1)$ 证明： “一棵含有n个结点的红黑树的高度至多为$2\\log_2(n + 1)$” 的逆否命题是 “高度为h的红黑树，它的包含的内结点个数至少为$2^{\\frac{h}{2}} - 1$个”。我们只需要证明逆否命题，即可证明原命题为真；即只需证明 “高度为h的红黑树，它的包含的内结点个数至少为 $2^{\\frac{h}{2}} - 1$个”。 从某个结点x出发（不包括该结点）到达一个叶结点的任意一条路径上，黑色结点的个数称为该结点的黑高度(x’s black height)，记为bh(x)。关于bh(x)有两点需要说明： 第1点：根据红黑树的”特性(5) ，即从一个结点到该结点的子孙结点的所有路径上包含相同数目的黑结点“可知，从结点x出发到达的所有的叶结点具有相同数目的黑结点。这也就意味着，bh(x)的值是唯一的！ 第2点：根据红黑色的”特性(4)，即如果一个结点是红色的，则它的子结点必须是黑色的“可知，从结点x出发达到叶结点”所经历的黑结点数目”&gt;&#x3D; “所经历的红结点的数目”。假设x是根结点，则可以得出结论”bh(x) &gt;&#x3D; $\\frac{h}{2}$“。进而，我们只需证明 “高度为h的红黑树，它的包含的黑结点个数至少为 $2^{bh(x)} - 1$个”即可。 到这里，我们将需要证明的定理已经由“一棵含有n个结点的红黑树的高度至多为$2\\log_2(n + 1)$” 转变成只需要证明“高度为h的红黑树，它的包含的内结点个数至少为 $2^{bh(x)} - 1$个”。 归纳假设证明： 归纳奠基：当高度bh(x)&#x3D;0时，黑结点数n(b) &#x3D; 0 &#x3D; $2^{bh(x)}-1$ &#x3D; $2^{0}-1$，原命题成立； 归纳假设：当高度bh(x)&#x3D;k时，假设该树至少有为 $2^{bh(x)}-1$ &#x3D; $2^{k}-1$个结点； 归纳递推：当高度bh(x)&#x3D;k+1时，根结点的两棵子树的高度肯定为k(特性4)，则两棵子树上的结点个数为$2(2^{bh(x)} - 1)$ &#x3D; $2^{k+1}-2$(归纳假设),那么该树共有结点$2^{k+1}-2+1$（根结点） &#x3D; $2^{k+1}-1$个结点，原命题成立。 红黑树的基本操作是添加、删除和旋转。在对红黑树进行添加或删除后，会用到旋转方法。为什么呢？道理很简单，添加或删除红黑树中的结点之后，红黑树就发生了变化，可能不满足红黑树的5条性质，也就不再是一颗红黑树了，而是一颗普通的树。而通过旋转，可以使这颗树重新成为红黑树。简单点说，旋转的目的是让树保持红黑树的特性。 左旋与右旋的代码和AVL相同，这里就不再列出 插入第一步: 将红黑树当作一颗二叉查找树，将结点插入 红黑树本身就是一颗二叉查找树，将结点插入后，该树仍然是一颗二叉查找树。也就意味着，树的键值仍然是有序的。此外，无论是左旋还是右旋，若旋转之前这棵树是二叉查找树，旋转之后它一定还是二叉查找树。这也就意味着，任何的旋转和重新着色操作，都不会改变它仍然是一颗二叉查找树的事实。好吧？那接下来，我们就来想方设法的旋转以及重新着色，使这颗树重新成为红黑树！ 第二步：将插入的结点着色为”红色”。 为什么着色成红色，而不是黑色呢？为什么呢？将插入的结点着色为红色，不会违背”特性(5)”！少违背一条特性，就意味着我们需要处理的情况越少。接下来，就要努力的让这棵树满足其它性质即可；满足了的话，它就又是一颗红黑树了 第三步: 通过一系列的旋转或着色等操作，使之重新成为一颗红黑树。 第二步中，将插入结点着色为”红色”之后，不会违背”特性(5)”。那它到底会违背哪些特性呢？ 对于”特性(1)”，显然不会违背了。因为我们已经将它涂成红色了。 对于”特性(2)”，显然也不会违背。在第一步中，我们是将红黑树当作二叉查找树，然后执行的插入操作。而根据二叉查找树的特点，插入操作不会改变根结点。所以，根结点仍然是黑色。 对于”特性(3)”，显然不会违背了。这里的叶子结点是指的空叶子结点，插入非空结点并不会对它们造成影响。 对于”特性(4)”，是有可能违背的！ 那接下来，想办法使之”满足特性(4)”，就可以将树重新构造成红黑树了 所有插入情况如下图所示 转载自 在开始每个情景的讲解前，我们还是先来约定下 插入情景1：红黑树为空树最简单的一种情景，直接把插入结点作为根结点就行，但注意，根据红黑树性质2：根结点是黑色。还需要把插入结点设为黑色。 处理：把插入结点作为根结点，并把结点设置为黑色。 插入情景2：插入结点的val已存在插入结点的val已存在，既然红黑树总保持平衡，在插入前红黑树已经是平衡的，那么把插入结点设置为将要替代结点的颜色，再把结点的值更新就完成插入。 处理： 把I设为当前结点的颜色 更新当前结点的值为插入结点的值 插入情景3：插入结点的父结点为黑结点由于插入的结点是红色的，当插入结点的黑色时，并不会影响红黑树的平衡，直接插入即可，无需做自平衡。 处理：直接插入。 插入情景4：插入结点的父结点为红结点再次回想下红黑树的性质2：根结点是黑色。如果插入的父结点为红结点，那么该父结点不可能为根结点，所以插入结点总是存在祖父结点。这点很重要，因为后续的旋转操作肯定需要祖父结点的参与。 情景4又分为很多子情景，下面将进入重点部分 插入情景4.1：叔叔结点存在并且为红结点从红黑树性质4可以，祖父结点肯定为黑结点，因为不可以同时存在两个相连的红结点。那么此时该插入子树的红黑层数的情况是：黑红红。显然最简单的处理方式是把其改为：红黑红 处理： 将P和S设置为黑色 将PP设置为红色 把PP设置为当前插入结点 可以看到，我们把PP结点设为红色了，如果PP的父结点是黑色，那么无需再做任何处理；但如果PP的父结点是红色，根据性质4，此时红黑树已不平衡了，所以还需要把PP当作新的插入结点，继续做插入操作自平衡处理，直到平衡为止。 试想下PP刚好为根结点时，那么根据性质2，我们必须把PP重新设为黑色，那么树的红黑结构变为：黑黑红。换句话说，从根结点到叶子结点的路径中，黑色结点增加了。这也是唯一一种会增加红黑树黑色结点层数的插入情景。 我们还可以总结出另外一个经验：红黑树的生长是自底向上的。这点不同于普通的二叉查找树，普通的二叉查找树的生长是自顶向下的。 插入情景4.2：叔叔结点不存在或为黑结点，并且插入结点的父亲结点是祖父结点的左子结点单纯从插入前来看，也即不算情景4.1自底向上处理时的情况，叔叔结点非红即为叶子结点(Nil)。因为如果叔叔结点为黑结点，而父结点为红结点，那么叔叔结点所在的子树的黑色结点就比父结点所在子树的多了，这不满足红黑树的性质5。后续情景同样如此，不再多做说明了。 前文说了，需要旋转操作时，肯定一边子树的结点多了或少了，需要租或借给另一边。插入显然是多的情况，那么把多的结点租给另一边子树就可以了。 插入情景4.2.1：插入结点是其父结点的左子结点处理： 将P设为黑色 将PP设为红色 对PP进行右旋 插入情景4.2.2：插入结点是其父结点的右子结点这种情景显然可以转换为情景4.2.1 处理： 对P进行左旋 把P设置为插入结点，得到情景4.2.1 进行情景4.2.1的处理 插入情景4.3：叔叔结点不存在或为黑结点，并且插入结点的父亲结点是祖父结点的右子结点该情景对应情景4.2，只是方向反转，不做过多说明了，直接看图 插入情景4.3.1：插入结点是其父结点的右子结点处理： 将P设为黑色 将PP设为红色 对PP进行左旋 插入情景4.3.2：插入结点是其父结点的右子结点处理： 对P进行右旋 把P设置为插入结点，得到情景4.3.1 进行情景4.3.1的处理 代码 删除将红黑树内的某一个节点删除。需要执行的操作依次是：首先，将红黑树当作一颗二叉查找树，将该节点从二叉查找树中删除；然后，通过”旋转和重新着色”等一系列来修正该树，使之重新成为一棵红黑树 第一步：将红黑树当作一颗二叉查找树，将节点删除 二叉树删除结点找替代结点有3种情情景： 情景1：若删除结点无子结点，直接删除 情景2：若删除结点只有一个子结点用子结点替换删除结点 情景3：若删除结点有两个子结点，那么，先找出它的后继节点；然后把“它的后继节点的内容”复制给“该节点的内容”；之后，删除“它的后继节点”。在这里，后继节点相当于替身，在将后继节点的内容复制给”被删除节点”之后，再将后继节点删除。这样就巧妙的将问题转换为”删除后继节点”的情况了，下面就考虑后继节点。 在”被删除节点”有两个非空子节点的情况下，它的后继节点不可能是双子非空。既然”的后继节点”不可能双子都非空，就意味着”该节点的后继节点”要么没有儿子，要么只有一个儿子。若没有儿子，则按”情景1 “进行处理；若只有一个儿子，则按”情景2 “进行处理 即使简化了还是有9种情景！但跟插入操作一样，存在左右对称的情景，只是方向变了，没有本质区别。同样的，我们还是来约定下 R表示替代结点，P表示替代结点的父结点，S表示替代结点的兄弟结点，SL表示兄弟结点的左子结点，SR表示兄弟结点的右子结点。灰色结点表示它可以是红色也可以是黑色 值得特别提醒的是，R是即将被替换到删除结点的位置的替代结点，在删除前，它还在原来所在位置参与树的子平衡，平衡后再替换到删除结点的位置，才算删除完成。 情景1：替换结点是红色结点我们把替换结点换到了删除结点的位置时，由于替换结点时红色，删除也了不会影响红黑树的平衡，只要把替换结点的颜色设为删除的结点的颜色即可重新平衡。 处理：颜色变为删除结点的颜色 情景2：替换结点是黑结点当替换结点是黑色时，我们就不得不进行自平衡处理了。我们必须还得考虑替换结点是其父结点的左子结点还是右子结点，来做不同的旋转操作，使树重新平衡。 情景2.1：替换结点是其父结点的左子结点情景2.1.1：替换结点的兄弟结点是红结点若兄弟结点是红结点，那么根据性质4，兄弟结点的父结点和子结点肯定为黑色，不会有其他子情景，我们按图处理，得到删除情景2.1.2.3（后续讲解） 处理： 将S设为黑色 将P设为红色 对P进行左旋，得到情景2.1.2.3 进行情景2.1.2.3的处理 情景2.1.2：替换结点的兄弟结点是黑结点 当兄弟结点为黑时，其父结点和子结点的具体颜色也无法确定（如果也不考虑自底向上的情况，子结点非红即为叶子结点Nil，Nil结点为黑结点），此时又得考虑多种子情景。 情景2.1.2.1：替换结点的兄弟结点的右子结点是红结点，左子结点任意颜色 删除的左子树的一个黑色结点，左子树的就黑色结点少1了，然而右子树又有红色结点，那么我们直接向右子树“借”个红结点来补充黑结点就好啦，此时肯定需要用旋转处理了。 处理： 将S的颜色设为P的颜色 将P设为黑色 将SR设为黑色 对P进行左旋 前文提醒过，R是即将替换的，它还参与树的自平衡，平衡后再替换到删除结点的位置，所以R最终可以看作是删除的 情景2.1.2.2：替换结点的兄弟结点的右子结点为黑结点，左子结点为红结点 兄弟结点所在的子树有红结点，我们总是可以向兄弟子树借个红结点过来，显然该情景可以转换为情景2.1.2.1 处理： 将S设为红色 将SL设为黑色 对S进行右旋，得到情景2.1.2.1 进行情景2.1.2.1的处理 情景2.2.2.3：替换结点的兄弟结点的子结点都为黑结点 好了，此次兄弟子树都没红结点“借”了，兄弟帮忙不了，找父母呗，这种情景我们把兄弟结点设为红色，再把父结点当作替代结点，自底向上处理，去找父结点的兄弟结点去“借”。但为什么需要把兄弟结点设为红色呢？显然是为了在P所在的子树中保证平衡（R即将删除，少了一个黑色结点，子树也需要少一个），后续的平衡工作交给父辈们考虑了，还是那句，当每棵子树都保持平衡时，最终整棵总是平衡的。 处理： 将S设为红色 把P作为新的替换结点 重新进行删除结点情景处理 情景2.2：替换结点是其父结点的右子结点好啦，右边的操作也是方向相反，不做过多说明了，相信理解了删除情景2.1后，肯定可以理解2.2。 情景2.2.1：替换结点的兄弟结点是红结点 将S设为黑色 将P设为红色 对P进行右旋，得到情景2.2.2.3 进行情景2.2.2.3的处理 情景2.2.2：替换结点的兄弟结点是黑结点情景2.2.2.1：替换结点的兄弟结点的左子结点是红结点，右子结点任意颜色处理： 将S的颜色设为P的颜色 将P设为黑色 将SL设为黑色 对P进行右旋 情景2.2.2.2：替换结点的兄弟结点的左子结点为黑结点，右子结点为红结点处理： 将S设为红色 将SR设为黑色 对S进行左旋，得到情景2.2.2.1 进行情景2.2.2.1的处理 情景2.2.2.3：替换结点的兄弟结点的子结点都为黑结点处理： 将S设为红色 把P作为新的替换结点 重新进行删除结点情景处理 综上，红黑树删除后自平衡的处理可以总结为： 自己能搞定的自消化（情景1） 自己不能搞定的叫兄弟帮忙（除了情景1、情景2.1.2.3和情景2.2.2.3） 兄弟都帮忙不了的，通过父母，找远方亲戚（情景2.1.2.3和情景2.2.2.3） 代码 最后再做个习题加深理解（请不熟悉的同学务必动手画下）： 请画出图29的删除自平衡处理过程。 答： B树B树(B-Tree)是一种自平衡的树,它是一种多路搜索树（并不是二叉的），能够保证数据有序。同时它还保证了在查找、插入、删除等操作时性能都能保持在O(logn)，为大块数据的读写操作做了优化,同时它也可以用来描述外部存储(支持对保存在磁盘或者网络上的符号表进行外部查找) 一棵m阶的B 树 (m叉树)的特性如下：** 定义任意非叶子结点最多只有M个儿子；且M&gt;2 根结点的儿子数为[2, M] 除根结点以外的非叶子结点的儿子数为[M&#x2F;2, M] 每个结点存放至少M&#x2F;2-1（取上整）和至多M-1个关键字；（至少2个关键字） 非叶子结点的关键字个数&#x3D;指向儿子的指针个数-1 非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] &lt; K[i+1] 非叶子结点的指针：P[1], P[2], …, P[M]，其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树 所有叶子结点位于同一层 添加&#x2F;删除也是一样的，要考虑添加&#x2F;删除孩子后，父节点是否还满足子树 k 介于 M&#x2F;2 和 M 的条件，不满足就得从别的节点拆子树甚至修改相关子树结构来保持平衡。"},{"title":"OpenCV-核心操作","date":"2019-11-06T12:17:51.000Z","url":"/2019/11/06/OpenCV-CoreOperation/","tags":[["-Python -OpenCV","/tags/Python-OpenCV/"]],"categories":[["图像处理","/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"]],"content":"几乎所有的操作在本节主要是有关Numpy而不是OpenCV，所以掌握好Numpy有利于写好OpenCV代码 访问和操作图片像素对于BGR图片来说，它的像素组成可以用一个三维矩阵表示，行列以及三基色值，如 事实上numpy库最大优势是优化矩阵运算，所以进行简单的像素访问修改，反而会有些缓慢 对于单个像素的访问修改我们可以使用Numpy 矩阵方法：array.item()和array.itemset 图片对象属性这些属性包括行列、像素通道、图像数据类型(dtype调试时是非常重要的,因为大量的OpenCV-Python代码中的错误是由于无效的数据类型)、像素数量等，值得注意的是，正常图片shape属性会返回行列数、通道数，而灰度图片只有行列数 图片ROIROI是region of images首字母的简写，翻译为图片的区域。有时处理图片的时候只对其中的一部分图片的区域进行处理，例如我们想在图片某个区域打马赛克，为了性能考虑我们可以只让程序对这一部分信息进行处理而将其他部分忽略，这时我们就要设置图片感性趣的区域。设置完感性趣的区域后其实是指针指到了ROI区域的左上角，好像我们截取了一张小图片一样，我们只对这张小图片进行处理就可以了，因其ROI指向的还是原图只在告诉它图片的起始位置和大小变了，所以在对ROI区操作会影响原图。 分裂和合并图像通道有时你需要对图像的单通道进行操作，这种情况你可以从图片的矩阵中分割出单独通道矩阵进行操作，或者将几个单独的通道矩阵合并 制作图像边界如果你想要给图像加上相框一样的边界，可以使用 **cv.copyMakeBorder()**，这个方法还可以用作卷积和零填充等方面上，它需要如下参数： src：图片对象 top, bottom, left, right：相应方向上边界像素大小 borderType：边界类型，有一下几种 **cv.BORDER_CONSTANT**：色彩的边界。色彩值应该为下一个参数 cv.BORDER_REFLECT：边界将镜面反射边界的元素，像这样：fedcba|abcdefgh|hgfedcb cv.BORDER_REFLECT_101 or **cv.BORDER_DEFAULT*：同上，但有些不同，像：gfedcb|abcdefgh|gfedcba* cv.BORDER_REPLICATE：最后的元素将被一直复制，像这样：aaaaaa|abcdefgh|hhhhhhh cv.BORDER_WRAP： value：边界色彩 图像运算图像加法你可以使用OpenCV自带的方法 cv.add() ，也可以直接使用Numpy 的矩阵操作，但需要注意的是，OpenCV方法是一种饱和式操作（不超过255），Numpy则是一种模减运算 ps.OpenCV方法能提供更好的结果，尽量使用使用它 图像混合某种意义上来说也是一种加法，不同的是它通过给设置每张图片不同的比重，制造一种混合和透明的感觉 公式： $$g(x) &#x3D; (1 - α)f_0 + αf_1(x)$$ 主要方法：cv.addWeighted() ps.两张的尺寸要相同，否则矩阵运算会出错 逐位运算这包括与、或、非和异或操作，在对图片做提取、定义和操作非矩形ROI等操作时经常用到。接下来让我们看看怎样改变图像的特定区域。 我想在例图上添加OpenCV logo，假如使用叠加，那么OpenCV的黑色背景会覆盖例图；假如使用混合则会造成透明效果，这是可以使用逐位运算解决 上述代码中cv.cvtColor()将img2由BGR色域转为GRAY cv.threshold()设置阀值 cv.bitwise_not()进行异位操作 这样便可以在背景图与logo图中精准抠图，在相互叠加 [ 测试性能和改进技术在图像处理中，由于你需要每秒处理大量操作，所以您的代码不仅要提供正确的解决方案，还要以最快的方式进行处理 除了OpenCV，Python也提供了一个time模块帮助测试代码执行时间。而另一个模块profile有助于获得有关代码的详细报告，例如代码中每个函数占用了多少时间，函数被调用了多少次等等. 用OpenCV测量性能cv2.getTickCount()： 用于返回从操作系统启动到当前所经的计时周期数 cv.getTickFrequency()： 用于返回CPU的频率，这里的单位是秒，也就是一秒内重复的次数 所以剩下的就很清晰了：总次数&#x2F;一秒内重复的次数 &#x3D; 时间(s)1000 *总次数&#x2F;一秒内重复的次数&#x3D; 时间(ms) 我们将用下面的例子来演示。 以下示例应用中值滤波，奇数大小的内核范围为5至49. Note 也可以用时间模块做同样的事情。 使用time.time()函数，取两次的差别 OpenCV中的默认优化许多OpenCV功能都使用SSE2，AVX等进行优化。它还包含未优化的代码。 所以如果我们的系统支持这些功能，我们应该利用它们（几乎所有的现代处理器都支持它们）。 编译时默认启用。 因此，OpenCV在启用时运行优化的代码，否则它会运行未优化的代码。 你可以使用cv.useOptimized()检查是否启用&#x2F;禁用，并使用cv.setUseOptimized()启用&#x2F;禁用它。 我们来看一个简单的例子 检测IPython中的性能有时你可能需要比较两个类似操作的性能。IPython提供了一个魔术命令timeit来执行此操作。 它可以让代码运行几次以获得更准确的结果。它们也适用于测量单行代码。 例如，你想知道以下哪个加法操作更快吗？ x &#x3D; 5; y &#x3D; x ** 2x &#x3D; 5; y &#x3D; x * xx &#x3D; np.uint8（[5]）; y &#x3D; x * xy &#x3D; np.square（x）我们将在IPython shell中使用timeit得到答案。 你可以看到，x &#x3D; 5; y &#x3D; x * x是最快的，与Numpy相比快了约20倍。如果你也考虑创建阵列，它可能会快达100倍 Note Python标量操作比Numpy标量操作更快。因此对于包含一个或两个元素的操作，Python标量优于Numpy数组。当阵列的大小稍大时，Numpy会占据优势** 我们将再尝试一个例子。 这次，我们将比较同一图像的cv.countNonZero()和np.count_nonzero()的性能 性能优化技术有几种技术和编码方法可以利用Python和Numpy的最大性能。此处仅注明相关的内容，并提供重要来源的链接。这里要注意的主要是，首先尝试以简单的方式实现算法。一旦工作，对其进行分析，找到瓶颈并进行优化 尽量避免在Python中使用循环，尤其是双层&#x2F;三层嵌套循环等。它们本身就很慢 将算法&#x2F;代码尽量使用向量化操作，因为Numpy和OpenCV针对向量运算进行了优化 利用高速缓存一致性 除非需要，否则不要复制数组。尝试使用视图去替代复制数组。数组复制是一项非常浪费资源的操作 即使在完成所有这些操作之后，如果你的代码仍然很慢，或者使用大型循环是不可避免的，请使用其他库（如Cython）来加快速度"},{"title":"OpenCV-鼠标作画和滑块","date":"2019-11-05T14:11:48.000Z","url":"/2019/11/05/OpenCV-MousePaint/","tags":[["-Python -OpenCV","/tags/Python-OpenCV/"]],"categories":[["图像处理","/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"]],"content":"鼠标事件鼠标在窗口上作画的基础是鼠标事件的回调函数，鼠标事件能为我们提供坐标地址，之后我们就能做许多事情，下列代码能列出所有可用的事件 接下来，我们用鼠标双击事件画圆 更高级点的例子，根据你的决定选择画圆还是画矩形。这里用到了三个鼠标事件，鼠标移动计算坐标，左键按下开始画图，松开停止 随后将回调函数和OpenCV窗口绑定在一起 滑块在这里,我们将创建一个简单的应用程序,它显示了你指定的颜色，在OpenCV窗口中展示色彩和三基色B,G,R的滑块，通过滑动BGR的滑块引起色彩的变化，这里还用滑块做了一个开关，通过绑定回调函数起到控制的作用 用到的函数： cv.createTrackbar(trackbarName, imgName, defaultValue, maxValue, callbackFunction) cv.getTrackbarPos(trackbarName, imgName) "},{"title":"OpenCV-画几何图","date":"2019-11-04T13:30:06.000Z","url":"/2019/11/04/OpenCV-DrawingFunction/","tags":[["Python","/tags/Python/"],["OpenCV","/tags/OpenCV/"]],"categories":[["图像处理","/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"]],"content":"接下来我们要接触的函数：functions : cv.line(), cv.circle() , cv.rectangle(), cv.ellipse(), cv.putText() 等. 这些函数都有一下相同的参数： img：你想画出的形状 color：色彩维度，比如BGR，以元组形式输入，如（255,0,0） thickness：线或环得厚度，如果输入-1则是封闭图形，如圆。默认thickness为1 lineType：线性，注意不是指线型是实线、虚线还是点画线，这个参数实际用途是改变线的产生算法，默认是8通线 线需要起点和终点 长方形需要四角 圆需要圆心和半径，还可以填充颜色 椭圆需要一下参数 中心位置（x, y） 轴长（长轴，短轴） 逆时针方向椭圆旋转角 起始角度、终止角度、图色、线宽等 多边形需要各顶点坐标，我们可以把它们放入rowsx1x2维度的矩阵中，设置类型为int32 文字需要指定一下事项： 文本内容 放置坐标 字体 字号 字色，线宽，线型（lineType） 完整代码 "},{"title":"OpenCV-开始使用视频","date":"2019-11-04T11:46:13.000Z","url":"/2019/11/04/OpenCV-StartWithVideo/","tags":[["Python","/tags/Python/"],["OpenCV","/tags/OpenCV/"]],"categories":[["图像处理","/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"]],"content":"获取视频cv.VideoCapture(path&#x2F;device) device：如果想从设备中获取，则参数输入设备下标，如0（or1），更多详细信息可以看OpenCV官网 path：从文件获取，则输入文件路径 return：VideoCapture对象 VideoCapture.read()一帧帧读取，返回每帧图像frame和读取是否正确ret VideoCapture.get(propId)propId是数字0-18，分别代表video不同属性，详细参考cv::VideoCapture::get()，这里列举几个 cap.get(cv.CAP_PROP_FRAME_WIDTH)：读取video宽 cap.get(cv.CAP_PROP_FRAME_HEIGHT)：读取video高 cap.set(cv.CAP_PROP_FRAME_WIDTH,320)和cap.set(cv.CAP_PROP_FRAME_HEIGHT,240)则是设置 保存视频cv.VideoWriter(path, fourCC, …) path：保存路径，注意.后缀要和fourcc一致 fourcc：是一种独立标示视频数据流格式的四字符代码，视频播放软件通过查询 FourCC 代码并且寻找与 FourCC 代码相关联的视频解码器来播放特定的视频流 fourCC代码的传递：cv.VideoWriter_fource(‘M’,’J’,’P’,’G’)或cv.VideoWriter_fourcc(*’MJPG’)&#96; 对应MJPG. 更多fourCC细节参考fourcc.org "},{"title":"OpenCV-开始使用图片","date":"2019-11-03T14:17:56.000Z","url":"/2019/11/03/OpenCV-StartWithImage/","tags":[["Python","/tags/Python/"],["OpenCV","/tags/OpenCV/"]],"categories":[["图像处理","/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"]],"content":"Using OpenCV 读取图片cv.imread(imgPath, flag)imgPath：图片路径，字符串 flag：图片读取方式 cv.IMREAD_COLOR：加载一张彩色图片，任何透明图像会被忽略，这是默认flag cv.IMREAD_GRAYSCALE：使用灰度模式加载图片 cv.IMREAD_UNCHANGED：加载图像包括alpha通道 显示图片cv.imshow(imgName, img)imgName：你自己给张图的命名，字符串 img：cv读取到的图片，如上文的img 实际使用时，第一句只会弹出显示图片的窗口，但没有图片 输入第二句的时候才会显示图片 cv.waitKey(milliseconds)绑定键盘点击事件，在指定时间（毫秒）内可中断程序，如果你是使用ipython的shell模式实验，会发现显示图片后你是不能在控制台输入的，因为主线程在显示图片这时候就需要你点击键盘退回控制台 若未在指定时间内点击程序会自动中断；若milliseconds设置为0则是无限期等待。 cv.destroyAllWindows()中断后，虽然退回了控制台，但图片依然存在，使用该函数可以关闭所有窗口；若想关闭指定窗口可使用cv.destroyWindow(imgName). cv.namedWindow(imgName, flag)设置窗口大小 flag： cv.WINDOW_AUTOSIZE：自动适应图片大小 cv.WINDOW_NORMAL：自设置窗口大小，图片尺寸过大时增加滑动条 写入图片cv.imwrite(imgPath, img)imgPath：保存路径 img：图片对象 Using MatplotlibPython的Matplotlib库有各种各样的绘图方法，并且它能提供许多可选项 ps.OpenCV读取彩色图片时使用的是BGR模式，而matplotlib则是RGB模式，所以一些OpenCV读取的彩色图片matplotlib显示会有问题"},{"title":"素数筛法","date":"2019-10-24T12:44:27.000Z","url":"/2019/10/24/Algorithm-isPrime/","tags":[["Java","/tags/Java/"]],"categories":[["数据结构与算法","/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"在力扣碰到的题，判断一个数是否为素数，之前也做过类似的题目，这回总结一下素数筛法的知识点 素数的定义：除了1和它本身之外，不能被其他整数整除 定义法根据定义，枚举2~n-1个整数，如果不能整除n，则n为素数 优化版本：从2开始枚举到不大于sqrt(n)的所有正整数，假设n存在大于或等于sqrt(n)的因子y，则z&#x3D;n&#x2F;y必同时为n的因子，且其值小于或等于sqrt(n)，例如12 … 3 * 4 &#x3D; 12 sqrt(12) * sqrt(12) &#x3D; 12 4 * 3 &#x3D; 21 … 但如果问题升级到：给定一个正整数n，问n以内有多少个素数，该方法就力不从心了 埃氏筛埃氏筛的定义是枚举n内所有素数，并将其倍数剔除。先用2去，把2留下，其倍数剔除，2筛完后，剩余最小的数一定是素数，因为其前面小于它的数都不是它的合数，如3，不断重复下去，直到n，这个过程同时需要一个长度为n的空间记录 一些优化：内层循环 这个过程将i的倍数都标记为false，但仍然有计算亢余 如i &#x3D; 4，标记 4 * 2 &#x3D; 8时，8这个数字已经被i&#x3D; 2 的2 × 4所标记，所以我们可以从i的平方开始 欧拉筛算法思路对于每一个数（无论质数合数）x，筛掉所有小于x最小质因子的质数，再乘以x的数。比如对于77,它分解质因数是7*11，那么筛掉所有小于7的质数×77，如筛掉2×77、3× 77、5×77 算法证明没有重复筛我们假设一个合数可以分解为p1×p2×p3，并且满足p1&lt;p2&lt;p3的约束，如154，其可被筛的组合有：2和7×11、7和2×11、11和2×7，而欧拉筛只会选择小于右边因子中最小质因子的质数，所以上述组合只有2和7×11会被循环到（下面代码中 &#x2F;&#x2F;if (i%prime[j] &#x3D;&#x3D; 0) break&#x2F;&#x2F; 语句会限制质数只会取到因子的最小质因子）， "},{"title":"Spring源码分析-环境搭建","date":"2019-07-14T05:15:32.000Z","url":"/2019/07/14/Spring-building/","tags":[["SpringSourceCode","/tags/SpringSourceCode/"]],"categories":[["Spring","/categories/Spring/"]],"content":"Gradle安装先决条件：已安装Java JDK orJRE且版本为7或者以上，可通过命令$:java -version查看JDK版本。 笔者平台为Ubuntu，Windows的用户点这里 下载下载地址：点这里这里我选择的是binary-only 解压 配置环境变量 保存完成后运行命令source &#x2F;etc&#x2F;profile 使环境变量生效验证 Spring源码导入eclipseSpring源码下载github解压源码包 使用gradle将项目结构转变为eclipse工程结构进入解压包目录下，其中就有官方提供的导入手册import-into-eclipse.md接下来我们按照手册来导入 预构在解压包目录下，终端执行命令 ps.Windows的朋友在dos中执行另外项目明确说了 Eclipse需要安装 AspectJ (AspectJ Development Tools) 和 Groovy 两个插件 不然项目可能会报一些错误，BuildShip插件也需要，但是eclipse4版本好像内置此插件 导入eclipse使用eclipse 将整个文件导入 File -&gt; Import -&gt; Existing Gradle Project -&gt; 找到源码目录 点击finish 开始导入 导入成功后你会发现项目编译错误打开Build path Libraries中缺少jar包，一般缺少两个，spring-cglib-repack-3.2.2.jar和spring-objenesis-repack-2.4.jar两个包解决方法：在工程目录下（本文工程目录是直接导入spring源码解压包，且已转变eclipse工程结构）运行以下命令： 在refresh一下工程项目可以看到这两个包已经导入 另外，部分模块会出现com.sum….包无法导入，这是由于Eclipse的JRE System library中默认包含了一系列的代码访问规则，如果代码中引用了这些访问规则所禁止引用的类，就会报错，如引用了rt.jar包，可以通过添加一条允许访问JAR包中所有类的访问规则来解决 进入项目build path CoroutinesUtils 报错，找不到该类。 解决办法：直接找到spring-framework-master\\spring-core-coroutines\\build\\libs 下面的spring-core-coroutines-5.2.0.BUILD-SNAPSHOT.jar包，将这个jar包导入依赖报错项目右键 properties -&gt; java build path -&gt; add jars -&gt; 找到spring-core-coroutines-5.2.0.BUILD-SNAPSHOT.jar 位置，选择确定， project clean 一下，这个CoroutinesUtils not found 的问题就解决了"},{"title":"JVM-Class类文件结构","date":"2019-06-15T03:19:32.000Z","url":"/2019/06/15/JVM-ClassStruct/","tags":[["Java","/tags/Java/"]],"categories":[["JVM","/categories/JVM/"]],"content":"最近在看JVM的Class类文件结构的章节，书上的例子因为图片较少常常需要往上回翻看表或者16进制表，觉得很是麻烦，所以自己动手做了下实验，并截图以供对比。参考自《_深入理解Java虚拟机_JVM高级特性与最佳实践 第2版》 首先看看导图开始之前先介绍下工具，笔者用的系统是Ubuntu系统，编辑文本用的是vim，但用vim打开class文件后并不能直接看到16进制数点击Esc键输入冒号:，然后输入%!xxd，即可显示16进制 你也可以使用Java自带的工具，在JDK的bin目录中有专门用于分析Class文件字节码的工具：javap。使用javap工具的-verbose参数可以输出.class文件字节码内容 数据格式 Class文件以8位字节为基础单位的二进制流，当数据项占用8位以上空间，则会按Big-Endian方式分割成若干个8位字节进行存储。 Class文件有两种数据类型：无符号数和表。无符号数以u1、u2、u4来分别代表1个字节、2个字节4个字节等。表由多个无符号数或者其他表作为数据项构成复合数据类型，所有表以“_info”结尾。 文件结构为了解释方便，我已下面这段代码生成Class文件来进行比对 魔数与Class文件版本Class文件的头4个字节成为魔数（Magic Number），唯一的作用是确定这个文件是否为一个被虚拟机接受的Class文件，值为0xCAFEBABE紧接着魔数的4个字节存储的是Class文件的版本号。前两个字节是次版本号，后两个字节是主版本号ps.相关的Class文件版本号的16进制请自行网上查找 常量池紧接着主次版本之后的就是常量池，它是Class文件结构中与其他项目关联最多的数据类型，也是占用Class文件空间最大的数据项目之一 常量池容量计数器（constant_pool_count）u2类型，计数从1而不是0开始，第0项常量有特殊考虑，这里就不讲了。 常量池（constant_pool）主要存放两大类常量：字面量（Literal）和符号引用（Symbolic References）字面量接近Java语言的常量概念，如文本字符串、申明为final的常量值等 而符号引用则属于编译原理方面的概念，包括下面三类常量 类和接口的权限定名（Fully Qualified Name） 字段的名称和描述符（Descriptor） 方法的名称和描述符 ** Class文件不会保存各个方法、字段的最终内存布局信息，因为这些符号引用不经过运行期转换的话无法得到真正的内存入口地址，当虚拟机运行时，需要从常量池获得对应的符号引用，再在类创建时或运行时解析、翻译到具体的内存地址之中 ** 常量池中的每一项常量都是一个表，只JDK1.7开始总共有14种表，这些表共同的特点就是第一位是一个u2类型的标志位，代表当前这个常量属于哪种常量类型，这14种常量类型如下图所示 这14种常量类结构型均有自己的结构，如图我们测试的Class文件第一项常量就是CONSTANT_Class_info类型，其标志位是0x07，该类型代表类或者接口的符号引用，结构为 其另一个项name_index是一个索引值，它指向常量池中的一个CONSTANT_Utf8_info类型常量，代表这个类（或者接口）的权限定名 图中name_index为0x0002，指向了常量池第二项常量，而第二项的标志位就是0x01，表结构为 length值说明这个UTF8编码的字符串长度是多少字节，他后面紧跟着的长度为length字节的连续数据是一个使用UTF8缩略编码表示的字符串图中length值为0x000f，也就是15字节长的字符串通过比对ASCII表内容为ViewClassStruct ** 由于Class文件中方法、字段等都需要引用CONSTANT_Utf8_info型常量来描述名称，所以CONSTANT_Utf8_info型常量的最大长度也就是Java中方法、字段名的最大长度，而这也就是length的最大值，即u2类型能表达的 最大值65535，所以Java程序中不能定义超过64KB英文字符的变量或方法名 ** 后面的常量这里就不接下去讲了，大家可以比对或者用javap -verbose命令让计算机帮我们计算 访问标志常量池结束后，紧接着的两个字节代表访问标志（access_flags）,这个表示用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口；是否定义为public类型；是否定义为abstract类型；如果是类的话，是否被申明为final等，具体标志含义见图access_flags中一共有16个标志为可供使用，当前Java只用了其中8个，没有使用的标志位要求一律为0上图中，我们的测试类只是一个普通类，所以ACC_PUBLIC、ACC_SUPER标志为真 类索引、父索引与接口索引集合类索引（this_class）和父类索引（super_class）都是u2类型的数据，而接口索引集合（interfaces）是一组u2类型的数据集合，Class文件通过这三项确定这个类的继承关系，它们各自指向CONSTANT_Class_info类型的类描述符常量类索引确定这个类的权限定名，父类索引确定父类的权限定名，接口索引中的接口顺序按implements语句后的接口顺序排列我们的测试Class文件中可以看到类索引为0x0001，指向常量池中第一项常量正是这个类在常量池的位置，而其后的父类索引指向第三项因为我们的测试类没有继承别的类，其父类就是Object类 字段表集合用于描述接口或者类中声明的 变量，包括类级变量以及实例级变量，但不包括方法内部声明的局部变量，字段表格式ps.字段表集合前有一个u2类型的容器计数器fields_count记录字段表集合长度如图，当前测试类只有一个字段字段修饰符放在access_flags项目中，它与类中的access_flags项目类似，都是u2数据类型，可设置的标志位和含义见图ps。接口中字段必须有ACC_PUBLIC、ACC_STATIC、ACC_FINAL标志，因为接口中的只能有static final 类型的变量 跟随access_flags标志的是两项索引值：name_index和descriptor_index，他们都是对常量池的引用，分别代表字段的简单名称以及字段和方法的描述符 简单名称指没有类型和参数修饰的方法或者字段名称，如inc()方法和m字段的简单名称分别为“inc”和“m” 描述符描述字段的数据类型、方法的参数列表（包括数量、类型以及顺序）和返回值根据描述符规则，基本数据类型以及代表无返回值的void类型用一个大写字符来表示，如图对于数组类型，每一维度将使用一个前置的“[”字符来描述，如一个定义为“java.lang.String[][]”类型的二维数组，将被记录为：“[[Ljava&#x2F;lang&#x2F;String;”,一个整形数组“int[]”将被记录为“[I”来看看我们测试类中的字段如图access_flags为0x001a，说明ACC_PRIVATE、ACC_STATIC和ACC_FINAL三个标志为真 name_index值为0x0005，指向的常量为该字段简单名称为num descriptor_index值为0x0006，指向的常量为该字段数据类型为Integer attributes_count值为0x0001，即只有一个属性表而紧接其后的attribute_info，其结构为（该表为规则结构，根据不同的属性，会在info出细分）让我们回到16进制表上atrribute_name_index值为0x0007,指向的常量为该属性是一个ConStantValue，所以后面会指向一个常量 attribute_length值为0x00000002，说明属性值为接下来2个u1，即0x0008，指向的常量为 ** 字段表中不会列出从父类或接口继承而来的字段，但可能列出原本Java代码中不存在的隐式字段，如内部类中为了保持对外部类的访问性，会自动添加指向外部类实例的字段** 方法表集合方法表的结构同字段表一样，以此包括了访问标志、名称索引、描述符索引、属性表集合几项，之前也有一个u2的计数器 access_flags 看回16进制文件如图methods_count为0x0003，有三个方法表第一张表的access_flags为0x0001，即ACC_PUBLIC为真name_index为0x0009，指向的常量为该属性为Code，其结构细分为（此处因测试需要讲下Code，更多属性表将在下节讲解）** 与字段表集合相对应的，如果父类方法在自类中没有被重写，方法表集合中就不会出现来自父类的方法信息。但同样的，有可能会出现有编译器自动添加的方法，最典型的便是类构造器&lt;clinit&gt;方法和实例构造器&lt;init&gt;方法 ** 接下来再看descriptor_index为0x000a，指向常量为该方法参数列表为空，返回值为void用描述符来描述方法时，按照先参数列表，后返回值的顺序描述，参数列表按照参数的严格顺序放在一组小括号“()”之内，如void inc()描述为“()V”，方法java.lang.String.toString()描述为“()Ljava&#x2F;lang&#x2F;Sting” 属性表接着attributes_count计数为0x0001，有一张属性表，它可能是Code属性，也可能是LineNumberTable属性，这取决于表开头的attribute_name_index，它指向常量池中的名称 Code属性attribute_name_index为0x000b，指向常量attribute_length为0x0000002f，属性值占用位数为47个u1 max_stack和max_locals值均为0x0001 max_stack代表操作数栈（Operand Stacks）深度的最大值 max_locals代表了局部变量表所需的存储空间，单位为Slot，Slot是虚拟机为局部变量分配内存所使用的最小单位。对于byte、char、float、int、short、boolean、returnAddress等长度不超过32位的数据类型，每个局部变量占用1个Slot，而double和long这两种64位的数据类型则需要两个Slot来存放。方法参数（包括实例方法中的隐藏参数“this”）、显式异常处理器的参数、方法体中定义的局部变量都需要使用局部变量表来存放 code_length和code用来存储Java源程序编译后生成的字节码指令code_length代表字节码长度，code是用于存储字节码指令的一系列字节流，也叫字节码指令，每个指令都是u1类型，当虚拟机读取到code中的字节码时，会找出对应的指令，并可以知道这条指令后面是否需要跟随参数u1取值范围0x00~0xFF，一共可以表达256条指令，编码与指令的对应关系可以查询虚拟机字节码指令表 继续以测试类为例，我们现在分析的是&lt;init&gt;方法的Code属性，字节码区域所占空间（code_length）为0x0005，紧随其后的5个字节“2a b7 00 0c b1”对应的字节码指令： 2a：aload_0，将第0个Slot中为reference类型的本地变量推送到操作数栈顶 b7：invokespecial，以栈顶的reference类型数据所指向的对象作为方法接收者，调用此对象的实例构造器方法、private方法或者它的父类方法。这个方法有一个u2类型的参数说明具体调用哪一个方法，它指向常量池中的一个CONSTANT_Methodref_info类型常量，即此方法的方法符号引用 00 0c：这是invokespecial的参数，差常量池得0x000A对应的常量为实例构造函数器“&lt;init&gt;”方法的符号引用 读入B1，对应的指令为return 关于字节码指令，下次我会单独讲解 我们再回头看看javap计算的Code区域可以注意到Locals和Args_size的值为1，但方法inc()是没有参数的，并且方法体内也没有定义局部变量，那么为什么呢？不要忘了，在任何实例方法中，都可以是使用this关键字访问到此方法所属的对象，而Java编译器编译的时候把对this关键字的访问转变为对一个普通方法参数的访问，然后虚拟机调用实例方法时自动传入此参数，因此实例方法的局部变量表会预留一个Slot位存放对象实例的引用，方法参数从1开始计算，如果是静态方法，那Args_size值就是0 字节码指令之后是这个方法的显式异常处理表集合，这个不是必须的，我们测试类就没有异常表的生成 Exceptions 属性不要与上面的异常表产生混淆，Exception属性的作用是列举出方法中可能抛出的受查异常，也就是方法描述时在throws关键字后面列举的异常Exceptions属性中的number_of_exceptions项表示方法可能抛出number_of_exceptions种受查异常，每一种受查异常使用一个exception_index_table项表示，exception_index_table是一个指向常量池中CONSTANT_Class_info型常量得到索引，代表该受查异常得到类型 LineNumberTable 属性用于描述Java源码行号与字节码行号（字节码的偏移量）之间的对应关系默认生成到Class文件中，可以在Javac中分别使用-g:none或-g:lines选项来取消或要求生成这项信息，不生成最大的影响就是当抛出异常时，堆栈将不会显示出错的行号，并且调试程序时无法按照源码行来设置断点 属性表这里就介绍这些，其余表大家可以自己在网上查找"},{"title":"JDK-命令行工具","date":"2019-06-02T12:46:18.000Z","url":"/2019/06/02/JVM-LineTools/","tags":[["Java","/tags/Java/"]],"categories":[["JVM","/categories/JVM/"]],"content":" 最近在看JVM的相关书籍，在讲到JDK命令行工具时，笔者按照书上的命令运行，但得带了与书上不同的结果。倒不是说出错了，就是时过境迁，命令行还是那些，但结果参数不是名称换了，就是新加入了参数。在这里笔者再对这些JDK工具实验一下，并结合网上的参考，说明一下命令参数和查询结果的意义 参考自：《深入理解Java虚拟机 JVM高级特性与最佳实践》 系统：Ubuntu Java版本：openjdk version “1.8.0_212” 笔者介绍的这些工具主要用于监视虚拟机和故障处理的工具，我们可以在java&#x2F;bin中找到他们 这些工具大多是jdk&#x2F;lib&#x2F;tools.jar类库的一层薄包装，这要功能是在tools类库中实现的。 jps(JVM Process Status Tool)显示指定系统内所有HotSpot虚拟机进程（与操作系统进程一致） 命令格式：** jps [option] [hostid] ** option: hostid：命令对应的服务器ip，默认不加参数，代码查看本机 ps. 笔者这里启动了一个XMind的程序，没想到居然是Java写的~~ jstat(JVM Statistics Monitoring Tool)用于监视虚拟机各种运行状态信息的命令行工具，它可以显示本地或者远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据 命令格式：** jstat [option vmid [interval [s|ms] [count]]] ** vmid若是本地虚拟机VMID则与LVMID一致，若是远程虚拟机，VMID格式为：[protocol:][&#x2F;&#x2F;]lvmid[@hostname[:port]&#x2F;servername] interval查询时间间隔 [s|ms] count查询次数 option选项 | 作用– | –-class | 监视类装载、卸载数量、总空间以及类装载所耗费的时间-gc | 监视Java堆状况，包括Eden区、两个survivor区、老年区、永久代等的容量、已用空间、GC时间合计等信息-gccapacity | 监视内容与-gc基本相同，但输出主要关注Java堆各个区域使用到的最大、最小空间-gcutil | 监视内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比-gccause | 与-gcutil功能一样，但是会额外输出导致上一次GC产生的原因-gcnew | 监视新生代GC状况-gcnewcapacity | 监视内容与-gcnew基本相同，输出主要关注使用到的最大、最小空间-gcold | 监视老年代GC状况-gcoldcapacity | 监视内容与-gcold基本相同，输出主要关注使用到的最大、最小空间-gcpermcapacity | 输出永久带使用到的最大、最小空间-compiler | 输出JIT编译器编译过的方法、耗时等信息-printcompilation | 输出已经被JIT编译的方法 ps.jstat选项众多，这里只列举常用的 下面我将以上图jps命令查询到的VMID来进行实验，读者若想自己动手试试，也可使用jps先查询到一个VMID** -class：类加载统计 ** loaded：加载class的数量 Bytes：所占用空间大小 Unloaded：未加载数量 Bytes：未加载占用空间 Time：时间 ** -compiler：编译统计 ** Compiled：编译数量 Failed：失败数量 Invalid：不可用数量 Time：时间 FailedType：失败类型 FailedMethod：失败方法 ** -gc: 垃圾回收统计 ** S0C：第一个幸存区的大小 S1C：第二个幸存区的大小 S0U：第一个幸存区的使用大小 S1U：第二个幸存区的使用大小 EC：伊甸园区的大小 EU：伊甸园区的使用大小 OC：老年代大小 OU：老年代使用大小 MC：方法区大小 MU：方法区使用大小 CCSC:压缩类空间大小 CCSU:压缩类空间使用大小 YGC：年轻代垃圾回收次数 YGCT：年轻代垃圾回收消耗时间 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 ** -gccapacity：堆内存统计 ** NGCMN：新生代最小容量 NGCMX：新生代最大容量 NGC：当前新生代容量 S0C：第一个幸存区大小 S1C：第二个幸存区的大小 EC：伊甸园区的大小 OGCMN：老年代最小容量 OGCMX：老年代最大容量 OGC：当前老年代大小 OC:当前老年代大小 MCMN:最小元数据容量 MCMX：最大元数据容量 MC：当前元数据空间大小 CCSMN：最小压缩类空间大小 CCSMX：最大压缩类空间大小 CCSC：当前压缩类空间大小 YGC：年轻代gc次数 FGC：老年代GC次数 **-gcnew：新生代垃圾回收统计 ** S0C：第一个幸存区大小 S1C：第二个幸存区的大小 S0U：第一个幸存区的使用大小 S1U：第二个幸存区的使用大小 TT:对象在新生代存活的次数 MTT:对象在新生代存活的最大次数 DSS:期望的幸存区大小 EC：伊甸园区的大小 EU：伊甸园区的使用大小 YGC：年轻代垃圾回收次数 YGCT：年轻代垃圾回收消耗时间 ** gcnewcapacity：新生代内存统计 ** NGCMN：新生代最小容量 NGCMX：新生代最大容量 NGC：当前新生代容量 S0CMX：最大幸存1区大小 S0C：当前幸存1区大小 S1CMX：最大幸存2区大小 S1C：当前幸存2区大小 ECMX：最大伊甸园区大小 EC：当前伊甸园区大小 YGC：年轻代垃圾回收次数 FGC：老年代回收次数 ** -gcold：老年代垃圾回收统计 ** MC：方法区大小 MU：方法区使用大小 CCSC:压缩类空间大小 CCSU:压缩类空间使用大小 OC：老年代大小 OU：老年代使用大小 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 ** -gcoldcapacity：老年代内存统计 ** OGCMN：老年代最小容量 OGCMX：老年代最大容量 OGC：当前老年代大小 OC：老年代大小 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 ** -gcmetacapacity：元数据空间统计 ** MCMN: 最小元数据容量 MCMX：最大元数据容量 MC：当前元数据空间大小 CCSMN：最小压缩类空间大小 CCSMX：最大压缩类空间大小 CCSC：当前压缩类空间大小 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 ** -gcutil：总结垃圾回收统计 ** S0：幸存1区当前使用比例 S1：幸存2区当前使用比例 E：伊甸园区使用比例 O：老年代使用比例 M：元数据区使用比例 CCS：压缩使用比例 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 ** -printcompilation：JVM编译方法统计 ** Compiled：最近编译方法的数量 Size：最近编译方法的字节码数量 Type：最近编译方法的编译类型。 Method：方法名标识。 jinfo(Configuration Info for Java)实时查看和 调整虚拟机各项参数。使用jps命令的-v参数可以查看虚拟机启动时显式指定的参数列表，未被显式指定的只能使用jinfo 命令格式** jinfo [option] pid ** option查询的参数名称 jmap(Memory Map for Java)生成虚拟机的内存转储快照，获取dump文件。它还可以查询finaize执行队列、Java堆和永久代的详细信息，如空间使用率、当前用的是那种收集器等 命令格式** jmap [option] vmid ** option主要选项 | 作用— | —-dump | 生成Java堆转储快照。格式为：-dump:[live, ]format&#x3D;b, file&#x3D;，其中live子参数说明只dump出存活的对象，format设置文件格式，b&#x3D;binary-finalizerinfo | 显示在F-Queue中等待Finalizer线程执行finalize方法的对象-heap | 显示Java堆详细信息，如使用哪种回收器、参数配置、分代状况等-histo | 显示堆中对象统计信息，包括类、实例数量、合计容量-permstat | 以ClassLoader为统计口径显示永久代内存状态-F | 当虚拟机进程对-dump选项没有相应时，可使用这个选项强制生成dump快照 jhat(Java Heap Dump Browser)用于分析heapdump文件，内置了微型的HTTP&#x2F;HTML服务器，可以在浏览器查看分析结果，但一般不会使用，主要原因有二： 一般不会在部署应用程序的服务器上直接分析dump文件，这是一个耗时且消耗硬件资源的过程 jhat的分析功能相对简陋 命令格式** jhat filename ** jstack(Stack Trace for Java)用于生成当前时刻线程快照（一般称为threaddump或者javacore文件）。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等原因 命令格式** jstack [option] vmid ** option选项 | 作用— | —-F | 当正常输出的请求不被相应时，强制输出线程堆栈-l | 除堆栈外，显示关于锁的附加信息-m | 如果调用到本地方法的话，可以显示C&#x2F;C++的堆栈 HSDIS插件：JIT生成代码反汇编Java虚拟机规范详细描述了虚拟机指令集中每条指令的执行过程、执行前后对操作数栈、局部变量表的影响。这些细节描述与早期虚拟机高度吻合，但随着技术的发展，高性能虚拟机真正的细节实现方式已经渐渐与虚拟机规范内容产生越来越大差距，虚拟机规范中的描述逐渐成了虚拟机实现的“概念模型”——即实现只能保证规范描述等效。基于这个原因，我们分析程序的执行语义问题(虚拟机做了什么)时，在字节码层面上分析完全可行，但分析程序的执行行为问题(虚拟机是怎么做的、性能如何)时，在字节码层面上分析就没有意义了，需要通过其他方式解决，HSDIS插件登场了它的作用是让HotSpot的-XX:+PrintAssembly指令调用它来把动态生成的本地代码来分析问题。读者可以根据自己操作系统和CPU类型从Project Kenai的网站上下载编译好的插件，直接放在JDK_HOME&#x2F;jre&#x2F;bin&#x2F;client和JDK_HOME&#x2F;jre&#x2F;bin&#x2F;server目录中即可。"},{"title":"Hadoop-配置文件","date":"2019-04-17T01:26:36.000Z","url":"/2019/04/17/Hadoop-ConfigurationFile/","tags":[["Hadoop","/tags/Hadoop/"]],"categories":[["分布式集群","/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/"]],"content":"最近在看Hadoop，实验分布集群的时候经常要配一些配置文件，但通常对这些文件参数都是不都意思的，直接照抄教程，有种死记硬背的赶脚。网上查找了下资料，这边就总结下 etc&#x2F;hadoop&#x2F;core-site.xml顾名思义，是全局配置文件 参数 | 属性值 | 解释—— | —— | ——fs.defaultFS | NameNode URI | hdfs:&#x2F;&#x2F;host:port&#x2F;io.file.buffer.size | 131072 | SequenceFiles文件中.读写缓存size设定 ps.以上只是列出了常用的几个，完整的参数解释看这里，后面的配置文件也是如此 etc&#x2F;hadoop&#x2F;hdfs-site.xml对hdfs的局部配置###配置NameNode 参数 | 属性值 | 解释—— | —— | ——dfs.namenode.name.dir | 在本地文件系统所在的NameNode的存储空间和持续化处理日志 | 如果这是一个以逗号分隔的目录列表，然后将名称表被复制的所有目录，以备不时之需。dfs.namenode.hosts&#x2F;dfs.namenode.hosts.exclude | Datanodes permitted&#x2F;excluded列表 | 如有必要，可以使用这些文件来控制允许 数据节点的列表dfs.blocksize | 268435456 | 大型的文件系统HDFS块大小为256MBdfs.namenode.handler.count | 100 | 设置更多的namenode线程，处理从 datanode发出的大量RPC请求 配置DataNode参数 | 属性值 | 解释—— | —— | ——dfs.datanode.data.dir | 逗号分隔的一个DataNode上，它应该保存它的块的本地文件系统的路径列表 | 如果这是一个以逗号分隔的目录列表，那么数据将被存储在所有命名的目录，通常在不同的设备 完整参数看这里 etc&#x2F;hadoop&#x2F;yarn-site.xml配置yarn，yarn是一种新的 Hadoop 资源管理器，职能就是将资源调度和任务调度分开。资源管理器ResourceManager全局管理所有应用程序计算资源的分配，每一个job的ApplicationMaster负责相应任务的调度和协调。 ResourceManager做的事情是负责协调集群上计算资源的分配。调度、启动每一个 Job 所属的 ApplicationMaster、另外监控 ApplicationMaster 的存在情况。 NodeManager 功能比较专一，根据要求启动和监视集群中机器的计算容器container。负责 Container 状态的维护，并向 RM 保持心跳汇报该节点资源使用情况。 ApplicationMaster 负责一个 Job 生命周期内的所有工作。注意每一个Job都有一个 ApplicationMaster。它和MapReduce任务一样在容器中运行。AM通过与RM交互获取资源，然后然后通过与NM交互，启动计算任务。 容器是由ResourceManager进行统一管理和分配的。有两类container：一类是AM运行需要的container；另一类是AP为执行任务向RM申请的。 配置ResourceManager参数 | 属性值 | 解释—— | —— | ——yarn.resourcemanager.address | 客户端对ResourceManager主机通过 host:port 提交作业 | host:portyarn.resourcemanager.scheduler.address | ApplicationMasters 通过ResourceManager主机访问host:port跟踪调度程序获资源 | host:portyarn.resourcemanager.resource-tracker.address | NodeManagers通过ResourceManager主机访问host:port | host:portyarn.resourcemanager.admin.address | 管理命令通过ResourceManager主机访问host:port | host:portyarn.resourcemanager.webapp.address | ResourceManager web页面host:port | host:portyarn.resourcemanager.scheduler.class | ResourceManager 调度类（Scheduler class） | CapacityScheduler（推荐），FairScheduler（也推荐），orFifoScheduleryarn.scheduler.minimum-allocation-mb | 每个容器内存最低限额分配到的资源管理器要求 | 以MB为单位yarn.scheduler.maximum-allocation-mb | 资源管理器分配给每个容器的内存最大限制 | 以MB为单位yarn.resourcemanager.nodes.include-path&#x2F;yarn.resourcemanager.nodes.exclude-path | NodeManagers的permitted&#x2F;excluded列表 | 如有必要，可使用这些文件来控制允许NodeManagers列表 配置NodeManager参数 | 属性值 | 解释—— | —— | ——yarn.nodemanager.resource.memory-mb | givenNodeManager即资源的可用物理内存，以MB为单位 | 定义在节点管理器总的可用资源，以提供给运行容器yarn.nodemanager.vmem-pmem-ratio | 最大比率为一些任务的虚拟内存使用量可能会超过物理内存率 | 每个任务的虚拟内存的使用可以通过这个比例超过了物理内存的限制。虚拟内存的使用上的节点管理器任务的总量可以通过这个比率超过其物理内存的使用yarn.nodemanager.local-dirs | 数据写入本地文件系统路径的列表用逗号分隔 | 多条存储路径可以提高磁盘的读写速度yarn.nodemanager.log-dirs | 本地文件系统日志路径的列表逗号分隔 | 多条存储路径可以提高磁盘的读写速度yarn.nodemanager.log.retain-seconds | 10800 | 如果日志聚合被禁用。默认的时间（以秒为单位）保留在节点管理器只适用日志文件yarn.nodemanager.remote-app-log-dir | logs | HDFS目录下的应用程序日志移动应用上完成。需要设置相应的权限。仅适用日志聚合功能yarn.nodemanager.remote-app-log-dir-suffix | logs | 后缀追加到远程日志目录。日志将被汇总到yarn.nodemanager.remote­app­logdir&#x2F;{user}&#x2F;${thisParam} 仅适用日志聚合功能。yarn.nodemanager.aux-services | mapreduce-shuffle | Shuffle service 需要加以设置的Map Reduce的应用程序服务 完整参数看这里 etc&#x2F;hadoop&#x2F;mapred-site.xmlMapReduce的局部配置，MapReduce是一个分布式的计算框架，核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算框架，并发运行在hadoop集群上。引入MapReduce框架后，开发人员可以将绝大部分的工作集中于业务逻辑上的开发，具体的计算只需要交给框架就可以。 配置mapreduce参数 | 属性值 | 解释—— | —— | ——mapreduce.framework.name | yarn | 执行框架设置为 Hadoop YARN.mapreduce.map.memory.mb | 1536 | 对maps更大的资源限制的.mapreduce.map.java.opts | -Xmx2014M | maps中对jvm child设置更大的堆大小mapreduce.reduce.memory.mb | 3072 | 设置 reduces对于较大的资源限制mapreduce.reduce.java.opts | -Xmx2560M | reduces对 jvm child设置更大的堆大小mapreduce.task.io.sort.mb | 512 | 更高的内存限制，而对数据进行排序的效率mapreduce.task.io.sort.factor |100 | 在文件排序中更多的流合并为一次mapreduce.reduce.shuffle.parallelcopies | 50 | 通过reduces从很多的map中读取较多的平行 副本 配置mapreduce的JobHistory服务器参数 | 属性值 | 解释—— | —— | ——maprecude.jobhistory.address | MapReduce JobHistory Server host:port | 默认端口号 10020mapreduce.jobhistory.webapp.address | MapReduce JobHistory Server Web UIhost:port | 默认端口号 19888mapreduce.jobhistory.intermediate-done-dir | &#x2F;mr­history&#x2F;tmp | 在历史文件被写入由MapReduce作业mapreduce.jobhistory.done-dir | &#x2F;mr­history&#x2F;done | 目录中的历史文件是由MR JobHistory Server管理 完整参数看这里"},{"title":"Hadoop-分布式模式","date":"2019-04-16T03:24:07.000Z","url":"/2019/04/16/Hadoop-Mode-PseudoDistrubuted/","tags":[["Hadoop","/tags/Hadoop/"]],"categories":[["分布式集群","/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/"]],"content":"最近参照网上的教程搭建Hadoop集群，在自己动手操作时出现了一些教程上没有出现的错误，头痛了好几天，索性得遇大神指点才找出问题所在，这里分享我的历程 以下教程参考自： Hadoop的三种运行模式（启动模式）运行的前提是Hadoop环境配置完毕，这里就不多说，想了解的看这里 单机模式（独立模式）（Local或Standalone Mode）单机模式其实很简单，没出什么问题，我这里就简单介绍下。 默认情况下，Hadoop即处于该模式，用于开发和调式。 不对配置文件进行修改。 使用本地文件系统，而不是分布式文件系统。 Hadoop不会启动NameNode、DataNode、JobTracker、TaskTracker等守护进程，Map()和Reduce()任务作为同一个进程的不同部分来执行的。 用于对MapReduce程序的逻辑进行调试，确保程序的正确。 伪分布式模式（Pseudo-Distrubuted Mode）重点来了 Hadoop的守护进程运行在本机机器，模拟一个小规模的集群 在一台主机模拟多主机。 Hadoop启动NameNode、DataNode、JobTracker、TaskTracker这些守护进程都在同一台机器上运行，是相互独立的Java进程。 在这种模式下，Hadoop使用的是分布式文件系统，各个作业也是由JobTraker服务，来管理的独立进程。在单机模式之上增加了代码调试功能，允许检查内存使用情况，HDFS输入输出，以及其他的守护进程交互。类似于完全分布式模式，因此，这种模式常用来开发测试Hadoop程序的执行是否正确。 修改3个配置文件：core-site.xml（Hadoop集群的特性，作用于全部进程及客户端）、hdfs-site.xml（配置HDFS集群的工作属性）、mapred-site.xml（配置MapReduce集群的属性） 格式化文件系统 配置文件这里我们之为实验需求而设置，具体配置文件作用，参数意义不多说，想看详细解析的，来Hadoop-配置文件这些文件都在hadoop-3.1.2&#x2F;etc&#x2F;hadoop&#x2F;中 hadoop-env.sh 改为你电脑上Java的局对路径ps.在配置文件中有提示我们怎么设置，我们一般不删除，而是选择注释它 core-site.xml 1.0.0.5是你主节点所在主机的ip，而9000为端口注意，第一个问题来了，如果你是使用云服务器做实验，碰巧用的还是阿里云，那你会在最后测试时出现9000端口拒绝服务但是通过natstat -nplt 并没有看到9000有被占用的情况。 解决：阿里云服务器有公网ip，和私网ip，两个节点之间的通信通过公网ip进行，但是开启namenode，9000要用内网ip在core-site.xml的配里应如下设定： 同理 hdfs-site.xml的配置中对于50070或9870端口也要用内网IP。ps.若你后面要更改，一定要全部重启，且重新对HDFS集群进行格式化，否则还是会拒绝连接参考自： hdfs-site.xml创建相关目录 ps.如果使用sudo启动hadoop的相关进程，这几目录的权限可以不用管。如果是使用当前的用户启动相关进程，对于opt目录，当前用户得有读写权限，对于&#x2F;data目录也需要读写权限。 mapred-site.xml如果你使用的版本没有这个文件，有一个mapred-site.xml.template文件，将该文件复制一份为mapred-site.xml yarn-site.xml 启动集群1.对HDFS集群进行格式化，HDFS集群是用来存储数据的。 2.启动HDFS集群 hadoop-daemon.sh start datanode 启动从节点ps.好像Hadoop3Hadoop-daemon命令被hdfs,yarn等取代了，3以上版本用下面的命令 3.启动YARN集群 yarn-daemon.sh start nodemanager3以上版本： 4.启动作业历史服务器 3以上版本： 5.jps命令查看是否启动成功 其实使用命令可以一起启动的 但我使用时，使用jps查看只启动了Jps和ResourceManager两项，具体原因我也不清楚，只好老老实实一条条启动 关闭合集（重启时先关闭再启动）： 6.HDFS集群的简单操作命令 如果出现9000拒绝连接，且你使用的是阿里云服务器可能是你core-site.xml设置的是外网ip，改为内网ip，使用ifconfig查看内网ip WEB监控页面HDFS：版本默认端口由50070改为9870如果拒绝访问，则可以在hdfs-site.xml中，更改开放端口的绑定IP： ps.阿里云服务器的ip需为内网ip YARN："},{"title":"Docker-Compose","date":"2019-04-13T06:15:46.000Z","url":"/2019/04/13/Docker-Compose/","tags":[["Docker","/tags/Docker/"]],"categories":[["虚拟化","/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"]],"content":"前面我们使用 Docker 的时候，定义 Dockerfile 文件，然后使用 docker build、docker run 等命令操作容器。然而微服务架构的应用系统一般包含若干个微服务，每个微服务一般都会部署多个实例，如果每个微服务都要手动启停，那么效率之低，维护量之大可想而知 使用 Docker Compose 可以轻松、高效的管理容器，它是一个用于定义和运行多容器 Docker 的应用程序工具 安装 Docker Compose安装 Docker Compose 可以通过下面命令自动下载适应版本的 Compose，并为安装脚本添加执行权限 查看安装是否成功 Docker-Compose.yml 文件详解先来看一份 docker-compose.yml 文件，不用管这是干嘛的，只是有个格式方便后文解说： 以看到一份标准配置文件应该包含 version、services、networks 三大部分，其中最关键的就是 services 和 networks 两个部分，下面先来看 services 的书写规则。 serviceimage 在 services 标签下的第二级标签是 web，这个名字是用户自己自定义，它就是服务名称。image 则是指定服务的镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。例如下面这些格式都是可以的： build服务除了可以基于指定的镜像，还可以基于一份 Dockerfile，在使用 up 启动之时执行构建任务，这个构建标签就是 build，它可以指定 Dockerfile 所在文件夹的路径。Compose 将会利用它自动构建这个镜像，然后使用这个镜像启动服务容器。 也可以是相对路径，只要上下文确定就可以读取到 Dockerfile。 设定上下文根目录，然后以该目录为准指定 Dockerfile。 注意 build 都是一个目录，如果你要指定 Dockerfile 文件需要在 build 标签的子级标签中使用 dockerfile 标签指定，如上面的例子。如果你同时指定了 image 和 build 两个标签，那么 Compose 会构建镜像并且把镜像命名为 image 后面的那个名字。 既然可以在 docker-compose.yml 中定义构建任务，那么一定少不了 arg 这个标签，就像 Dockerfile 中的 ARG 指令，它可以在构建过程中指定环境变量，但是在构建成功后取消，在 docker-compose.yml 文件中也支持这样的写法： 与 ENV 不同的是，ARG 是允许空值的。同样构建时的命令，这里都能作为标签用，如command。这样构建过程可以向它们赋值。ps.YAML 的布尔值（true, false, yes, no, on, off）必须要使用引号引起来（单引号、双引号均可），否则会当成字符串解析。 container_name前面说过 Compose 的容器名称格式是：&lt;项目名称&gt;&lt;服务名称&gt;&lt;序号&gt;虽然可以自定义项目名称、服务名称，但是如果你想完全控制容器的命名，可以使用这个标签指定： 这样容器的名字就指定为 app 了。 depends_on在使用 Compose 时，最大的好处就是少打启动命令，但是一般项目容器启动的顺序是有要求的，如果直接从上到下启动容器，必然会因为容器依赖问题而启动失败。例如在没启动数据库容器的时候启动了应用容器，这时候应用容器会因为找不到数据库而退出，为了避免这种情况我们需要加入一个标签，就是 depends_on，这个标签解决了容器的依赖、启动先后的问题。例如下面容器会先启动 redis 和 db 两个服务，最后才启动 web 服务： 先就写这些，等有空在整理，有兴趣的可以去看官方文档"},{"title":"Docker-私有仓库","date":"2019-04-13T02:29:16.000Z","url":"/2019/04/13/Docker-Registry/","tags":[["Docker","/tags/Docker/"]],"categories":[["虚拟化","/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"]],"content":"Docke官方提供了Docker Hub网站来作为一个公开的集中仓库。然而，本地访问Docker Hub速度往往很慢，并且很多时候我们需要一个本地的私有仓库只供网内使用。Docker仓库实际上提供两方面的功能，一个是镜像管理，一个是认证。前者主要由docker-registry项目来实现，通过http服务来上传下载；后者可以通过docker-index（闭源）项目或者利用现成认证方案（如nginx）实现http请求管理。 安装docker-registry 将本机&#x2F;opt&#x2F;registry挂载到容器的&#x2F;var&#x2F;lib&#x2F;registry作为存放images地址 上传镜像查看系统已有的镜像： 使用docker tag将centos镜像打个标记，建议格式：网卡IP地址:端口&#x2F;image 网卡ip地址可使用ifconfig eth0查看 使用docker push 上传标记的镜像没有成功，这是因为从docker1.3.2版本开始，使用registry时，必须使用TLS保证其安全。在&#x2F;etc&#x2F;docker&#x2F;目录下，创建daemon.json文件。在文件中写入： ps.写自己的ip，别照抄啊！！ 然后重启docker： 重新上传：主机上就可以查看到上传的镜像 配置SSL证书及nginx反向代理docker registry搭建私有CA初始化CA环境，在&#x2F;etc&#x2F;pki&#x2F;CA&#x2F;下建立证书索引数据库文件index.txt和序列号文件serial，并为证书序列号文件提供初始值。 生成密钥并保存到&#x2F;etc&#x2F;pki&#x2F;CA&#x2F;private&#x2F;cakey.pem 生成根证书 接下来会让你填写以下信息： 使系统信任根证书 额…，突然涉及CA证书，有点晕，待搞清楚CA再更 转载自："},{"title":"Docker-跨主机连接","date":"2019-04-11T02:15:35.000Z","url":"/2019/04/11/Docker-CrossHostConnection/","tags":[["Docker","/tags/Docker/"]],"categories":[["虚拟化","/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"]],"content":" 这里指的是不同宿主机之间的容器连接 Docker网桥实现跨主机容器连接docker网桥实现跨主机连接的网络拓扑图如下：在同一个docker主机中，docker容器通过虚拟网桥连接(docker0)，如果将连接容器的网桥docker0也桥接到宿主机提供的网卡上，将docker0分配的IP地址和宿主机的IP地址设置为同一个网段，就相当于将docker容器和宿主机连接到了一起，这样就可以实现跨主机的docker容器通信。 主机端，修改&#x2F;etc&#x2F;network&#x2F;interfaces 文件添加网桥 docker端，修改&#x2F;etc&#x2F;default&#x2F;docker 文件 -b：指定使用宿主机的网桥名 -b &#x3D; br0 –fixed-cidr：指定对docker容器分配的ip段 -fixed-cidr&#x3D;172.25.11.1&#x2F;24 另一台也是同样方法设置，之后随意进入一个容器ping另一台容器ip测试即可 网桥配置跨主机容器连接的优点： 配置简单，不依赖第三方软件网桥配置跨主机容器连接的缺点： 容器和主机在同一网段，划分IP需要特别小心 需要网段控制权，在生产环境中不容易实现 不容易管理，兼容性不佳 Open vSwitch实现跨主机容器连接Open vSwitch是一个高质量、多层虚拟交换机。使用Apache2.0许可协议，旨在通过编程扩展，使庞大的网络自动化（配置、管理、维护），同时还支持标准的管理接口和协议。网络拓扑如下：这张图中蓝色部分就是我们上一节介绍的虚拟网桥br0，容器通过虚拟网桥实现同主机之间的连接。而其上层黄色部分open vSwitch创建的ovs网桥obr0，ovs通过gre隧道协议接口实现跨主机的网络连接。 GRE是通用路由协议封装；隧道技术（Tunneling）是一种通过使用互联网络的基础设施在网络之间传递数据的方式。使用隧道传递的数据（或负载）可以是不同协议的数据帧或包。隧道协议将其它协议的数据帧或包重新封装然后通过隧道发送。新的帧头提供路由信息，以便通过互联网传递被封装的负载数据。 具体步骤A、B两台主机A：192.168.59.103 docker网段：192.168.1.1B：192.168.59.103 docker网段：192.168.2.4以下以A实验确认安装了Open vSwitch 1.建立网桥 2.添加gre接口 3.本机docker容器需要的网桥 4.修改docker容器网桥，编辑&#x2F;etc&#x2F;default&#x2F;docker 5.开启一个docker容器ping测试B主机的ip虽然能ping通，但其docker容器的却不能，因为不同网段需要查找路由表确定地址，故还需要将docker容器的网段 6.添加不同Docker容器网段路由在A中添加B的docker路由，B相反 使用weave实现跨主机容器连接Weave是由weaveworks公司开发的解决Docker跨主机网络的解决方案，它能够创建一个虚拟网络，用于连接多台主机上的Docker容器，这样容器就像被接入了同一个网络交换机，那些使用网络的应用程序不必去配置端口映射和链接等信息。Weave会在主机上创建一个网桥,每一个容器通过 veth pair 连接到该网桥上，同时网桥上有个 Weave router 的容器与之连接，该router会通过连接在网桥上的接口来抓取网络包(该接口工作在Promiscuous模式)。 在每一个部署Docker的主机(可能是物理机也可能是虚拟机)上都部署有一个W(即Weave router)，它本身也可以以一个容器的形式部署。Weave run的时候就可以给每个veth的容器端分配一个ip和相应的掩码。veth的网桥这端就是Weave router容器，并在Weave launch的时候分配好ip和掩码。 Weave网络是由这些weave routers组成的对等端点(peer)构成，每个对等的一端都有自己的名字，其中包括一个可读性好的名字用于表示状态和日志的输出，一个唯一标识符用于运行中相互区别，即使重启Docker主机名字也保持不变，这些名字默认是mac地址。 每个部署了Weave router的主机都需要将TCP和UDP的6783端口的防火墙设置打开，保证Weave router之间控制面流量和数据面流量的通过。控制面由weave routers之间建立的TCP连接构成，通过它进行握手和拓扑关系信息的交换通信。 这个通信可以被配置为加密通信。而数据面由Weave routers之间建立的UDP连接构成，这些连接大部分都会加密。这些连接都是全双工的，并且可以穿越防火墙。 对每一个weave网络中的容器，weave都会创建一个网桥，并且在网桥和每个容器之间创建一个veth pair，一端作为容器网卡加入到容器的网络命名空间中，并为容器网卡配置ip和相应的掩码，一端连接在网桥上，最终通过宿主机上weave router将流量转发到对端主机上。其基本过程如下： weave默认基于UDP承载容器之间的数据包，并且可以完全自定义整个集群的网络拓扑，但从性能和使用角度来看，还是有比较大的缺陷的： weave自定义容器数据包的封包解包方式，不够通用，传输效率比较低，性能上的损失也比较大。 集群配置比较负载，需要通过weave命令行来手工构建网络拓扑，在大规模集群的情况下，加重了管理员的负担。 Weave优劣势： Weave优势 支持主机间通信加密。 支持container动态加入或者剥离网络。 支持跨主机多子网通信。 Weave劣势 只能通过weave launch或者weave connect加入weave网络。 转载自："},{"title":"Docker核心-资源隔离和限制","date":"2019-04-10T01:05:51.000Z","url":"/2019/04/10/DockerCore-ResourcesIsolation/","tags":[["Docker","/tags/Docker/"]],"categories":[["虚拟化","/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"]],"content":"关于Docker实现原理，简单总结如下： 使用Namespaces实现了系统环境的隔离，Namespaces允许一个进程以及它的子进程从共享的宿主机内核资源（网络栈、进程列表、挂载点等）里获得一个仅自己可见的隔离区域，让同一个Namespace下的所有进程感知彼此变化，对外界进程一无所知，仿佛运行在一个独占的操作系统中； 使用CGroups限制这个环境的资源使用情况，比如一台16核32GB的机器上只让容器使用2核4GB。使用CGroups还可以为资源设置权重，计算使用量，操控任务（进程或线程）启停等； Namespaces命名空间（namespaces）是 Linux 为我们提供的用于分离进程树、网络接口、挂载点以及进程间通信等资源的方法。在日常使用 Linux 或者 macOS 时，我们并没有运行多个完全分离的服务器的需要，但是如果我们在服务器上启动了多个服务，这些服务其实会相互影响的，每一个服务都能看到其他服务的进程，也可以访问宿主机器上的任意文件，这是很多时候我们都不愿意看到的，我们更希望运行在同一台机器上的不同服务能做到完全隔离，就像运行在多台不同的机器上一样。在这种情况下，一旦服务器上的某一个服务被入侵，那么入侵者就能够访问当前机器上的所有服务和文件，这也是我们不想看到的，而 Docker 其实就通过 Linux 的 Namespaces 对不同的容器实现了隔离。 Linux 的命名空间机制提供了以下七种不同的命名空间，包括 CLONE_NEWCGROUP、CLONE_NEWIPC、CLONE_NEWNET、CLONE_NEWNS、CLONE_NEWPID、CLONE_NEWUSER 和 CLONE_NEWUTS，通过这七个选项我们能在创建新的进程时设置新进程应该在哪些资源上与宿主机器进行隔离。 进程进程是 Linux 以及现在操作系统中非常重要的概念，它表示一个正在执行的程序，也是在现代分时系统中的一个任务单元。在每一个 *nix 的操作系统上，我们都能够通过 ps 命令打印出当前操作系统中正在执行的进程，比如在 Ubuntu 上，使用该命令就能得到以下的结果： 当前机器上有很多的进程正在执行，在上述进程中有两个非常特殊，一个是 pid 为 1 的 &#x2F;sbin&#x2F;init 进程，另一个是 pid 为 2 的 kthreadd 进程，这两个进程都是被 Linux 中的上帝进程 idle 创建出来的，其中前者负责执行内核的一部分初始化工作和系统配置，也会创建一些类似 getty 的注册进程，而后者负责管理和调度其他的内核进程。如果我们在当前的 Linux 操作系统下运行一个新的 Docker 容器，并通过 exec 进入其内部的 bash 并打印其中的全部进程，我们会得到以下的结果：在新的容器内部执行 ps 命令打印出了非常干净的进程列表，只有包含当前 ps -ef 在内的三个进程，在宿主机器上的几十个进程都已经消失不见了。 在当前的宿主机器上，可能就存在由上述的不同进程构成的进程树： CUP限制默认情况下容器可以使用的主机 CPU 资源是不受限制的。和内存资源的使用一样，如果不对容器可以使用的 CPU 资源进行限制，一旦发生容器内程序异常使用 CPU 的情况，很可能把整个主机的 CPU 资源耗尽，从而导致更大的灾难。 限制可用的 CPU 个数在 docker 1.13 及更高的版本上，能够很容易的限制容器可以使用的主机 CPU 个数。只需要通过 –cpus 选项指定容器可以使用的 CPU 个数就可以了，并且还可以指定如 1.5 之类的小数。使用top命令可查看cup数及负载情况。 但注意，对于进程来说是没有 CPU 个数这一概念的，内核只能通过进程消耗的 CPU 时间片来统计出进程占用 CPU 的百分比，严谨起见，我们看看 docker 的官方文档中是如何解释 –cpus 选项的：Specify how much of the available CPU resources a container can use.果然，人家用的是 “how much”，不可数的！并且 –cpus 选项支持设为小数也从侧面说明了对 CPU 的计量只能是百分比。 虽然 –cpus 选项用起来很爽，但它毕竟是 1.13 才开始支持的。对于更早的版本完成同样的功能我们需要配合使用两个选项：–cpu-period 和 –cpu-quota(1.13 及之后的版本仍然支持这两个选项)。下面的命令实现相同的结果： 这样的配置选项是不是让人很傻眼呀！100000 是什么？200000 又是什么？ 它们的单位是微秒，100000 表示 100 毫秒，200000 表示 200 毫秒。它们在这里的含义是：在每 100 毫秒的时间里，运行进程使用的 CPU 时间最多为 200 毫秒(需要两个 CPU 各执行 100 毫秒)。要想彻底搞明白这两个选项的同学可以参考：CFS BandWith Control。我们要知道这两个选项才是事实的真相，但是真相往往很残忍！还好 –cpus 选项成功的解救了我们，其实它就是包装了 –cpu-period 和 –cpu-quota。 指定固定的 CPU通过 –cpus 选项我们无法让容器始终在一个或某几个 CPU 上运行，但是通过 –cpuset-cpus 选项却可以做到！这是非常有意义的，因为现在的多核系统中每个核心都有自己的缓存，如果频繁的调度进程在不同的核心上执行势必会带来缓存失效等开销。为容器设置了 –cpuset-cpus 选项，指定运行容器的 CPU编号（可指定多个），可通过top查询。 –cpuset-cpus 选项的一个缺点是必须指定 CPU 在操作系统中的编号，这对于动态调度的环境(无法预测容器会在哪些主机上运行，只能通过程序动态的检测系统中的 CPU 编号，并生成 docker run 命令)会带来一些不便。 设置使用 CPU 的权重当 CPU 资源充足时，设置 CPU 的权重是没有意义的。只有在容器争用 CPU 资源的情况下， CPU 的权重才能让不同的容器分到不同的 CPU 用量。–cpu-shares 选项用来设置 CPU 权重，它的默认值为 1024。我们可以把它设置为 2 表示很低的权重，但是设置为 0 表示使用默认值 1024。 限制容器对内存的使用为什么要限制容器对内存的使用限制容器不能过多的使用主机的内存是非常重要的。对于 linux 主机来说，一旦内核检测到没有足够的内存可以分配，就会扔出 OOME(Out Of Memmory Exception)，并开始杀死一些进程用于释放内存空间。糟糕的是任何进程都可能成为内核猎杀的对象，包括 docker daemon 和其它一些重要的程序。更危险的是如果某个支持系统运行的重要进程被干掉了，整个系统也就宕掉了！这里我们考虑一个比较常见的场景，大量的容器把主机的内存消耗殆尽，OOME 被触发后系统内核立即开始杀进程释放内存。如果内核杀死的第一个进程就是 docker daemon 会怎么样？结果是所有的容器都不工作了，这是不能接受的！ 针对这个问题，docker 尝试通过调整 docker daemon 的 OOM 优先级来进行缓解。内核在选择要杀死的进程时会对所有的进程打分，直接杀死得分最高的进程，接着是下一个。当 docker daemon 的 OOM 优先级被降低后(注意容器进程的 OOM 优先级并没有被调整)，docker daemon 进程的得分不仅会低于容器进程的得分，还会低于其它一些进程的得分。这样 docker daemon 进程就安全多了。 内存限制 docker run 命令中通过 -m 选项限制容器使用的内存上限，同时设置 memory-swap 值为 -1，它表示容器程序使用内存的受限，而可以使用的 swap 空间使用不受限制(宿主机有多少 swap 容器就可以使用多少)。 限制可用的 swap 大小强调一下 –memory-swap 是必须要与 –memory 一起使用的。正常情况下， –memory-swap 的值包含容器可用内存和可用 swap。所以 –memory&#x3D;”300m” –memory-swap&#x3D;”1g” 的含义为：容器可以使用 300M 的物理内存，并且可以使用 700M(1G -300M) 的 swap。 把 –memory-swap 设置为 0 和不设置是一样的，此时如果设置了 –memory，容器可以使用的 swap 大小为 –memory 值的两倍。 如果 –memory-swap 的值和 –memory 相同，则容器不能使用 swap。 未完待续~"},{"title":"Docker-数据卷","date":"2019-04-09T02:29:34.000Z","url":"/2019/04/09/Docker-DataVolume/","tags":[["Docker","/tags/Docker/"]],"categories":[["虚拟化","/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"]],"content":"docker的镜像是由多个只读的文件系统叠加在一起形成的。当我们在我启动一个容器的时候，docker会加载这些只读层并在这些只读层的上面(栈顶)增加一个读写层。这时如果修改正在运行的容器中已有的文件，那么这个文件将会从只读层复制到读写层。该文件的只读版本还在，只是被上面读写层的该文件的副本隐藏。当删除docker,或者重新启动时，之前的更改将会消失。在Docker中，只读层及在顶部的读写层的组合被称为Union File System（联合文件系统）。 为了很好的实现数据保存和数据共享，Docker提出了Volume这个概念，简单的说就是绕过默认的联合文件系统，而以正常的文件或者目录的形式存在于宿主机上。又被称作数据卷。 Volume 通过数据卷可以在容器之间实现共享和重用 对数据卷的修改会立马生效(非常适合作为开发环境) 对数据卷的更新,不会影响镜像 卷会一直存在,直到没有容器使用 初始化Volume在使用docker run的时候我们可以通过 -v 来创建一个数据卷并挂载到容器上，在一次run中多次使用可以挂载多个容器。 如果使用Dockerfile方式进行初始化时可以使用 VOLUME 来添加一个或者多个新的卷到由该镜像创建的任意容器。 创建一个数据卷 上面的命令的意思是，我们创建了一个名称为volume-test1的容器，将本机的8080端口映射到容器中nginx服务器的默认web访问端口80下，创建一个数据卷，并挂载到容器的&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html目录下。 这时我们就可以绕过联合文件系统，直接在主机上操作该目录了，任何在该镜像&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html下的文件都会被复制到Volume。 我们可以通过docker inspect指令找到Volume在主机上的存储位置 docker inspect指令后面的参数可以跟容器名称。通过这个命令我们可以获得容器所有的相关信息。我们需要看这一部分 这说明docker把本机的“Source”指向目录，也就是 在Linux中我们可以ls“Source”指向的路径，可以看到nginx的index.html文件。 只要将主机的目录挂载到容器的目录上，那改变就会立即生效。在Dockerfile中我们可以通过VOLUME达到相同的目的 目录作为数据卷通过-v标识可以将主机的目录挂载到容器中去 上面的命令将本机的$PWD&#x2F;html目录挂载到容器的&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html目录。$PWD在是一个系统环境变量，指代当前目录环境。这个功能在进行测试的时候十分方便,比如用户可以放置一些程序到本地目录中,来查看容器是否正常工作。本地目录的路径必须是绝对路径,如果目录不存在 Docker 会自动为你创建它。ps.Dockerfile中不支持这种语法. docker挂载数据卷的默认权限是读写，当然我们可以通过指令:ro指定为只读。 在我的本机主机的$PWD&#x2F;html中有一个index.html文件，内容如下： 本机下对其修改，通过8080端口访问可以直接观察到。 文件作为数据卷我们也可以使用-v指令从主机挂载单个文件到容器中去 当修改本机$PWD&#x2F;html&#x2F;index.html时,容器中的&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;index.html也会随之变化。效果和上面相同，在这里就不做赘述了。 ps.如果直接挂载一个文件,很多文件编辑工具,包括 vi 或者 sed –in-place ,可能会造成文件 inode的改变,从 Docker 1.1 .0起,这会导致报错误信息。所以最简单的办法就直接挂载文件的父目录。 数据共享如果想要实现容器间的数据共享，那么需要授权一个容器访问另一个容器的Volume。我们可以在使用docker run时使用-volumes-from参数来进行指定。 数据卷容器如果我们有一些持续更新的数据需要在容器之间共享,最好创建数据卷容器。常见的使用场景是使用纯数据容器来持久化数据库、配置文件或者数据文件等。 数据卷容器，其实就是一个正常的容器,专门用来提供数据卷供其它容器挂载的。 首先我们需要先创建一个数据卷容器 然后通过–volumes-from指令参数来挂载 dbdata 容器中的数据卷。 当然，我们也可以使用多个 –volumes-from 参数来从多个容器挂载多个数据卷。 也可以从其他已经挂载了数据卷的容器来挂载数据卷。 现在我们进入容器中查看数据卷容器是否挂载成功 说明数据卷容器挂载已经成功了。 ps.如果删除了挂载的容器(包括 dbdata、db1 和 db2等),数据卷并不会被自动删除。如果要删除一个数据卷,必须在删除最后一个还挂载着它的容器时使用 docker rm -v 命令来指定同时删除关联的容器。 备份和恢复我们可以利用数据卷对其中的数据进行进行备份、恢复和迁移。首先使用 –volumes-from 标记来创建一个加载 dbdata 容器卷的容器,并从本地主机挂载当前到容器的 &#x2F;backup 目录。命令如下: 容器启动后,使用了 tar 命令来将 dbdata 卷备份为本地的 &#x2F;backup&#x2F;backup.tar 。 如果要恢复数据到一个容器,首先创建一个带有数据卷的容器 dbdata2。 然后创建另一个容器,挂载 dbdata2 的容器,并使用 untar 解压备份文件到挂载的容器卷中。 转载自："},{"title":"Docker-网络","date":"2019-04-04T02:16:43.000Z","url":"/2019/04/04/Docker-Network/","tags":[["Docker","/tags/Docker/"]],"categories":[["虚拟化","/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"]],"content":" 网络基础Docker网络命令docker network命令是配置和管理容器网络的主要命令 命令输出显示如何使用该命令以及所有docker network子命令。从输出中可以看出，该命令允许创建新网络，列出现有网络，检查网络和删除网络。它还允许从网络连接和断开容器。 列出网络运行docker network ls命令以查看当前Docker主机上的现有容器网络。 上面的输出显示了作为Docker标准安装的一部分创建的容器网络。你创建的新网络也将显示在docker network ls命令的输出中。 你可以看到，每一个网络获得一个唯一的ID和NAME。每个网络还与单个驱动程序相关联。请注意，“网桥”网络和“主机”网络与其各自的驱动程序具有相同的名称。 检查网络该docker network inspect命令用于查看网络配置详细信息。这些细节包括; 名称，ID，驱动程序，IPAM驱动程序，子网信息，连接容器等。 在docker host 中使用docker network inspect 去查看容器的网络配置的详细信息。以下命令显示了所调用网络bridge的详细信息。 ps.该docker network inspect命令的语法是docker network inspect ，其中可以是网络名称或网络ID。在上面的示例中，我们显示了名为“bridge”的网络的配置详细信息。不要将它与“桥”驱动程序混淆。 列出网络驱动程序插件该docker info命令显示了许多有关Docker安装的有趣信息。运行该docker info命令并找到网络插件列表。 桥接网络###基础知识每个纯净安装的docker都带有一个bridge预构建网络，可以使用docker network ls 命令查看 上面的输出显示桥接网络与桥接驱动程序相关联。重要的是要注意网络和驱动程序是连接的，但它们并不相同。在这个例子中，网络和驱动程序具有相同的名称 - 但它们不是一回事！ 上面的输出还显示桥接网络是本地范围的。这意味着网络仅存在于此Docker主机上。所有使用网桥驱动程序的网络都是如此- 网桥驱动程序提供单主机网络。 使用网桥驱动程序创建的所有网络都基于Linux网桥（也称为虚拟交换机）。Linux虚拟网桥的特点: 可以设置IP地址 相当于拥有一个隐藏的虚拟网卡 docker0的地址划分: IP:172.17.42.1 子网掩码: 255.255.0.0 MAC: 02:42:ac:11:00:00 到 02:42:ac:11:ff:ff 总共提供65534个地址 docker守护进程在一个容器启动时，实际上它要创建网络连接的两端。一端是在容器中的网络设备，而另一端是在运行docker守护进程的主机上打开一个名为veth*的一个接口，用来实现docker这个网桥与容器的网络通信。 安装brctl并使用它来列出Docker主机上的Linux桥接器。centos使用yum install bridge-utils -y安装，debian系可以使用apt-get。 列出Docker主机上的网桥 上面的输出显示了一个名为docker0的 Linux桥。这是为桥（bridge）是自动创建的网桥（bridge network） 你还可以使用该ip a命令查看docker0网桥的详细信息。 运行一个docker容器，在容器中查看它的网络设备(如果没有ifconfig命令，通过apt-get install -y net-tools) docker已经自动创建了eth0的网卡，注意观察ip地址和mac地址。不要退出容器，再运行如下查看网桥的状态 我们看到在interface中多了一个veth*的这样一个接口。通过ifconfig命令同样可以看到这个网络接口。自定义docker0修改docker0默认分配的ip地址: 修改完后，重启docker服务 sudo service docker restart. 新运行的容器地址就变成了新的ip地址了。 添加虚拟网桥 更改docker守护进程的启动配置: vim &#x2F;etc&#x2F;default&#x2F;docker 中添加 DOCKER_OPS的值 -b&#x3D;br0.重启docker服务即可。 连接容器新容器的默认网络是网桥，这意味着除非你指定其他网络，否则所有新容器都将连接到网桥。 通过运行docker run -dt ubuntu sleep infinity创建一个新容器。 此命令将基于ubuntu:latest映像创建一个新容器，并将运行该sleep命令以使容器在后台运行。你可以通过运行docker ps验证我们的示例容器已启动。 由于未在docker run命令中指定网络，因此容器将添加到网桥网络中。 再次运行brctl show命令。请注意docker0网桥现在如何连接接口。此接口将docker0桥连接到刚刚创建的新容器。 通过运行docker network inspect bridge再次检查桥接网络，以查看连接到它的新容器。 测试网络连接上一个docker network inspect命令的输出显示新容器的IP地址。在前面的例子中它是“172.17.0.2”，但你的可能会有所不同。 在Docker主机的shell提示符中运行ping -c5 ，ping容器的IP地址。 面的回复表明Docker主机可以通过桥接网络ping容器。但是，我们也可以验证容器是否也可以连接到外部世界。让我们登录容器，安装ping程序，然后ping www.github.com。 首先，我们需要获取上一步中启动的容器的ID。你可以使用docker ps查找。 接下来，让我们通过运行在该ubuntu容器中运行一个shell 接下来，我们需要安装ping程序。 ping www.github.com 最后，让我们通过运行exit来断开我们的shell与容器的连接。 我们也应该停止这个容器，可以通过运行docker stop 来清理这个测试。 这表明新容器可以ping互联网，因此具有有效且可正常工作的网络配置。ps.使用阿里云的服务器实验记得打开安全组哦 为外部连接配置NAT在此步骤中，我们将启动一个新的NGINX容器，并将Docker主机上的端口8080映射到容器内的端口80。这意味着在端口8080上访问Docker主机的流量将传递到容器内的端口80。ps.如果从官方NGINX映像启动新容器而未指定要运行的命令，则容器将在端口80上运行基本Web服务器。 通过运行启动基于官方NGINX映像的新容器 通过运行docker ps查看容器状态和端口映射。 现在容器正在运行并映射到主机接口上的端口，你可以测试与NGINX Web服务器的连接。只需将Web浏览器指向Docker主机的IP和端口8080即可。此外，如果你尝试在不同的端口号上连接到相同的IP地址，它将失败。 如果由于某种原因你无法从Web浏览器打开会话，则可以使用该curl 127.0.0.1:8080命令从Docker主机进行连接。 覆盖网络该步涉及到Swarm的知识点，以后有机会再补上 转载自："},{"title":"Docker-Linux内核功能","date":"2019-04-04T01:26:43.000Z","url":"/2019/04/04/Docker-LinuxKernel/","tags":[["Docker","/tags/Docker/"]],"categories":[["虚拟化","/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"]],"content":"Linux内核能够将root用户的权限分解为称为功能的不同单元。例如，CAP_CHOWN功能允许root用户对文件UID和GID进行任意更改。CAP_DAC_OVERRIDE功能允许root用户绕过文件读取，写入和执行操作的内核权限检查。几乎所有与Linux root用户相关的特殊功能都被分解为单独的功能。 将root权限功能分解优点： 从root用户帐户中删除单个功能，使其不那么强大&#x2F;危险。 在非常精细的级别为非root用户添加权限。 功能适用于文件和线程。文件功能允许用户执行具有更高权限的程序。功能适用于文件和线程。文件功能允许用户执行具有更高权限的程序。Linux内核允许你设置功能边界集，对文件&#x2F;线程可以获得的功能施加限制。 在没有基于文件的功能的环境中，应用程序无法将其权限升级到超出边界集（超出其功能无法增长的集合）。Docker 在启动容器之前设置边界集。您可以使用Docker命令在边界集中添加或删除功能。 默认情况下，Docker 使用白名单方法删除除所需功能之外的所有功能。 Docker管理功能从Docker 1.12开始，您有3个高级选项可供使用： 使用大量功能以root身份运行容器，并尝试手动管理容器中的功能。 以有限的功能以root身份运行容器，并且永远不会在容器中更改它们。 以无权限的用户身份运行容器。 选项2是Docker 1.12中最现实的。选项3将是理想的但不现实。应尽可能避免备选方案1。ps.可以在Docker的未来版本中添加另一个选项，允许你以具有附加功能的非root用户身份运行容器。执行此操作的正确方法需要环境功能，该功能已添加到版本4.3中的Linux内核中。Docker是否有可能在较旧的内核中近似这种行为需要更多的研究。 在以下命令中，$CAP将用于指示一个或多个单独的功能。我们将在下一节中对它们进行测试。1.从root容器帐户中删除功能。 2.向root容器帐户添加功能。 3.删除所有功能，然后将单个功能明确添加到root容器帐户。 “CAP_”为Linux内核使用所有功能常量添加前缀。例如，CAP_CHOWN，CAP_NET_ADMIN，CAP_SETUID，CAP_SYSADMIN等.Docker功能常量不以“CAP_”为前缀，而是匹配内核的常量。 有关功能的更多信息（包括完整列表），请参阅功能手册 Docker测试动各种新容器，使用上一步中学习的命令来调整与用于运行容器的帐户相关联的功能。 1.启动一个新容器并证明容器的root帐户可以更改文件的所有权。 该命令不提供表示操作成功的返回码。该命令有效，因为默认行为是使用root用户启动新容器。此root用户默认具有CAP_CHOWN功能。 2.启动另一个新容器并删除除CAP_CHOWN功能之外的容器root帐户的所有功能。请记住，在寻址功能常量时，Docker不使用“CAP_”前缀。 此命令也不提供返回代码，表示运行成功。操作成功，虽然删除了容器root帐户的所有功能，但又添加了该chown功能。该chown功能是更改文件所有权所需的全部功能。 3.启动另一个新容器，从该root帐户中删除CHOWN功能。 这次该命令返回一个错误代码，表明它失败了。这是因为容器的root帐户没有该CHOWN功能，因此无法更改文件或目录的所有权。 4.创建另一个新容器，并尝试将该CHOWN功能添加到被调用的非root用户nobody。作为同一命令的一部分，尝试并更改文件或文件夹的所有权。 上述命令失败，因为Docker尚不支持向非root用户添加功能。 在此步骤中，你已为一系列新容器添加和删除了功能。可以看到，可以在非常精细的级别上从容器的root用户添加和删除功能。了解到Docker目前不支持向非root用户添加功能。 另外其余部分涉及处理Linux she’ll功能，以后再添加，有兴趣的可以看原文 转载自："},{"title":"Docker-安全性","date":"2019-04-03T00:22:52.000Z","url":"/2019/04/03/Docker-Security/","tags":[["Docker","/tags/Docker/"]],"categories":[["虚拟化","/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"]],"content":"实验环境：Seccompseccomp是Linux内核中的沙盒工具，其作用类似于系统调用的防火墙（系统调用）。它使用Berkeley Packet Filter（BPF）规则来过滤系统调用并控制它们的处理方式。这些过滤器可以显著限制容器访问Docker Host的Linux内核 - 特别是对于简单的容器&#x2F;应用程序。 先决条件只有在使用 seccomp 构建 Docker 并且内核配置了 CONFIG_SECCOMP 的情况下，此功能才可用。要检查你的内核是否支持 seccomp： 为容器传递配置文件默认的 seccomp 配置文件为使用 seccomp 运行容器提供了一个合理的设置，并禁用了大约 44 个超过 300+ 的系统调用。它具有适度的保护性，同时提供广泛的应用兼容性。默认的 Docker 配置文件可以在 这里 找到 该配置文件是白名单，默认情况下阻止访问所有的系统调用，然后将特定的系统调用列入白名单。 seccomp 有助于以最小权限运行 Docker 容器。不建议更改默认的 seccomp 配置文件，但你可以通过将–security-opt标志传递给docker run命令来覆盖它 以下示例命令基于Alpine映像启动交互式容器并启动shell进程。它还应用了描述的seccomp配置文件.json Docker支持许多与安全相关的技术。其他安全相关技术可能会干扰对seccomp配置文件的测试。因此，测试seccomp配置文件效果的最佳方法是添加所有功能并禁用apparmor（一个高效和易于使用的Linux系统安全应用程序）。 以下docker run命令添加所有功能并禁用apparmor的参数 : –cap-add ALL –security-opt apparmor&#x3D;unconfined. 克隆实验室GitHub repoclone 实验室的GitHub仓库，以便你拥有将用于本实验其余部分的seccomp配置文件 切换到labs&#x2F;security&#x2F;seccomp目录 再次目录中，docker run在整个实验中引用各种命令的seccomp配置文件 测试seccomp配置文件此步骤中，将使用seccomp-profiles&#x2F;deny.json包含的seccomp配置文件。此配置文件具有空的系统调用白名单，这意味着将阻止所有系统调用。作为演示的一部分，将添加所有功能并有效地禁用apparmor，以便你知道只有你的seccomp配置文件阻止了系统调用。 使用该docker run命令尝试启动一个新容器，其中添加了所有功能，apparmor unconfined，并应用了seccomp-profiles&#x2F;deny.jsonseccomp配置文件。 在这种情况下，Docker实际上没有足够的系统调用来启动容器！ 有选择地删除系统调用在此步骤中，你将看到如何对default.json配置文件应用更改是一种很好的方法，可以微调容器可用的系统调用。对default.json概要文件的修改，其中chmod（）、fchmod（）和chmodat（）系统调用从其白名单中删除，得到default-no-chmod.json。 使用default-no-chmod.json配置文件启动新容器并尝试运行该chmod 777 &#x2F; -v命令 然后从容器内部： 因为chmod 777 &#x2F; -v命令使用了一些chmod()，fchmod()和chmodat()已经从的白名单中删除的系统调用所以失败。 退出容器，使用default.json配置文件启动另一个新容器并运行相同的容器chmod 777 &#x2F; -v该命令成功 检查两个配置文件的存在chmod()，fchmod()以及chmodat()系统调用 编写seccomp配置文件可以从头开始编写Docker seccomp配置文件，也可以编辑现有配置文件。默认的Docker seccomp配置文件的布局如下所示： 其中name是系统调用的名称，action是发生系统调用时seccomp的操作，args是系统调用的参数限制条件。 seccomp profile包含3个部分: 默认操作(default Action) 系统调用所支持的Linux架构(architectures) 系统调用具体规则(syscalls) 在seccomp profile规则中，可定义以下5种行为来对进程的系统调用行为做出响应，更高的行动否决了较低的行动 配置文件可以包含基于系统调用参数值的更精细的过滤器。ps.这里的知识点涉及linux系统调用知识，建议跳过，有基础了再来看 index 是系统调用参数的索引 op是对参数执行的操作。参数列表： SCMP_CMP_NE - not equal SCMP_CMP_LT - less than SCMP_CMP_LE - less than or equal to SCMP_CMP_EQ - equal to SCMP_CMP_GE - greater than SCMP_CMP_GT - greater or equal to SCMP_CMP_MASKED_EQ - masked equal: true if (value &amp; arg &#x3D;&#x3D; valueTwo) value 是操作的参数 仅用于SCMP_cmp_masked_eq 如何编写Docker seccomp配置文件的最权威的来源是用于反序列化JSON的结构。 ​​366236b069e50ef26562fb24f5911d4/types/seccomp.go  参考自："},{"title":"Docker-Dockerfile命令详解","date":"2019-04-02T01:54:21.000Z","url":"/2019/04/02/Docker-Dockerfile/","tags":[["Docker","/tags/Docker/"]],"categories":[["虚拟化","/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"]],"content":"制作Dockerfile为Docker入门学习的第一步（当然，除了环境搭建） FROM功能为指定基础镜像，并且必须是第一条指令。如果不以任何镜像为基础，那么写法为：FROM scratch。同时意味着接下来所写的指令将作为镜像的第一层开始语法： FROM FROM :FROM :三种写法，其中和 是可选项，如果没有选择，那么默认值为latest FUN用于指定docker build过程中运行的程序 其可以是任何命令 但是需要基础镜像的shell环境的支持 RUN命令有两种格式 RUN RUN [“executable”, “param1”, “param2”] 第一种后边直接跟shell命令在linux操作系统上默认 &#x2F;bin&#x2F;sh -c在windows操作系统上默认 cmd &#x2F;S &#x2F;C 第二种是类似于函数调用。可将executable理解成为可执行文件，后面就是两个参数。两种写法比对： RUN &#x2F;bin&#x2F;bash -c ‘source $HOME&#x2F;.bashrc; echo $HOMERUN [“&#x2F;bin&#x2F;bash”, “-c”, “echo hello”]注意：多行命令不要写多个RUN，原因是Dockerfile中每一个指令都会建立一层. 多少个RUN就构建了多少层镜像，会造成镜像的臃肿、多层，不仅仅增加了构件部署的时间，还容易出错。RUN书写时的换行符是\\ CMDCMD指令的首要目的在于为启动的容器指定默认要运行的程序,且其运行结束后,容器也将终止. 不过CMD指定的命令其可以被docker run的命令行选项所覆盖CMD命令的执行时间周期 就是容器的生命周期 CMD一旦执行完毕 容器就会立即停止 CMD指令只有最后一个指令生效CMD指令一般不会单独使用 通常都需要配合 ENTRYPOINT指令来设置语法有三种写法 CMD [“executable”,”param1”,”param2”] CMD [“param1”,”param2”] CMD command param1 param2第三种比较好理解了，就时shell这种执行方式和写法 第一种和第二种其实都是可执行文件加上参数的形式 举例说明两种写法： CMD [ “sh”, “-c”, “echo $HOME”CMD [ “echo”, “$HOME” ]补充细节：这里边包括参数的一定要用双引号，就是”,不能是单引号。千万不能写成单引号。 原因是参数传递后，docker解析的是一个JSON array 不要把RUN和CMD搞混了。RUN是构件容器时就运行的命令以及提交运行结果CMD是容器启动时执行的命令，在构件时并不运行，构件时紧紧指定了这个命令到底是个什么样子 ENTRYPOINT主要用来指定shell的 把shell作为容器中第一个启动进程 通过接收CMD命令 把命令作为参数启动指定的子进程用来指定容器内核启动的第一个进程 只有PID为1的进程才能接收系统发送给容器的系统信号由于ENTRYPOINT启动的程序不会被docker run命 令行指定的参数所覆盖.而且,这些命令行参数会被当作参数传递给ENTRYPOINT指定指定的程序不过,docker run命令的–entrypoint选项的参数可覆盖ENTRYPOINT指令指定的程序docker run命令传入的命令参数会覆盖CMD指令的内容并且附加到 ENTRYPOINT命令最后做为其参数使用语法： ENTRYPOINT [“executable”, “param1”, “param2”]ENTRYPOINT command param1 param2 与CMD比较说明（这俩命令太像了，而且还可以配合使用）： 相同点： 只能写一条，如果写了多条，那么只有最后一条生效 容器启动时才运行，运行时机相同 不同点： ENTRYPOINT不会被运行的command覆盖，而CMD则会被覆盖 如果我们在Dockerfile种同时写了ENTRYPOINT和CMD，并且CMD指令不是一个完整的可执行命令，那么CMD指定的内容将会作为ENTRYPOINT的参数如下： FROM ubuntuENTRYPOINT [“top”, “-b”]CMD [“-c”] 如果我们在Dockerfile种同时写了ENTRYPOINT和CMD，并且CMD是一个完整的指令，那么它们两个会互相覆盖，谁在最后谁生效如下： FROM ubuntuENTRYPOINT [“top”, “-b”]CMD ls -al那么将执行ls -al ,top -b不会执行。 LABEL功能是为镜像指定标签语法： LABEL &#x3D; &#x3D; &#x3D; … 一个Dockerfile种可以有多个LABEL，如下： LABEL “com.example.vendor”&#x3D;”ACME Incorporated”LABEL com.example.label-with-value&#x3D;”foo”LABEL version&#x3D;”1.0”LABEL description&#x3D;”This text illustrates that label-values can span multiple lines.” 但是并不建议这样写，最好就写成一行，如太长需要换行的话则使用\\符号 如下： LABEL multi.label1&#x3D;”value1” multi.label2&#x3D;”value2” other&#x3D;”value3” 说明：LABEL会继承基础镜像中的LABEL，如遇到key相同，则值覆盖 MAINTAINER指定作者语法： MAINTAINER EXPOSE功能为暴漏容器运行时的监听端口给外部语法： EXPOSE [&#x2F;] [[&#x2F;] …] EXPOSE指令可一次指定多个端口 EXPOSE 11211&#x2F;udp 11211&#x2F;tcp 但是EXPOSE并不会使容器访问主机的端口如果想使得容器与主机的端口有映射关系，必须在容器启动的时候加上 -P参数 ENV指令用于为镜像定义所需的环境变量,并可被Dockerfile文件中位于其后的其它指令（如ENV、ADD、COPY等）所调用语法： ENV ENV &#x3D; … 第二种格式可用一次设置多个变量,每个变量为一个”&#x3D;“的 键值对.如果中包含空格,可以以反斜线()进行转义,也可通过对加引号进行标识.另外,反斜线也可用于续行在docker run的时候可以通过 -e 选项直接覆盖Dockerfile文件中已经指定的ENV或者添加为容器新的ENV变量的 COPY从dockerfile的工作目录中 复制指定文件到目标镜像的文件系统中语法： COPY … COPY [““,… ““]:目标路径,即正在创建的image的文件系统路径;建议为使用绝对路径 否则,COPY指定则以WORKDIR为其起始路径注意: 在路径中有空白字符时,通常使用第二种格式复制规则： src的路径不能是当前工作目录之上的目录或者文件 只能是工作目录中的文件或者子目录如果是目录,则其内部文件或子目录会被递归复制,但目录自身不会被复制 相当于shell中的 cp -r &#x2F;root&#x2F;dir&#x2F;* &#x2F;tmp如果指定了多个或在中使用了通配符 则必须是一个目录,且必须以&#x2F;结尾如果事先不存在,它将会被自动创建,这包括其父目录路径 ADDADD指令类似于COPY指令 ADD支持使用TAR文件和URL路径如果为URL且不以&#x2F;结尾,则指定的文件将被下载并直接被 创建为.如果以&#x2F;结尾,则文件名URL指定的文件将被直接下载 并保存为&#x2F; 如果是一个本地系统上的压缩格式的tar文件,它将被展开为一个目录 ,其行为类似于“tar -x”命令；然而,通过URL获取到的tar文件将不会自动 展开 如果有多个,或其间接或直接使用了通配符,则必须是一个以&#x2F;结 尾的目录路径；如果不以&#x2F;结尾,则其被视作一个普通文件,的内 容将被直接写入到语法： ADD … ADD [““,… ““] VOLUME用于在image中创建一个挂载点目录 以挂载Docker host上的卷或 其它容器上的卷语法： VOLUME VOLUME [““] 如果挂载点目录路径下此前在文件存在, docker run命令会在卷挂载完成后将此前的所有文件复制到新挂载的卷中不能指定宿主机上面的目录路径 只能创建docker manage volume USER用于指定运行image时的或运行Dockerfile中任何RUN、CMD或 ENTRYPOINT指令指定的程序时的用户名或UID默认情况下container的运行身份为root用户语法： USER daemoUSER UID 需要注意的是可以为任意数字 但实践中其必须为&#x2F;etc&#x2F;passwd中某用户的有效UID 否则docker run命令将运行失败 WORKDIR用于为Dockerfile中所有的RUN、CMD、ENTRYPOINT、COPY和 ADD指定设定工作目录语法： WORKDIR &#x2F;path&#x2F;to&#x2F;workdir 在Dockerfile文件中,WORKDIR指令可出现多次,其路径也可以为相对路径,不过 ,其是相对此前一个WORKDIR指令指定的路径另外 WORKDIR也可调用由ENV指定定义的变量 ARG语法： ARG [&#x3D;] 设置变量命令，ARG命令定义了一个变量，在docker build创建镜像的时候，使用 –build-arg &#x3D;来指定参数 如果用户在build镜像时指定了一个参数没有定义在Dockerfile中，那么将有一个Warning 提示如下： [Warning] One or more build-args [foo] were not consumed. 我们可以定义一个或多个参数，如下： FROM busyboxARG user1ARG buildno…也可以给参数一个默认值： FROM busyboxARG user1&#x3D;someuserARG buildno&#x3D;1…如果我们给了ARG定义的参数默认值，那么当build镜像时没有指定参数值，将会使用这个默认值 ONBUILD用于在Dockerfile中定义一个触发器Dockerfile用于build映像文件,此映像文件亦可作为base image被另一个Dockerfile用作FROM指令的参数,并以之构建新的映像文件在后面的这个Dockerfile中的FROM指令在build过程中被执行时,将会“触发”创建其base image的Dockerfile文件中的ONBUILD指令定义的触发器语法： ONBUILD [INSTRUCTION] 这个命令只对当前镜像的子镜像生效。比如当前镜像为A，在Dockerfile种添加：ONBUILD RUN ls -al这个 ls -al 命令不会在A镜像构建或启动的时候执行此时有一个镜像B是基于A镜像构建的，那么这个ls -al 命令会在B镜像构建的时候被执行。 HEALTHCHECK 容器健康状况检查命令docker引擎判定容器是否健康的机制是仅仅判定容器是否处于运行状态判定运行的容器是否正常运行 并不能单一的检测容器是否正在运行 需要更加具体化 需要检测容器中的主进程是否能正常提供服务才行需要借助外部命令检测 如检测nginx容器是否正常 可以使用命令请求主页 wget -O - -q a1f2903f6de3 获取返回结果 进行健康检查 语法有两种： HEALTHCHECK [OPTIONS] CMD commandHEALTHCHECK NONE 第一个的功能是在容器内部运行一个命令来检查容器的健康状况第二个的功能是在基础镜像中取消健康检查命令[OPTIONS]的选项支持以下三中选项： 注意：HEALTHCHECK命令只能出现一次，如果出现了多次，只有最后一个生效。CMD后边的命令的返回值决定了本次健康检查是否成功，具体的返回值如下： 0: success - 表示容器是健康的1: unhealthy - 表示容器已经不能工作了2: reserved - 保留值 参考自："},{"title":"支付宝集成-当面付","date":"2019-04-01T07:52:24.000Z","url":"/2019/04/01/Alipay-F2F/","tags":[["Alipay","/tags/Alipay/"]],"categories":[["第三方接口","/categories/%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8E%A5%E5%8F%A3/"]],"content":"前段时间做项目，用到AliPay的接口，手册看得很懵，东一个西一个不知道从哪开头。花了些天看了下当面付的Demo文档，总算弄明白了些AliPay接口开发的流程，这里也以当面付Demo为案例，介绍Pay的开发流程。 开发之前还需要你一些准备，如账号注册，密钥绑定等，不了解流程的可以看这里事先申明，该文只是对AliP当面付Demo进行解析，非原创。当面付的官方文档，同时也是Demo下载地址。事实上开发支付，有alipay-sdk-java.jar这个集成SDK就可以了，而Demo中的TradePaySDK是对alipay-sdk-java.jar进一步的封装，但同时也是我们可以参考的工程模板。开始入口看TradePayDemo中的Main.java也可以参考WebRoot下的JSP。 Demo结构首先，献上个人理解的工程结构图：ps.自己画的思维导图，不合理的地方还请谅解 状态类别hb包中都是用于封装交易进行时的状态常量，通常为枚举，少部分是接受支付宝端返回的参数，需要解析json数据再封装，其中的Adapter类就是为其服务的 Utils工具包，这个不用多说吧，有过项目经验的都知道 requestBuilder包的request请求类，负责将请求参数封装到其内部的BizContent中，同时提供输出json字符串的方法，它只是中间类，最终的请求还是要用alipay-sdk-java.jar中封装的request。 serviceservice包，其负责服务功能，如支付、查询、退款等。 resultresult包，对支付宝响应结果进一步封装 现在让我们走一遍支付流程 支付流程先看看官方的流程图讲道理，看能看懂，但一开始却不知道怎么和Demo联系起来，后来自己总结画了一张流程图ps.艺术水准就这样，见谅啊~ 参数入场来到TradePayDemo中的Main其static块中，初始化公共参数和实例化service main方法中提供的方法就是给我们测试的功能的，这里以支付功能为例，看看test_trade_pay(tradeService);这里需要填写一大堆的参数，即请求参数，完整的参数集看官方调试接口。这里有些是必填，如付款码，有些则可以忽略。随后将参数传入TradePaySDK的request类封装（其实也可以用alipay-sdk-java.jar提供的ModelObject类封装，更简便，有兴趣的可以到最后看我的RESTApi项目），再交由service类处理得到result。到这，只要你zfbinfo.properties中公共参数和请求参数必填项填好，你就可以运行main方法了，不出意外你的沙盒钱包被扣0.01元哦~。 业务服务现在让我们来到TradePaySDK中的service包，接口就不说了，就是定义好提供给main方法，关键是impl中的那些抽象类。 AbsAlipayService定义了支付、查询等都要用的方法，验证bizContent对象不为空，即保证参数json不为空。getResponse()则是整个工程中真正和支付宝平台交互的地方，关键语句： 相信你在查阅支付宝API在线调试时经常看到，事实上如果你只是想简单测试一下API接口，不想写一个这样的工程，一下三句就OK了 一个Client和Request发起访问，响应结果。即客户端 –&gt; 支付宝平台。都封装在alipay-sdk-java.jar AbsAlipayTradeService已经实现了接口和大部分业务流程需要的方法，相比之下感觉AlipayTradeServiceImpl有种多余的赶脚~。之后就如上面的流程图那样，tradePay()中发起支付，同步返回当然最好，但也要做好异常处理。response为null或状态吗异常则进入轮询loopQueryResult()，不断查询订单tradeQuery()，次数在zfbinfo.properties中定义。不管最后有没有查询到结果，都将返回result给main显示结果。 至此完成一次支付操作，至于其他的功能，相信大家也知道怎么开始看了吧以上纯属个人见解，如有错误欢迎指出另外自己写了SpringBoot整合版，Swagger UI可供测试，代码地址点这里"},{"title":"支付宝集成-准备工作","date":"2019-04-01T06:25:23.000Z","url":"/2019/04/01/Alipay-Prepare/","tags":[["Alipay","/tags/Alipay/"]],"categories":[["第三方接口","/categories/%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8E%A5%E5%8F%A3/"]],"content":" 注册账号&amp;创建应用集成第三方的功能(无论是集成支付宝还是微信或者其他的都是一样)的第一步一般都是要跑到其类似于开放平台的官网上进行注册账号，并创建应用，然后提交审核，来获取应用的一些配置信息，如AppId、AppSecret等。 打开蚂蚁金服开放平台()并点击最顶端最右侧的【免费入住】按钮, 然后选择【自研开发者】【开始入住】 登录成功之后会进行实名认证(一般这个时候都认证过了)、完善身份信息、签署协议，按着提示将该流程走完即可 点击 蚂蚁金服开放平台的【首页】，选择【网页&amp;移动应用列表】，选择【支付接入】，创建应用 4. 创建成功后紧接着需要完善应用的信息，如应用图表，需要接入的支付宝功能、以及一些参数配置等，配置完成后【提交审核】，然后等待审核结果关于功能列表，默认提供 APP支付、手机网站支付、当面付三种功能，如果需要其他更多功能可以通过【添加功能】添加上来，常用的功能有 电脑网站支付、APP支付宝登录、获取会员信息、单笔转账到支付宝账户等上图添加功能，三个都选或者只选当面付都行 关于开发配置应用网关：一般是项目上线对应的域名(如：), 注意在设置应用网关前会先【设置应用公钥】，关于应用公钥的生成可以通过【查看密钥生成方法】来生成，将生成后的公钥(注意是公钥公钥公钥，重要的事情说三遍，不要复制成私钥了)粘贴过来，然后保存即可 授权回调地址：是自己项目的一个能访问的url地址，当支付宝支付成功后会异步通知到这个地址上，告诉此次支付的结果是成功还是失败，配置距离() 这里我们先空着不填，后面用到再填，但应用公钥是一定要填的公钥可以使用openssl 生成，或者使用支付宝提供的一键生成工具。但需注意，支付宝要求密钥位数为2048位，在用java作为服务器端语言，对订单信息进行RSA签名的时候，私钥要求是PKCS8格式的。 在线生成非对称加密公钥私钥对： 生成后公私密钥分别保存 再将公钥输入保存 之后提交审核，通常需要一个工作日 功能签约当审核通过时，还需要签约，有些功能是需要签约，有些功能不需要签约，点击【开发者中心 &#x2F; 网页&amp;移动应用 &#x2F; 应用列表】查看详情 在签约的时候需要提供经营信息和服务接入渠道对应的信息，经营信息一般需要人事或者老板提供、服务接入渠道一般需要产品来提供，但如果我们并没有经营什么只是纯属学习设计又或者老板这些资料可能不会立马能给到你，如果签约不成功就没法测试，基于此，支付宝提供了一个【沙箱环境】。 沙箱环境所谓的沙箱环境就是支付宝帮你创建了一个临时用于开发测试的应用,称为沙箱应用，并签约了所有功能，并提供一套账号信息(包括卖家账号和买家账号)称之为沙箱账号，还提供一个沙箱支付宝安卓版的应用，可以使用沙箱账号登录沙箱应用来进行支付操作，所有的支付都是假的，你也不用担心你的钱会扣掉，因为登录的是沙箱账号而不是自己的账号，也不用担心买家的钱不够用，因为自己可以随意充值，沙箱环境用于前期的研发以及个人学习研究使用。 【发者中心 &#x2F; 研发服务 &#x2F; 沙箱环境 &#x2F; 沙箱应用】 注意：沙箱环境已经创建好了一个测试应用并签约了所有功能，但是仍然有一些信息还需自己完善，如秘钥、应用网关、授权回调地址（选看部分的RSA(SHA1)密钥、AES密钥不是必须设置的）这些参数在上面已经讲过了，将这些信息配置完成后就可以开发了 关于网关和授权回调地址必须是外网，个人开发和学习是如果没有外网，可使用natapp软件，这是一款能够免费提供外网域名，并将外网域名绑定到本机局域网IP地址的一款软件，非常适用用于调试支付宝回调，具体使用参考博客  文档中心阿里提供了非常详细的各种功能的开发文档 蚂蚁开放平台开发文档 ，从开发文档中可以看到支付方式有四种，每一种都有应用的场景 当面付条码支付：使用场景为商家使用扫码枪等条码识别设备扫描用户支付宝钱包上的付钱-条码&#x2F;二维码，完成收款。一般在超市、便利店、店铺等使用。扫码支付：使用场景为用户打开支付宝钱包中的“扫一扫”功能，扫描商家展示在某收银场景下的二维码并进行支付的模式。一般在类似于无人售货机上使用，像地铁中的无人售货饮料机、医院中的自助挂号收费机等声波支付APP支付：适用于商家在App应用中集成支付宝支付功能手机网站支付：适用于商家在移动端网页应用中集成支付宝支付功能电脑网站支付: 用户通过支付宝PC收银台完成支付，交易款项即时给到商户支付宝账户每种支付方式都提供了SDK&amp;Demo和API列表，集成时我们只需要下载Demo并熟悉好之后将Demo集成到自己的项目中即可。 参考自："},{"title":"Docker-使用","date":"2019-04-01T01:00:07.000Z","url":"/2019/04/01/Docker-Use/","tags":[["Docker","/tags/Docker/"]],"categories":[["虚拟化","/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"]],"content":" Docker 容器使用Docker 客户端docker 客户端非常简单 ,我们可以直接输入 docker 命令来查看到 Docker 客户端的所有命令选项。 运行一个web应用前面我们运行的容器并没有一些什么特别的用处。接下来让我们尝试使用 docker 构建一个 web 应用程序。我们将在docker容器中运行一个 Python Flask 应用来运行一个web应用。 ps.training&#x2F;webapp镜像若你本地没有，会自动pull官网上的参数说明: -d:让容器在后台运行。 -P:将容器内部使用的网络端口映射到我们使用的主机上。使用 docker ps 来查看我们正在运行的容器可以看到多了端口信息Docker 开放了 5000 端口（默认 Python Flask 端口）映射到主机端口 32768 上。这时我们可以通过浏览器访问WEB应用 我们也可以指定 -p 标识来绑定指定端口。 网络端口的快捷方式通过docker ps 命令可以查看到容器的端口映射，docker还提供了另一个快捷方式：docker port,使用 docker port 可以查看指定 （ID或者名字）容器的某个确定端口映射到宿主机的端口号。上面我们创建的web应用容器ID为:b570473f8bf5 名字为：cranky_brown 查看WEB应用程序日志docker logs [ID或者名字] 可以查看容器内部的标准输出。 检查WEB应用程序使用 docker inspect 来查看Docker的底层信息。它会返回一个 JSON 文件记录着 Docker 容器的配置和状态信息 停止WEB应用容器 重启WEB应用容器 docker ps -l 来查看正在运行的容器正在运行的容器，我们可以使用 docker restart 命令来重启 移除WEB应用容器我们可以使用 docker rm 命令来删除不需要的容器 删除容器时，容器必须是停止状态，否则会报如下错误 Docker 镜像使用当运行容器时，使用的镜像如果在本地中不存在，docker 就会自动从 docker 镜像仓库中下载，默认是从 Docker Hub 公共镜像源下载。 下面我们来学习： 管理和使用本地 Docker 主机镜像 创建镜像 列出镜像列表我们可以使用 docker images 来列出本地主机上的镜像各个选项说明: REPOSTITORY：表示镜像的仓库源 TAG：镜像的标签 IMAGE ID：镜像ID CREATED：镜像创建时间 SIZE：镜像大小 同一仓库源可以有多个 TAG，代表这个仓库源的不同个版本，如ubuntu仓库源里，有15.10、14.04等多个不同的版本，我们使用 REPOSTITORY:TAG 来定义不同的镜像。所以，我们如果要使用版本为15.10的ubuntu系统镜像来运行容器时，命令如下： 如果要使用版本为14.04的ubuntu系统镜像来运行容器时，命令如下： 如果你不指定一个镜像的版本标签，例如你只使用 ubuntu，docker 将默认使用 ubuntu:latest 镜像。 获取一个新的镜像我们可以从 Docker Hub 网站来搜索镜像，Docker Hub 网址为：我们也可以使用 docker search 命令来搜索镜像。比如我们需要一个httpd的镜像来作为我们的web服务。我们可以通过 docker search 命令搜索 httpd 来寻找适合我们的镜像。 NAME:镜像仓库源的名称 DESCRIPTION:镜像的描述 OFFICIAL:是否docker官方发布 我们决定使用上图中的httpd 官方版本的镜像，使用命令 docker pull 来下载镜像。 创建镜像当我们从docker镜像仓库中下载的镜像不能满足我们的需求时，我们可以通过以下两种方式对镜像进行更改。 从已经创建的容器中更新镜像，并且提交这个镜像 使用 Dockerfile 指令来创建一个新的镜像 更新镜像更新镜像之前，我们需要使用镜像来创建一个容器。 在运行的容器内使用 apt-get update 命令进行更新。在完成操作之后，输入 exit命令来退出这个容器。使用docker ps -l 查找ID此时ID为e2532447b13a的容器，是按我们的需求更改的容器。我们可以通过命令 docker commit来提交容器副本。各个参数说明： -m:提交的描述信息 -a:指定镜像作者 e2532447b13a：容器ID ubuntu:v2:指定要创建的目标镜像名 使用我们的新镜像 w3cschool&#x2F;ubuntu 来启动一个容器 这其实也是保存容器修改的方法 构建镜像我们使用命令 docker build ， 从零开始来创建一个新的镜像。为此，我们需要创建一个 Dockerfile 文件，其中包含一组指令来告诉 Docker 如何构建我们的镜像。 Dockerfile文件 每一个指令都会在镜像上创建一个新的层，每一个指令的前缀都必须是大写的。第一条FROM，指定使用哪个镜像源RUN 指令告诉docker 在镜像内执行命令，安装了什么。。。然后，我们使用 Dockerfile 文件，通过 docker build 命令来构建一个镜像。第一条FROM，指定使用哪个镜像源RUN 指令告诉docker 在镜像内执行命令，安装了什么。。。然后，我们使用 Dockerfile 文件，通过 docker build 命令来构建一个镜像。 参数说明： -t ：指定要创建的目标镜像名 . ：Dockerfile 文件所在目录，可以指定Dockerfile 的绝对路径使用docker images 查看创建的镜像已经在列表中存在,镜像ID为6b874d8f824c 设置镜像标签我们可以使用 docker tag 命令，为镜像添加一个新的标签。docker tag 镜像ID，这里是 6b874d8f824c ,用户名称、镜像源名(repository name)和新的标签名(tag)。使用 docker images 命令可以看到，ID为860c279d2fec的镜像多一个标签。 Docker 容器连接前面我们实现了通过网络端口来访问运行在docker容器内的服务。下面我们来实现通过端口连接到一个docker容器 网络端口映射我们创建了一个 python 应用的容器。 另外，我们可以指定容器绑定的网络地址，比如绑定 127.0.0.1。端口绑定的两种方式： -P :是容器内部端口随机映射到主机的高端口。 -p : 是容器内部端口绑定到指定的主机端口。 另外，我们可以指定容器绑定的网络地址，比如绑定127.0.0.1。 这样我们就可以通过访问127.0.0.1:5001来访问容器的5002端口。 上面的例子中，默认都是绑定 tcp 端口，如果要绑定 UPD 端口，可以在端口后面加上 &#x2F;udp。 docker port 命令可以让我们快捷地查看端口的绑定情况。 Docker容器连接端口映射并不是唯一把 docker 连接到另一个容器的方法。docker有一个连接系统允许将多个容器连接在一起，共享连接信息。docker连接会创建一个父子关系，其中父容器可以看到子容器的信息。 容器命名当我们创建一个容器的时候，docker会自动对它进行命名。另外，我们也可以使用–name标识来命名容器，例如： 参考自："},{"title":"Docker-Hello World","date":"2019-03-31T13:48:39.000Z","url":"/2019/03/31/Docker-start/","tags":[["Docker","/tags/Docker/"]],"categories":[["虚拟化","/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"]],"content":" 要想入门Docker，首先你需要理解Docker！Docker，可以说是一个终端命令行的虚拟机，但更准确的说法，其实应该是一个虚拟环境。比如，你想要在PC上无缝使用Linux么？那么虚拟机并不是你唯一的出路，你还有Docker！我更愿意称Docker为一个容器，当然这只是Docker的一个狭义解释，Docker不止是一个容器。Docker包含3个重要概念： 一个，是镜像（Image），镜像是静态的、可以被用户互相分享的文件。我们玩过双系统和虚拟机的人都知道，首先你需要一个.iso镜像，才能安装系统。Docker中的镜像也是这个东西，镜像是静态的，你不能对他操作，只能pull别人的镜像或者push自己的镜像。 还有一个，是容器（Container），前面说过，镜像是静态不可操作的，只能被分享和下载，那什么是能被操作的呢？就是容器里！容器可以理解为镜像的动态状态，也就是我们虚拟机中系统装好后的状态，其实这么说是不对的，容器最符合的描述应该是Linux的iso文件的Live CD模式，比如我们玩双系统时都进入过Live CD模式，不安装系统而直接进入系统，很神奇是吧，Docker的容器就是这个概念，只不过更加轻量更加迅速便捷。但是Live CD的害处就是你关机后作出的修改安装的软件全部gg，容器也是一样，一旦被直接推出，之前安装的gcc啊vim啊啥的就会全部gg掉。如果要保存修改，就需要将当前容器封装成一个新的镜像，这样下次启动这个新的镜像后之前作出的修改还都在。 最后，是仓库（Repository）。各位在前面看到我写的pull和push什么的，有没有晕？不知道各位对于git熟悉不熟悉，Docker中的仓库很像git的代码仓库，你可以pull自己之前push到自己仓库的镜像到本地，也可以pull别人push到公共仓库的镜像到自己本地。说白了就是百度云盘，你可以上传（push）自己做好环境的Docker上去，也可以下载（pull）自己云端的镜像到本地。同时，我们知道百度云最大的特点就是分享（你懂的嘿嘿嘿），类比Docker，如果你得到百度云分享链接（别人的镜像名字、标签和别人的用户名），你还可以下载（pull）别人分享的镜像到自己的本地，别人也可以下载（pull）你的镜像，因为Docker仓库都是公共的。当然，每个免费用户有一个名额把自己的一个镜像设为私有，也就是禁止被分享给别人，类比百度云上你自己保存的而没有被生成分享链接的小姐姐。 Docker的安装CentOS Docker 安装Docker支持以下的CentOS版本： CentOS 7 (64-bit) CentOS 6.5 (64-bit) 或更高的版本 前提条件目前，CentOS 仅发行版本中的内核支持 Docker。Docker 运行在 CentOS 7 上，要求系统为64位、系统内核版本为 3.10 以上。Docker 运行在 CentOS-6.5 或更高的版本的 CentOS 上，要求系统为64位、系统内核版本为 2.6.32-431 或者更高版本。 使用 yum 安装（CentOS 7下）Docker 要求 CentOS 系统的内核版本高于 3.10 ，查看本页面的前提条件来验证你的CentOS 版本是否支持 Docker 。 通过 uname -r 命令查看你当前的内核版本 安装Docker ps. 安装之前可以 yum update一下安装完成启动docker服务 测试运行hello-world ps.第一次运行，会花些时间下载hello-world镜像 Ubuntu Docker 安装前提条件Docker 要求 Ubuntu 系统的内核版本高于 3.10 ，查看本页面的前提条件来验证你的 Ubuntu 版本是否支持 Docker。 通过 uname -r 命令查看你当前的内核版本 使用脚本安装 Docker1、获取最新版本的 Docker 安装包 2、启动docker 后台服务 Docker使用Docker Hello World首先，下载容器镜像Docker官方网站专门有一个页面来存储所有可用的镜像，网址是： index.docker.io。你可以通过浏览这个网页来查找你想要使用的镜像，或者使用命令行的工具来检索。 通过docker命令下载ubuntu镜像ps.执行pull命令的时候要写完整的名字，比如”ubuntu或i386&#x2F;ubuntu” 镜像查看命令：docker images Docker 允许你在容器内运行应用程序， 使用 docker run 命令来在容器内运行一个应用程序。 各个参数解析： docker: Docker 的二进制执行文件 run:与前面的 docker 组合来运行一个容器 ubuntu指定要运行的镜像 &#x2F;bin&#x2F;echo “Hello world”: 在启动的容器里执行的命令 运行交互式的容器我们通过docker的两个参数 -i -t，让docker运行的容器实现”对话”的能力 各个参数解析： -t:在新容器内指定一个伪终端或终端 -i:允许你对容器内的标准输入 (STDIN) 进行交互 此时我们已进入一个 ubuntu15.10系统的容器我们尝试在容器中运行命令ls查看当前系统的版本信息和当前目录下的文件列表我们可以通过运行exit命令或者使用CTRL+D来退出容器 启动容器（后台模式）使用以下命令创建一个以进程方式运行的容器 在输出中，我们没有看到期望的”hello world”，而是一串长字符这个长字符串叫做容器ID，对每个容器来说都是唯一的，我们可以通过容器ID来查看对应的容器发生了什么。 首先，我们需要确认容器有在运行，可以通过 docker ps 来查看 CONTAINER ID:容器IDNAMES:自动分配的容器名称 在容器内使用docker logs命令，查看容器内的标准输出 停止容器我们使用 docker stop 命令来停止容器: 通过docker ps查看，容器已经停止工作 参考自："},{"title":"SpringBoot-Swagger2","date":"2019-03-30T13:14:28.000Z","url":"/2019/03/30/SpringBoot-Swagger2/","tags":[["SpringBoot","/tags/SpringBoot/"]],"categories":[["Spring","/categories/Spring/"]],"content":"由于Spring Boot能够快速开发、便捷部署等特性，相信有很大一部分Spring Boot的用户会用来构建RESTful API。而我们构建RESTful API的目的通常都是由于多终端的原因，这些终端会共用很多底层业务逻辑，因此我们会抽象出这样一层来同时服务于多个移动端或者Web前端。 这样一来，我们的RESTful API就有可能要面对多个开发人员或多个开发团队：IOS开发、Android开发或是Web开发等。为了减少与其他团队平时开发期间的频繁沟通成本，传统做法我们会创建一份RESTful API文档来记录所有接口细节，然而这样的做法有以下几个问题： 由于接口众多，并且细节复杂（需要考虑不同的HTTP请求类型、HTTP头部信息、HTTP请求内容等），高质量地创建这份文档本身就是件非常吃力的事，下游的抱怨声不绝于耳。 随着时间推移，不断修改接口实现的时候都必须同步修改接口文档，而文档与代码又处于两个不同的媒介，除非有严格的管理机制，不然很容易导致不一致现象。 为了解决上面这样的问题，本文将介绍RESTful API的重磅好伙伴Swagger2，它可以轻松的整合到Spring Boot中，并与Spring MVC程序配合组织出强大RESTful API文档。它既可以减少我们创建文档的工作量，同时说明内容又整合入实现代码中，让维护文档和修改代码整合为一体，可以让我们在修改代码逻辑的同时方便的修改文档说明。另外Swagger2也提供了强大的页面测试功能来调试每个RESTful API。具体效果如下图所示： 添加Swagger2依赖 创建Swagger2配置类文档结构： 在Application.java同级创建Swagger2的配置类Swagger2。 如上代码所示，通过@Configuration注解，让Spring来加载该类配置。再通过@EnableSwagger2注解来启用Swagger2。 再通过createRestApi函数创建Docket的Bean之后，apiInfo()用来创建该Api的基本信息（这些基本信息会展现在文档页面中）。select()函数返回一个ApiSelectorBuilder实例用来控制哪些接口暴露给Swagger来展现，本例采用指定扫描的包路径来定义，Swagger会扫描该包下所有Controller定义的API，并产生文档内容（除了被@ApiIgnore指定的请求）。 添加文档内容在完成了上述配置后，其实已经可以生产文档内容，但是这样的文档主要针对请求本身，而描述主要来源于函数等命名产生，对用户并不友好，我们通常需要自己增加一些说明来丰富文档内容。如下所示，我们通过@ApiOperation注解来给API增加说明、通过@ApiImplicitParams、@ApiImplicitParam注解来给参数增加说明。 ps.这里有个小坑，就是上面的api中有个几个是依据数字，如id进行访问的，格式就成这样了：value&#x3D;”&#x2F;{id}”，即&#x2F;users&#x2F;{id}，通过追加在url尾部GET上传，这样会被转换为String类型，与Controller中的Long类型冲突引发错误。故加上了paramType &#x3D; “path”参数。 完成上述代码添加上，启动Spring Boot程序，访问：。就能看到前文所展示的RESTful API的页面。我们可以再点开具体的API请求，以POST类型的&#x2F;users请求为例，可找到上述代码中我们配置的Notes信息以及参数user的描述信息，如下图所示。 API文档访问与调试在上图请求的页面中，我们看到user的Value是个输入框？是的，Swagger除了查看接口功能外，还提供了调试测试功能，我们可以点击上图中右侧的Model Schema（黄色区域：它指明了User的数据结构），此时Value中就有了user对象的模板，我们只需要稍适修改，点击下方“Try it out！”按钮，即可完成了一次请求调用！ 此时，你也可以通过几个GET请求来验证之前的POST请求是否正确。 相比为这些接口编写文档的工作，我们增加的配置内容是非常少而且精简的，对于原有代码的侵入也在忍受范围之内。因此，在构建RESTful API的同时，加入swagger来对API文档进行管理，是个不错的选择。 参考自："},{"title":"Java-BigDecimal","date":"2019-03-29T12:21:15.000Z","url":"/2019/03/29/Java-BigDecimal/","tags":[["Java","/tags/Java/"]],"categories":[["undefined",""]],"content":"BigDecimal也是看源码的时候碰到的，不是很懂，所以在网上查了下，这里转载做下笔记 原文地址： 先看下面代码 你认为你看错了，但结果却是是这样的。问题在哪里呢？原因在于我们的计算机是二进制的。浮点数没有办法是用二进制进行精确表示。我们的CPU表示浮点数由两个部分组成：指数和尾数，这样的表示方法一般都会失去一定的精确度，有些浮点数运算也会产生一定的误差。如：2.4的二进制表示并非就是精确的2.4。反而最为接近的二进制表示是 2.3999999999999999。浮点数的值实际上是由一个特定的数学公式计算得到的。 1. BigDecimal构造方法1.public BigDecimal(double val) 将double表示形式转换为BigDecimal *不建议使用 2.public BigDecimal(int val) 将int表示形式转换成BigDecimal 3.public BigDecimal(String val) 将String表示形式转换成BigDecimal 为什么不建议采用第一种构造方法呢？来看例子 JDK的描述：1、参数类型为double的构造方法的结果有一定的不可预知性。有人可能认为在Java中写入newBigDecimal(0.1)所创建的BigDecimal正好等于 0.1（非标度值 1，其标度为 1），但是它实际上等于0.1000000000000000055511151231257827021181583404541015625。这是因为0.1无法准确地表示为 double（或者说对于该情况，不能表示为任何有限长度的二进制小数）。这样，传入到构造方法的值不会正好等于 0.1（虽然表面上等于该值）。 2、另一方面，String 构造方法是完全可预知的：写入 newBigDecimal(“0.1”) 将创建一个 BigDecimal，它正好等于预期的 0.1。因此，比较而言，通常建议优先使用String构造方法。 当double必须用作BigDecimal的源时，请使用Double.toString(double)转成String，然后使用String构造方法，或使用BigDecimal的静态方法valueOf，如下 2. BigDecimal加减乘除运算对于常用的加，减，乘，除，BigDecimal类提供了相应的成员方法。 大致用法： 这里有一点需要注意的是除法运算divide. BigDecimal除法可能出现不能整除的情况，比如 4.5&#x2F;1.3，这时会报错java.lang.ArithmeticException: Non-terminating decimal expansion; no exact representable decimal result. 其实divide方法有可以传三个参数 public BigDecimal divide(BigDecimal divisor, int scale, int roundingMode)第一参数表示除数， 第二个参数表示小数点后保留位数，第三个参数表示舍入模式，只有在作除法运算或四舍五入时才用到舍入模式，有下面这几种 按照各自的需要，可传入合适的第三个参数。四舍五入采用 ROUND_HALF_UP 需要对BigDecimal进行截断和四舍五入可用setScale方法，例： 减乘除其实最终都返回的是一个新的BigDecimal对象，因为BigInteger与BigDecimal都是不可变的（immutable）的，在进行每一步运算时，都会产生一个新的对象 3. BigDecimal比较BigDecimal是通过使用compareTo(BigDecimal)来比较的，具体比较情况如下： 打印结果是：-1、0、1，即左边比右边数大，返回1，相等返回0，比右边小返回-1。注意不能使用equals方法来比较大小 4. 总结(1)商业计算使用BigDecimal。 (2)尽量使用参数类型为String的构造函数。 (3) BigDecimal都是不可变的（immutable）的，在进行每一步运算时，都会产生一个新的对象，所以在做加减乘除运算时千万要保存操作后的值。 (4)我们往往容易忽略JDK底层的一些实现细节，导致出现错误，需要多加注意。 (5)使用BigDecimal的坏处是性能比double和float差，在处理庞大，复杂的运算时尤为明显，因根据实际需求决定使用哪种类型。"},{"title":"Manacher算法","date":"2019-03-29T00:42:46.000Z","url":"/2019/03/29/Algorithm-Manacher/","tags":[["Java","/tags/Java/"]],"categories":[["数据结构与算法","/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"前几天在力扣做了一道题，查找最长回文子串，按照普通的做法是使用中心拓展算法，以每个字符作为回文子串的中心对称点，每次保存前面求得的回文子串的最大值，最后得到的就是最长回文子串，这种方式的时间复杂度是O(n^2)。这种方式的时间复杂度太高，下面介绍时间复杂度为O(n)的Manacher算法。 1. Manacher算法中的基础概念因为回文子串中心字符可以是一个或者两个，这样就存在这奇偶性的问题，处理繁琐，所以这里我们使用一个技巧，具体做法是：在字符串首尾，及各字符间各插入一个字符。 举个例子：s&#x3D;”abbahopxpo”，转换为s_new&#x3D;”#a#b#b#a#h#o#p#x#p#o#”，如此，s 里起初有一个偶回文abba和一个奇回文opxpo，被转换为#a#b#b#a#和#o#p#x#p#o#，长度都转换成了奇数。 1.1 回文半径数组radius回文半径数组radius是用来记录以每个位置的字符为回文中心求出的回文半径长度，如下图所示，对于p1所指的位置radius[6]的回文半径是5，每个位置的回文半径组成的数组就是回文数组，所以#a#c#b#b#c#b#d#s#的回文半径数组为[1, 2, 1, 2, 1, 2, 5, 2, 1, 4, 1, 2, 1, 2, 1, 2, 1]。 1.2 最右回文右边界R一个位置最右回文右边界指的是这个位置及之前的位置的回文子串，所到达的最右边的地方。比如对于字符串#a#c#b#b#c#b#d#s#，求它的每个位置的过程如下：最开始的时候R&#x3D;-1，到p&#x3D;0的位置，回文就是其本身，最右回文右边界R&#x3D;0;p&#x3D;1时，有回文串#a#，R&#x3D;2；p&#x3D;2时，R&#x3D;2;P&#x3D;3时，R&#x3D;6;p&#x3D;4时，最右回文右边界还是p&#x3D;3时的右边界，R&#x3D;6,依次类推。ps.复杂度的n即这里的右边界移动次数 1.3 最右回文右边界的对称中心C就是上面提到的最右回文右边界的中心点C，如下图，p&#x3D;4时，R&#x3D;6，C&#x3D;3 2. Manacher算法的流程首先大的方面分为两种情况：第一种情况：下一个要移动的位置在最右回文右边界R的右边比如在最开始时，R&#x3D;-1,p的下一个移动的位置为p&#x3D;0，p&#x3D;0在R&#x3D;-1的右边；p&#x3D;0时，此时的R&#x3D;0，p的下一个移动位置为p&#x3D;1，也在R&#x3D;0的右边。在这种情况下，采用普遍的解法，将移动的位置为对称中心，向两边扩，同时更新回文半径数组，最右回文右边界R和最右回文右边界的对称中心C。第二种情况：下一个要移动的位置就是最右回文右边界R或是在R的左边在这种情况下又分为三种：1、下一个要移动的位置p1在最右回文右边界R左边，且cL&lt;pLp2是p1以C为对称中心的对称点； pL是以p2为对称中心的回文子串的左边界; cL是以C为对称中心的回文子串的左边界。 这种情况下p1的回文半径就是p2的回文半径radius[p2]。2、下一个要移动的位置票p1在最右回文右边界R的左边，且cL&lt;pLp2是p1以C为对称中心的对称点； pL是以p2为对称中心的回文子串的左边界； cL是以C为对称中心的回文子串的左边界。 这种情况下p1的回文半径就是p1到R的距离R-p1+1。3、下一个要移动的位置票p1不在最右回文右边界R的左边，且cL&#x3D;pLp2是p1以C为对称中心的对称点； pL是以p2为对称中心的回文子串的左边界； cL是以C为对称中心的回文子串的左边界。 这种情况下p1的回文半径就还要继续往外扩，但是只需要从R之后往外扩就可以了，扩了之后更新R和C。 3. Manacher时间复杂度分析从上面的分析中，可以看出，第二种情况的1，2的求某个位置的回文半径的时间复杂度是O(1)，对于第一种情况和第二种情况的3，R是不断的向外扩的，不会往回退，而且寻找回文半径时，R之内的位置是不是进行判断的，所以对整个字符串而且，R的移动是从字符串的起点移动到终点，时间复杂度是O(n),所以整个manacher的时间复杂度是O(n)。 4. 代码实现 以上代码通过力扣测试 参考自："},{"title":"Spring MVC 配置类 WebMvcConfigurerAdapter","date":"2019-03-28T11:50:39.000Z","url":"/2019/03/28/spring-WebMvcConfigurerAdapter/","tags":[["SpringBoot","/tags/SpringBoot/"]],"categories":[["Spring","/categories/Spring/"]],"content":"WebMvcConfigurerAdapter配置类是spring提供的一种配置方式，采用JavaBean的方式替代传统的基于xml的配置来对spring框架进行自定义的配置。因此，在spring boot提倡的基于注解的配置，采用“约定大于配置”的风格下，当需要进行自定义的配置时，便可以继承WebMvcConfigurerAdapter这个抽象类，通过JavaBean来实现需要的配置。 1. WebMvcConfigurerAdapter常用的方法1.1 addInterceptors：拦截器在之前Xml配置形式天下的时候，我们都是在spring-mvc.xml配置文件内添加mvc:interceptor\\标签配置拦截器。 InterceptorRegistry内的addInterceptor需要一个实现HandlerInterceptor接口的拦截器实例，addPathPatterns方法用于设置拦截器的过滤路径规则。 1.2 addCorsMappings：跨域CORS（Cross-Origin Resource Sharing）”跨域资源共享”，是一个W3C标准，它允许浏览器向跨域服务器发送Ajax请求，打破了Ajax只能访问本站内的资源限制，CORS在很多地方都有被使用，微信支付的JS支付就是通过JS向微信服务器发送跨域请求。开放Ajax访问可被跨域访问的服务器大大减少了后台开发的工作，前后台工作也可以得到很好的明确以及分工 同样是在上面的webConfig中重写 1.3 addViewControllers：跳转指定页面这一个配置在之前是经常被使用到的，最经常用到的就是”&#x2F;“、”&#x2F;index”路径请求时不通过@RequestMapping配置，而是直接通过配置文件映射指定请求路径到指定View页面，当然也是在请求目标页面时不需要做什么数据处理才可以这样使用，配置内容如下所示： 1.4 resourceViewResolver：视图解析器这个对我们来说很熟悉，只要我们配置html、Jsp页面视图时就会用到WebMvcConfigurerAdapte里InternalResourceViewResolver配置类（内部类），然后设置preffix、suffix参数进行配置视图文件路径前缀与后缀。这个我们以前经常在xml文件中配置 上述代码中方法resourceViewResolver上配置了@Bean注解，该注解会将方法返回值加入到SpringIoc容器内。而在configureViewResolvers方法内配置视图映射为resourceViewResolver方法返回的InternalResourceViewResolver实例，这样完成了视图的配置。在下面还有注释掉的一部分代码，这块代码很神奇，我们先来看看org.springframework.web.servlet.config.annotation.ViewResolverRegistry源码： 可以看到上述源码中有两个jsp方法，而没有参数的方法恰恰跟我们配置的内容一样，这一点看来是Spring早就根据用户使用习惯添加的默认配置，同样也提供了自定义配置Jsp相关的前缀、后缀内容的方法，方法内部同样是实例化了一个InternalResourceViewResolver视图映射类，并将实例添加到了viewResolvers集合内。 1.5 configureMessageConverters：信息转换器这个配置一般针对于Api接口服务程序，配置在请求返回时内容采用什么转换器进行转换，我们最常用到的就是fastJson的转换，配置如下所示： 内容转换都是针对面向接口进行编写的实现类，都必须implements HttpMessageConverter接口完成方法的实现。有关HttpMessageConverter接口的讲解可以看这里 1.6 addFormatters当请求的参数中带有日期的参数的时候，可以在此配置formatter使得接收到日期参数格式统一。 1.7 addResourceHandlers：静态资源 2. WebMvcConfigurerAdapter使用方式2.1 过时方式：继承WebMvcConfigurerAdapterSpring 5.0 以后WebMvcConfigurerAdapter会取消掉WebMvcConfigurerAdapter是实现WebMvcConfigurer接口 2.2 实现WebMvcConfigurer 2.3 直接继承WebMvcConfigurationSupport 建议后两种 参考自："},{"title":"Hexo博客多台电脑设备同步管理","date":"2019-03-25T13:02:33.000Z","url":"/2019/03/25/HexoSynchronize/","tags":[["Hexo","/tags/Hexo/"]],"categories":[["Web","/categories/Web/"]],"content":"最近一直在折腾Hexo博客, 玩的可谓是不亦乐乎啊，但也遇到了些问题我想在不同的终端进行github+Hexo的博客发布更新该如何进行呢，在Google中搜了一些教程，并自身进行了简化与实践！主体的思路是将博文内容相关文件放在Github项目中master中，将Hexo配置写博客用的相关文件放在Github项目的hexo分支上，这个是关键，多终端的同步只需要对分支hexo进行操作。下面是详细的步骤讲解： 首先，你得有个Hexo博客，没搭的看这里， 使用Hexo+Github搭建免费个人网站 1. Hexo 本地文件同步将Github+Hexo搭建自己的博客时安装的配置文件push到github的username.githun.io的hexo分支上 提交时考虑以下注意事项 将themes目录以内中的主题的.git目录删除（如果有），因为一个git仓库中不能包含另一个git仓库，否则提交主题文件夹会失败 后期需要更新主题时在另一个地方git clone下来该主题的最新版本，然后将内容拷到当前主题目录即可 这样你的github项目中就会多出一个Hexo分支，这个就是用于多终端同步关键的部分。 2. 另一终端完成clone和push更新开始之前需要确保该设备安装好了npm、node、hexo，不记得的可以回顾下：使用Hexo+Github搭建免费个人网站 此时在另一终端更新博客，只需要将Github的hexo分支clone下来，进行初次的相关配置 3. 同步之后至此同步设置就完成了，以后每次写博客记得先和线上的仓库同步hexo，做完自己的时候，再记得提交同步 "},{"title":"并发编程：不变约束","date":"2019-03-20T15:10:59.000Z","url":"/2019/03/20/Concurrent-invariant/","tags":[["Java","/tags/Java/"]],"categories":[["并发编程","/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"]],"content":"最近看《JAVA并发编程实践》时，看到一个名词不是很理解，网上也查了很久，今天总算弄清楚了，这里记录一下 书中原文：维护类的线程安全性以为着要确保在并发访问的情况下，保护它的不变约束；这需要对其状态进行判断。对象与变量拥有一个状态空间(state space):即他们可能处于的状态范围。如果一个操作的过程中可能出现非法状态转换，则该操作必须是原子。一个类的不变约束也可以约束多个状态变量。不理解对象的不变约束和后验条件，你就不能保证线程安全性。要约束状态变量的有效值后者状态转换，就需要原子性与封装性。 哇，最后一句好可怕哦，不理解都不行啊首先要说下，不变约束也可以称为不变式，表达了对状态的约束，这些状态是应该始终监视的值的组合。不变式可以代表某种业务规则。首先应知道，对象的状态（不管是大是小甚至是整个系统都可看做是对象）是由其属性值组合体现的（某些属性的存在可能并不影响状态），并不是所有的属性组合都是合法的不变式，比如 定义一个员工的工资属性： duoble salary; 但工资总不可能是负的吧，那还干个屁活儿啊，所以不变式的意义就在于将这些组成状态的值，约束在一个合法的范围内。而其实现的可以考虑用before&#x2F;after 模式，你可能听说过操作的前置条件和后置条件：就是说欲执行此操作必须满足一个条件，操作执行完后还须检查另一个条件，以便确保不会把对象置于不合法的状态，用后置条件加上回滚机制可以实现rollback语义。通过在类的每个公共方法的入口和出口处同时对不变约束进行检查可以动态地检查程序是否遵从了计算的不变约束。同时不变式还指出属性间的某种必要的联系。 参考："},{"title":"SpringBoot：开始你的第一个SpringBoot应用","date":"2019-03-19T14:49:26.000Z","url":"/2019/03/19/DevlopingSpringBootApp/","tags":[["SpringBoot","/tags/SpringBoot/"]],"categories":[["Spring","/categories/Spring/"]],"content":" 依赖在开始之前，要确定你的电脑是否安装Java和maven（若是使用IDE如eclipse，可直接使用IDE自带的）。安装这里不叙述，终端输入一下命令验证： ps.maven由于GWF缘故连接外网下载jar包会很慢，建议将源地址替换为阿里镜像找到找到 apache-maven-3.5.2\\conf 目录中的 settings.xml 文件找到** &lt;&#x2F; mirrors&gt;**标签，在标签内添加内容如下： 纯命令行式最原始的方法1.创建一份pom.xml文件 终端输入以下（默认继承parent starter构件）： 个人建议保存一份模板，每次创建时cp就行可以终端运行（但其实没必要，因为你还没开始编辑你的Java代码） 就会自动导入依赖包（导入过程你可以无视“jar will be empty - no content was marked for inclusion!” 警告）。导入成功并自动生成maven和target文件夹 2.添加类路径依赖 该命令打印树型结构工程依赖然后我们在pom.xml中添加 再使用mvn denpendency:tree，你可以看到跟多的依赖，如tomcat web server 3.写代码接下来我们创建Java文件 4.运行Example终端使用： 在浏览器访问 localhost:8080，可以看到 Hello World！按Ctrl+c退出5.创建可执行jar包含所有依赖和你编辑的类，相当于一个硬盘免安装软件。我们需要先在pom.xml中添加spring-boot-maven-plugin 终端使用 target文件夹中会出现myproject-0.0.1-SNAPSHOT.jar和myproject-0.0.1-SNAPSHOT.jar.original（它是Maven在SpringBoot重新打包之前创建的原始JAR文件）现在我们运行这个应用 像之前一样浏览器访问，退出Ctrl+C eclipse创建SpringBoot项目替换maven源我们先自己创建一份setting.xml: 再在eclipse中Eclipse - &gt; [ Windows ] - &gt; [ Preferences ]- &gt; [ Maven ] - &gt; [ User Settings ]替换为我们创建的setting.xml文件之后重启eclipse即可 方法一 安装STS插件 安装插件导向窗口完成后，在eclipse右下角将会出现安装插件的进度，等插件安装完成后重启eclipse生效新建springboot项目项目启动 方法二1.创建Maven项目2.选择项目类型这里勾选了Create project…，也可以不够只是更方便，省去之后创建resources文件夹3.编写项目组和名称即可，Packaging选jar或war都可以4.修改pom.xml文件 ps.在导入spring-boot-starter-parent出现这种情况：可鼠标右键点击工程[Maven] -&gt; [Update Project]取消Offline，勾选Force Update of Snapshots&#x2F;Releases，Ok编译插件 依赖，这里实验只用web 5.创建resources文件夹和application.properties文件6.写代码在src&#x2F;main&#x2F;java处创建Example.java，代码依旧是之前写的hello world之后[Run As] -&gt; [Java Aplication]运行，浏览器查看"},{"title":"常用的八种排序算法和代码实现","date":"2019-03-17T09:13:55.000Z","url":"/2019/03/17/DSAA-sort/","tags":[["Java","/tags/Java/"]],"categories":[["数据结构与算法","/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":" 直接插入排序我们经常会到这样一类排序问题：把新的数据插入到已经排好的数据列中。将第一个数和第二个数排序，然后构成一个有序序列将第三个数插入进去，构成一个新的有序序列。对第四个数、第五个数……直到最后一个数，重复第二步。 直接插入排序（Straight Insertion Sorting）的基本思想：在要排序的一组数中，假设前面(n-1) [n&gt;&#x3D;2] 个数已经是排好顺序的，现在要把第n个数插到前面的有序数中，使得这n个数也是排好顺序的。如此反复循环，直到全部排好顺序。 代码实现 希尔排序希尔排序是希尔（Donald Shell）于1959年提出的一种排序算法。希尔排序也是一种插入排序，它是简单插入排序经过改进之后的一个更高效的版本，也称为缩小增量排序，同时该算法是冲破O(n2）的第一批算法之一。它与插入排序的不同之处在于，它会优先比较距离较远的元素。希尔排序又叫缩小增量排序。 希尔排序是把记录按下表的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。 算法描述我们来看下希尔排序的基本步骤，在此我们选择增量gap&#x3D;length&#x2F;2，缩小增量继续以gap &#x3D; gap&#x2F;2的方式，这种增量选择我们可以用一个序列来表示，{n&#x2F;2,(n&#x2F;2)&#x2F;2…1}，称为增量序列。希尔排序的增量序列的选择与证明是个数学难题，我们选择的这个增量序列是比较常用的，也是希尔建议的增量，称为希尔增量，但其实这个增量序列不是最优的。此处我们做示例使用希尔增量。 先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述： 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk&#x3D;1；按增量序列个数k，对序列进行k 趟排序；每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 过程演示 代码实现 冒泡排序冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越大(或小)的元素会经由交换慢慢“浮”到数列的顶端。 代码实现 选择排序表现最稳定的排序算法之一，因为无论什么数据进去都是O(n2)的时间复杂度，所以用到它的时候，数据规模越小越好。唯一的好处可能就是不占用额外的内存空间了吧。理论上讲，选择排序可能也是平时排序一般人想到的最多的排序方法了吧。 选择排序(Selection-sort)是一种简单直观的排序算法。它的工作原理：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 代码实现 归并排序归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。归并排序是一种稳定的排序方法。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并。 把长度为n的输入序列分成两个长度为n&#x2F;2的子序列； 对这两个子序列分别采用归并排序； 将两个排序好的子序列合并成一个最终的排序序列。 代码实现 快速排序快速排序的基本思想：通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。 代码实现 堆排序堆排序比较难理解，下面描述转载自： 预备知识堆排序是利用堆这种数据结构而设计的一种排序算法，堆排序是一种选择排序，它的最坏，最好，平均时间复杂度均为O(nlogn)，它也是不稳定排序。首先简单了解下堆结构。 堆 堆是具有以下性质的完全二叉树：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆；或者每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆。如下图： 同时，我们对堆中的结点按层进行编号，将这种逻辑结构映射到数组中就是下面这个样子 该数组从逻辑上讲就是一个堆结构，我们用简单的公式来描述一下堆的定义就是： **大顶堆：arr[i] &gt;&#x3D; arr[2i+1] &amp;&amp; arr[i] &gt;&#x3D; arr[2i+2] ** **小顶堆：arr[i] &lt;&#x3D; arr[2i+1] &amp;&amp; arr[i] &lt;&#x3D; arr[2i+2] ** ok，了解了这些定义。接下来，我们来看看堆排序的基本思想及基本步骤： 堆排序基本思想及步骤堆排序的基本思想是：将待排序序列构造成一个大顶堆，此时，整个序列的最大值就是堆顶的根节点。将其与末尾元素进行交换，此时末尾就为最大值。然后将剩余n-1个元素重新构造成一个堆，这样会得到n个元素的次小值。如此反复执行，便能得到一个有序序列了 步骤一 构造初始堆。将给定无序序列构造成一个大顶堆（一般升序采用大顶堆，降序采用小顶堆)。1.假设给定无序序列结构如下2.此时我们从最后一个非叶子结点开始（叶结点自然不用调整，第一个非叶子结点 arr.length&#x2F;2-1&#x3D;5&#x2F;2-1&#x3D;1，也就是下面的6结点），从左至右，从下至上进行调整。3.找到第二个非叶节点4，由于[4,9,8]中9元素最大，4和9交换。4.这时，交换导致了子根[4,5,6]结构混乱，继续调整，[4,5,6]中6最大，交换4和6。此时，我们就将一个无需序列构造成了一个大顶堆。步骤二 将堆顶元素与末尾元素进行交换，使末尾元素最大。然后继续调整堆，再将堆顶元素与末尾元素交换，得到第二大元素。如此反复进行交换、重建、交换。a.将堆顶元素9和末尾元素4进行交换b.重新调整结构，使其继续满足堆定义c.再将堆顶元素8与末尾元素5进行交换，得到第二大元素8.后续过程，继续进行调整，交换，如此反复进行，最终使得整个序列有序再简单总结下堆排序的基本思路：a.将无需序列构建成一个堆，根据升序降序需求选择大顶堆或小顶堆;b.将堆顶元素与末尾元素交换，将最大元素”沉”到数组末端;c.重新调整结构，使其满足堆定义，然后继续交换堆顶元素与当前末尾元素，反复执行调整+交换步骤，直到整个序列有序 代码实现 计数排序计数排序的核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。 计数排序(Counting sort)是一种稳定的排序算法。计数排序使用一个额外的数组C，其中第i个元素是待排序数组A中值等于i的元素的个数。然后根据数组C来将A中的元素排到正确的位置。它只能对整数进行排序。 动画演示 代码实现 桶排序桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。 桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排 算法描述 人为设置一个BucketSize，作为每个桶所能放置多少个不同数值（例如当BucketSize&#x3D;&#x3D;5时，该桶可以存放｛1,2,3,4,5｝这几种数字，但是容量不限，即可以存放100个3）； 遍历输入数据，并且把数据一个一个放到对应的桶里去； 对每个不是空的桶进行排序，可以使用其它排序方法，也可以递归使用桶排序； 从不是空的桶里把排好序的数据拼接起来。 代码实现 基数排序（Radix Sort）基数排序也是非比较的排序算法，对每一位进行排序，从最低位开始排序，复杂度为O(kn),为数组长度，k为数组中的数的最大的位数； 基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。基数排序基于分别排序，分别收集，所以是稳定的。 算法描述 取得数组中的最大数，并取得位数； arr为原始数组，从最低位开始取每个位组成radix数组； 对radix进行计数排序（利用计数排序适用于小范围数的特点）； 动画演示 代码实现 基数排序 vs 计数排序 vs 桶排序这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异： 基数排序：根据键值的每位数字来分配桶 计数排序：每个桶只存储单一键值 桶排序：每个桶存储一定范围的数值 参考："},{"title":"写给自己的","date":"2019-03-17T02:28:48.000Z","url":"/2019/03/17/hope/","tags":[["鸡汤","/tags/%E9%B8%A1%E6%B1%A4/"]],"categories":[["undefined",""]],"content":" 曾经我也以为我是那个最特别的人。可惜我不是。 我自以为擅长的东西，总有人比我做得更好。我自以为与众不同的地方，其实也没什么不一样。 相比之下，我不过是一个很普通的人。可能我拼命努力下也曾有一两次比一些人做得更好，但置身于人海之中，我顶多算是一颗大一点的鹅卵石。 我很努力，但好像缺少点天赋和运气。有很多梦想，但实现起来也遥遥无期。 但我没有放弃。我慢慢也能接受我是一个普通人的事实，但我也希望自己能追求喜欢的事物，哪怕回报我的不多。 也许这世界上真的存在着那样的人。存在着我永远都追不上的人，存在着我穷尽一生都难以望其项背的人。 但即使再普通，我也希望活出一点点不一样的光芒。 我祈求有好运降临，我也渴望被命运所爱。 但如果没有，我也不会放弃。希望你也一样。 "},{"title":"设计模式之创建型模式：建造者模式","date":"2019-03-15T01:21:30.000Z","url":"/2019/03/15/Creating-BuilderPattern/","tags":[["Java","/tags/Java/"]],"categories":[["设计模式","/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"]],"content":"定义建造者模式将一个复杂对象的构建与表示分离，使得同样的构建过程可以创建不同的表示。 建造者模式主要包含四个角色：Builder：抽象建造者。它声明为创建一个Product对象的各个部件指定的抽象接口。 ConcreteBuilder：具体建造者，实现Builder抽象接口，构建和装配各个部件，定义并明确它所创建的表示，并提供一个检索产品的接口。 Director：指挥者。构建一个使用Builder接口的对象。它主要是用于创建一个复杂的对象，它主要有两个作用，一是：隔离了客户与对象的生产过程，二是：负责控制产品对象的生产过程。 Product：产品角色。表示被构造的复杂对象。ConcreteBuilder创建该产品的内部表示并定义它的装配过程，包含定义组成部件的类，包括将这些部件装配成最终产品的接口。 模型实现"},{"title":"设计模式之创建型模式：单例模式","date":"2019-03-14T02:22:30.000Z","url":"/2019/03/14/Creating-Singleton/","tags":[["Java","/tags/Java/"]],"categories":[["设计模式","/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"]],"content":"1. 特点在Java应用中，单例对象能保证在一个JVM中，该对象只有一个实例存在，且必须由单例类自己创建唯一实例，单例类必须给所有其他对象提供这一实例。这样的模式有几个好处：1）某些类创建比较频繁，对于一些大型的对象，这是一笔很大的系统开销。 2）省去了new操作符，降低了系统内存的使用频率，减轻GC压力。 3）有些类如交易所的核心交易引擎，控制着交易流程，如果该类可以创建多个的话，系统完全乱了。（比如一个军队出现了多个司令员同时指挥，肯定会乱成一团），所以只有使用单例模式，才能保证核心交易服务器独立控制整个流程。 实现方式饿汉式单例（立即加载方式） 饿汉式单例在类加载初始化时就创建好一个静态的对象供外部使用，除非系统重启，这个对象不会改变，所以本身就是线程安全的。Singleton通过将构造方法限定为private避免了类在外部被实例化，在同一个虚拟机范围内，Singleton的唯一实例只能通过getInstance()方法访问。（事实上，通过Java反射机制是能够实例化构造方法为private的类的，那基本上会使所有的Java单例实现失效。此问题在此处不做讨论，姑且闭着眼就认为反射机制不存在。） 懒汉式单例（延迟加载方式） 这里的getInstance()方法用了synchronized修饰，单例在毫无线程安全保护下，放入多线程的环境下，肯定就会出现问题了。但是，synchronized关键字锁住的是这个对象，这样的用法，在性能上会有所下降，因为每次调用getInstance()，都要对对象上锁，事实上，只有在第一次创建对象的时候需要加锁，之后就不需要了，所以，这个地方需要改进。我们改成下面这个： 只在第一次创建对象时上锁， 性能得到了保证。但还是存在线程安全问题。在Java指令操作中创建和赋值是分开的，即 single &#x3D; new Singleton()其实是两个操作，jvm并不保证执行的顺序，有可能jvm在给Singleton实例分配好内存地址后就直接将地址赋值给single，再去初始化Singleton实例。以A、B两个线程为例：故再进一步优化： 使用内部类来维护单例的实现，因为jvm内部机制保证一个类的加载过程是线程互斥的，内部类加载的同时Singleton单例就已经创建完成了。但这个方法也不是完美的，如果构造函数中抛出异常，单例将永远不能被创建 最后单例模式理解起来简单，但是具体实现起来还是有一定的难度，特别是要考虑线程安全问题，各家有个家的方法，各有优缺，就看实际情况来取舍了。 学习参考： "},{"title":"读懂UML类图","date":"2019-03-13T06:54:25.000Z","url":"/2019/03/13/UML/","tags":[["UML","/tags/UML/"]],"categories":[["建模语言","/categories/%E5%BB%BA%E6%A8%A1%E8%AF%AD%E8%A8%80/"]],"content":"转载自：平时阅读一些远吗分析类文章或是设计应用架构时没少与UML类图打交道。实际上，UML类图中最常用到的元素五分钟就能掌握，下面赶紧来一起认识一下它吧： 1. 类的属性的表示方式在UML类图中，类使用包含类名、属性(field) 和方法(method) 且带有分割线的矩形来表示，比如下图表示一个Employee类，它包含name,age和email这3个属性，以及modifyInfo()方法。 那么属性&#x2F;方法名称前加的加号和减号是什么意思呢？它们表示了这个属性或方法的可见性，UML类图中表示可见性的符号有三种： · + ：表示public · - ：表示private · #：表示protected（friendly也归入这类） 因此，上图中的Employee类具有3个私有属性和一个公有方法。实际上，属性的完整表示方式是这样的：可见性 名称 ：类型 [ &#x3D; 缺省值]中括号中的内容表示是可选的 2. 类的方法的表示方式上图中我们已经看到了方法的表示形式。实际上，方法的完整表示方式如下：可见性 名称(参数列表) [ ： 返回类型]同样，中括号中的内容是可选的。比如在下图的Demo类中，定义了3个方法： · public方法method1接收一个类型为Object的参数，返回值类型为void · protected方法method2无参数，返回值类型为String · private方法method3接收类型分别为int、int[]的参数，返回值类型为int 3.类与类之间关系的表示方式3.1 关联关系关联关系又可进一步分为单向关联、双向关联和自关联（1）单相关联我们可以看到，在UML类图中单向关联用一个带箭头的直线表示。上图表示每个顾客都有一个地址，这通过让Customer类持有一个类型为Address的成员变量类实现。（2）双向关联从上图中我们很容易看出，所谓的双向关联就是双方各自持有对方类型的成员变量。在UML类图中，双向关联用一个不带箭头的直线表示。上图中在Customer类中维护一个Product[]数组，表示一个顾客购买了那些产品；在Product类中维护一个Customer类型的成员变量表示这个产品被哪个顾客所购买。（3）自关联自关联在UML类图中用一个带有箭头且指向自身的直线表示。上图的意思就是Node类包含类型为Node的成员变量，也就是“自己包含自己”。 3.2 聚合关系上图中的Car类与Engine类就是聚合关系（Car类中包含一个Engine类型的成员变量）。由上图我们可以看到，UML中聚合关系用带空心菱形和箭头的直线表示。聚合关系强调是“整体”包含“部分”，但是“部分”可以脱离“整体”而单独存在。比如上图中汽车包含了发动机，而发动机脱离了汽车也能单独存在。 3.3 组合关系组合关系与聚合关系见得最大不同在于：这里的“部分”脱离了“整体”便不复存在。比如下图：显然，嘴是头的一部分且不能脱离了头而单独存在。在UML类图中，组合关系用一个带实心菱形和箭头的直线表示。 3.4 依赖关系从上图我们可以看到，Driver的drive方法只有传入了一个Car对象才能发挥作用，因此我们说Driver类依赖于Car类。在UML类图中，依赖关系用一条带有箭头的虚线表示。 3.5 继承关系继承关系对应的是extend关键字，在UML类图中用带空心三角形的直线表示，如下图所示中，Student类与Teacher类继承了Person类。 3.6 接口实现关系这种关系对应implement关键字，在UML类图中用带空心三角形的虚线表示。如下图中，Car类与Ship类都实现了Vehicle接口。到了这里，UML类图中最常见的表示方式我们就介绍完了，有了这些我们就能读懂常见的UML类图了，剩下的遇到时再查即可。"},{"title":"设计模式之创建型模式：工厂模式","date":"2019-03-13T06:12:12.000Z","url":"/2019/03/13/Creating-FactoryPattern/","tags":[["Java","/tags/Java/"]],"categories":[["设计模式","/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"]],"content":"工厂模式是我们最常用的实例化对象模式了，是用工厂方法代替new操作的一种模式。著名的Jive论坛 ,就大量使用了工厂模式，工厂模式在Java程序系统可以说是随处可见。因为工厂模式就相当于创建实例对象的new，我们经常要根据类Class生成实例对象，如A a&#x3D;new A() 工厂模式也是用来创建实例对象的，所以以后new时就要多个心眼，是否可以考虑使用工厂模式，虽然这样做，可能多做一些工作，但会给你系统带来更大的可扩展性和尽量少的修改量。 本文使用的结构图为UML，不知道的看这里，读懂UML类图 1. 简单工厂模式以买饮料为例 我们先建立一个饮料的抽象类 然后就是具体的实物这里的coffe、tea、cola 然后统一由饮料店售卖 你要哪种饮料，它就卖那种 优点1）简单工厂模式实现了对责任的分割，提供了专门的工厂类用于创建对象，实现对象的创建和对象的使用分离。2）客户不需要知道创建对象的逻辑，甚至不需要知道具体类名，只要知道对应参数即可。 缺点1）过于集中，所有的创建逻辑都在工厂类中，一旦不能正常工作，整个系统就瘫痪了，有道是鸡蛋不能都放一个篮子里。2）对产品部分来说，它是符合开闭原则的，但是工厂部分不符合，系统扩展困难，一旦添加新产品就不得不修改工厂逻辑，在产品类型较多时，有可能造成工厂逻辑过于复杂，不利于系统的扩展和维护。 2. 多工厂方法上面实现的工厂都是通过额外参数如type来确定不同产品。但传递的type出错，将不能得到正确的对象，容错率低。而多方法的工厂模式为不同产品，提供不同的生产方法具体代码我就不写了。ps.也可以将方法设置为静态，不创建实例。 普通工厂把简单工厂中具体的工厂类，划分为抽象工厂类和具体工厂类两层。简单来说，就是饮料店为统称，具体的是各大饮料的专卖店。 接下来便是要什么饮料，找什么工厂###普通工厂与简单工厂模式的区别：可以看出，普通工厂模式特点：不仅仅做出来的产品要抽象， 工厂也应该需要抽象。工厂方法使一个产品类的实例化延迟到其具体工厂子类.工厂方法的好处就是更拥抱变化。当需求变化，只需要增删相应的类，不需要修改已有的类。而简单工厂需要修改工厂类的create()方法，多方法工厂模式需要增加一个静态方法。 抽象工厂以上介绍的工厂都是单产品系的。抽象工厂是多产品系。不仅工厂抽象具体分离，产品也分离。在讲解抽象工厂模式之前，我们要讲两个概念：这回shop不单卖饮料了，还卖零食、文具等等。1）产品等级结构：即同种产品，coffee、tea、cola等，都继承自一个抽象类2）产品族：产品族是在抽象工厂模式中的。即都由一个工厂生产。 具体的快餐店 接下来的使用就看自己了 使用场景一句话总结工厂模式：方便创建 同种产品类型的 复杂参数 对象工厂模式重点就是适用于 构建同产品类型（同一个接口 基类）的不同对象时，这些对象new很复杂，需要很多的参数，而这些参数中大部分都是固定的，so，懒惰的程序员便用工厂模式封装之。（如果构建某个对象很复杂，需要很多参数，但这些参数大部分都是“不固定”的，应该使用Builder模式）为了适应程序的扩展性，拥抱变化，便衍生出了 普通工厂、抽象工厂等模式。 学习参考"},{"title":"设计模式-前言","date":"2019-03-13T05:00:14.000Z","url":"/2019/03/13/DesignPattern/","tags":[["[object Object]","/tags/object-Object/"]],"categories":[["undefined",""]],"content":"为何需要模式模式是做事的一套高效方法，是实现目标，提炼技术的方法。小白在学习编程时，通常是想到哪写到哪，好比盖房子，low点的就只有四面墙加屋顶，细心的会加窗户、门、家具等；过一会你又觉得要有个厨房，又在旁边添了个单间当厨房；用一段时间之后发现得有卫生间，然后又是旁边加盖。但这样的后续添加势必会和现有的设计有冲突，如电力线、水管、排水管的排布，要么推翻原有的，要么妥协当前的，所以你会觉得如果事先画好建筑图会更好。同理大型软件的开发，也要先设计的整体框架，设计模式（Design pattern）是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了可重用代码、让代码更容易被他人理解、保证代码可靠性。 设计模式的分类总体来说，设计模式分为三大类： 创建型模式：共物五种：工厂方法模式，抽象工厂模式，单例模式，建造者模式，原型模式。 结构型模式：共七种：适配器模式，装饰器模式，代理模式，外观模式，桥接模式，组合模式，享元模式。 行为型模式：共十一种：策略模式，模板方法模式，观察者模式，迭代子模式，责任链模式，命令模式，备忘录模式，状态模式，访问者模式，中介者模式，解释器模式。 其实还有两类：并发型模式和线程池模式。用一个图片来整体描述一下： 设计模式的六大原则总原则：开闭原则（Open Close Principle）开闭原则就是说对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，而是要扩展原有代码，实现一个热插拔的效果。所以一句话概括就是：为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类等，后面的具体设计中我们会提到这点。 1. 单一职责原则不要存在多于一个导致类变更的原因，也就是说每个类应该实现单一的职责，如若不然，就应该把类拆分。 2. 里氏替换原则（Liskov Substitution Principle）里氏代换原则(Liskov Substitution Principle LSP)面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。 LSP是继承复用的基石，只有当衍生类可以替换掉基类，软件单位的功能不受到影响时，基类才能真正被复用，而衍生类也能够在基类的基础上增加新的行为。里氏代换原则是对“开-闭”原则的补充。实现“开-闭”原则的关键步骤就是抽象化。而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。 历史替换原则中，子类对父类的方法尽量不要重写和重载。因为父类代表了定义好的结构，通过这个规范的接口与外界交互，子类不应该随便破坏它。 3. 依赖倒转原则（Dependence Inversion Principle）这个是开闭原则的基础，具体内容：面向接口编程，依赖于抽象而不依赖于具体。写代码时用到具体类时，不与具体类交互，而与具体类的上层接口交互。 4. 接口隔离原则（Interface Segregation Principle）这个原则的意思是：每个接口中不存在子类用不到却必须实现的方法，如果不然，就要将接口拆分。使用多个隔离的接口，比使用单个接口（多个接口方法集合到一个的接口）要好。 5. 迪米特法则（最少知道原则）（Demeter Principle）就是说：一个类对自己依赖的类知道的越少越好。也就是说无论被依赖的类多么复杂，都应该将逻辑封装在方法的内部，通过public方法提供给外部。这样当被依赖的类变化时，才能最小的影响该类。 最少知道原则的另一个表达方式是：只与直接的朋友通信。类之间只要有耦合关系，就叫朋友关系。耦合分为依赖、关联、聚合、组合等。我们称出现为成员变量、方法参数、方法返回值中的类为直接朋友。局部变量、临时变量则不是直接的朋友。我们要求陌生的类不要作为局部变量出现在类中。迪米特法则不希望类之间建立直接的联系。如果真的有需要建立联系，也希望能通过它的友元类来转达。因此，应用迪米特法则有可能造成的一个后果就是：系统中存在大量的中介类，这些类之所以存在完全是为了传递类之间的相互调用关系——这在一定程度上增加了系统的复杂度。 6.合成复用原则（Composite Reuse Principle）原则是尽量首先使用合成&#x2F;聚合的方式，而不是使用继承。"},{"title":"Hexo主题优化","date":"2019-03-11T01:57:15.000Z","url":"/2019/03/11/HexoThemes/","tags":[["Hexo","/tags/Hexo/"],["Themes","/tags/Themes/"],["NexT","/tags/NexT/"]],"categories":[["Web","/categories/Web/"]],"content":"1. 选择主题Hexo默认的主题为landscape，其他主题可在一下网站浏览选择我使用的是NexT，一下的教程以NexT为例 2. 安装NexT在Hexo中有两份主要的配置文件，名称都是 _config.yml。一份在站点根目录下，负责Hexo本身的配置。一份在主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。为了描述方便，在以下说明中，将前者称为 站点配置文件， 后者称为 主题配置文件 2.1 下载主题建议你使用 Git克隆最新版本 的方式，之后的更新可以通过 git pull 来快速更新， 而不用再次下载压缩包替换。在终端窗口下，定位到Hexo站点下themes目录下 这是themes目录下除了landscape，还会多一个next 2.2 启用主题与所有 Hexo 主题启用的模式一样。 当 克隆&#x2F;下载 完成后，打开 站点配置文件， 找到 theme 字段，并将其值更改为 next。 2.3 选择SchemeNexT提供了四种外观Muse - 默认 Scheme，这是 NexT 最初的版本，黑白主调，大量留白Mist - Muse 的紧凑版本，整洁有序的单栏外观Pisces - 双栏 Scheme，小家碧玉似的清新Gmini-双栏 Scheme，内容区较Pisces大 Scheme的切换通过修改 主题配置文件 用那种就把前面的#去掉 2.3 菜单栏设置编辑 主题配置文件，设定菜单内容，对应的字段是 menu。 以上为NexT默认菜单项，同样的，用哪个就去掉前面的#NexT 默认的菜单项有（标注！的项表示需要手动创建这个页面） 键值 | 设定值 | 显示文本- | - | -home | home: &#x2F; | 主页archives | archives: &#x2F;archives | 归档页categories | categories: &#x2F;categories | 分类页！tags | tags: &#x2F;tags | 标签页 !about | about: &#x2F;about | 关于页面 ！commonweal | commonweal: &#x2F;404.html | 公益 404！ 2.4 设置菜单项的显示文本在上一步中设置的菜单的名称并不直接用于界面上的展示。Hexo 在生成的时候将使用 这个名称查找对应的语言翻译，并提取显示文本。这些翻译文本放置在 NexT 主题目录下的 languages&#x2F;{language}.yml （{language} 为你所使用的语言）以简体中文为例，若你需要添加一个菜单项，比如 something。那么就需要修改简体中文对应的翻译文件 languages&#x2F;zh-Hans.yml，在 menu 字段下添加一项： 2.5 设定菜单项的图标对应的字段就在menu下，为menu_icons。将enable填入true即可 2.6 设置侧栏默认情况下，侧栏仅在文章页面（拥有目录列表）时才显示，并放置于右侧位置。 可以通过修改 主题配置文件 中的 sidebar 字段来控制侧栏的行为。侧栏的设置包括两个部分，其一是侧栏的位置， 其二是侧栏显示的时机 1.设置侧栏的位置，修改 sidebar.position 的值，支持的选项有：left - 靠左放置right - 靠右放置 2. 设置侧栏显示的时机，修改 sidebar.display 的值，支持的选项有：post - 默认行为，在文章页面（拥有目录列表）时显示always - 在所有页面中都显示hide - 在所有页面中都隐藏（可以手动展开）remove - 完全移除 2.7 设置头像编辑 主题配置文件， 修改字段 avatar， 值设置成头像的链接地址。其中，头像的链接地址可以是：互联网URI： 站点内的地址：将头像放置主题目录下的 source&#x2F;uploads&#x2F; （新建 uploads 目录若不存在）配置为：avatar: &#x2F;uploads&#x2F;avatar.png或者 放置在 source&#x2F;images&#x2F; 目录下配置为：avatar: &#x2F;images&#x2F;avatar.png个人建议图片全部放在网上，现在免费图床很多随便选个 2.8 添加背景图在 themes&#x2F;*&#x2F;source&#x2F;css&#x2F;_custom&#x2F;custom.styl 中添加如下代码： 2.9 修改字体互联网上的字体直接使用URI，自己下载的则放在 themes&#x2F;&#x2F;source&#x2F;font、在 themes&#x2F;&#x2F;source&#x2F;css&#x2F;_custom&#x2F;custom.styl 中添加如下代码： 在该文件中你可以使用css样式设定字体，但很容易与NexT或Hexo本身的css样式冲突，所以建议只在主题custom.styl申明font-family然后我们在主题 _config.yml中找到font字段 如使用互联网字体，则URI上方的enable填true，本地则填false子字段如global、heading那部分要用该字体就在family填入font-family 2.10 添加看板娘当人们浏览你的博客时，视线中出现一个跟随你鼠标转动的妹纸，能够更加吸引人们的注意力哦~ 2.10.1 安装让我们先返回站点目录 完成后，目录中会出现node_modules文件夹在站点目录下建文件夹live2d_models再在live2d_models下建文件夹下安装模型： 更多模型可以到项目github中选择将以下代码添加到主题配置文件_config.yml，修改 你喜欢的模型名字 ： 运行命令hexo clean &amp;&amp; hexo g &amp;&amp; hexo s查看 2.11 打赏最后这个嘛，读书人的事怎么能见讨呢，叫打赏就是将你的微信或支付宝收款二维码贴在每篇博客末尾首先把你的收款二维码图片放在themes&#x2F;*&#x2F;source&#x2F;images中ps.最好微信的重命名为wechatpay.png，支付宝的为alipay.png，省的等会儿改然后在 主题配置文件中找到 Reward字段子字段 reward_comment: 坚持原创技术分享，您的支持将鼓励我继续创作！（这个自己随意）下面三个付款方式，用哪个就去掉前面的#，注意路径的名称要对上啊 3. 站点设置3.1 设置语言编辑 站点配置文件， 将 language 设置成你所需要的语言。建议明确设置你所需要的语言，例如选用简体中文，配置如下： 3.2 设置作者编辑 站点配置文件，设置 author 为你的昵称。 3.2 社交链接编辑 主题配置文件，查找social字段用哪个就去掉#，修改成自己的主页网址ps. || 后面的别删，到时候相应图标显示不出的再往下可以看到social_icon字段，enable为true。如，我要显示github的icon，要与social字段内标题和||后的简写对应。"},{"title":"使用Hexo+Github搭建免费个人网站","date":"2019-03-10T08:38:07.000Z","url":"/2019/03/10/HexoWeb/","tags":[["Hexo","/tags/Hexo/"],["Node.js","/tags/Node-js/"],["Github","/tags/Github/"]],"categories":[["Web","/categories/Web/"]],"content":"1.写在前面的个人之前是使用Tomcat+VPS尝试搭博客的，但由于过于死脑筋，前后端都是自己手敲的，结果就是前端和后台都会但都不够深入，框架也只是懂个皮毛用法，别人一问就不知道说明，真是够浪费时间的。所以这次就直接用Hexo模板建博客，这篇文章则是总结下自己的搭建过程，后续也会更新一些新玩意儿。话不多说，这就让我们开始吧使用github page服务搭建博客的好处有： 2. 准备环境Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。然而安装 Hexo 前，你必须安装下列应用程序：Node.jsGit本人使用的是linux系统(退出Windows很多年了)，所以一下教程是基于Linux的，windows的朋友可以看这里 2.1 Node.jsNode.js安装包及源码下载地址为： Source code为源码是需要手动安装滴~，不建议安装源码，会有许多的问题，例如c++版本过低等，毕竟我们只是使用者，方便就好节省时间。** binaries为编译版本，解压即用，可理解为免安装硬盘版（ps.注意ARM为嵌入式版本，PC选×64）网页下载或wget命令下载皆可。 2.2 GitGit是目前世界上最先进的分布式版本控制系统（没有之一）借助它我们就可以随时随地将我们的博客文章同步到Github上或版本回退大部分的linux上都是自带了Git，这里只是简单讲下使用系统提供的包管理工具安装 安装前需确定是否安装了Git的依赖包：curl，zlib，openssl，expat，libiconv在有yum的系统（比如Fedora）： 在apt-get 的系统上（比如 Debian 体系）: 2.3 Hexo安装Hexo，在命令行运行： ps.这里建议在&#x2F;usr&#x2F;local&#x2F;node-v10.15.3-linux-x64&#x2F;bin&#x2F;目录中运行命令，之后目录中hexo文件，之后我们有许多命令要用到它，这里也用ln建立软连接 npm就是之前node.js解压包中自带的，我们通过ln建立软连接所以直接使用 至此hexo的环境就完成了 2.3.1 初始化Hexo自己选好一个存放Hexo初始化文件的文件夹，如&#x2F;home&#x2F;HexoWeb在文件夹中运行： 完成后，站点目录： hexo相关命令都在站点目录下运行OK，现在让我们启动服务器： 浏览器访问： 不出意外的话就是hexo默认主题在已启动服务器的命令行下执行快捷键Ctrl + c，即可关闭服务器ps.右下角的妹纸可不是默认主题的，后面我会交代怎样设置 3. 搭建github博客现在你的电脑已经具备本地服务器的能力了，现在我们要借助github充当我们的服务器 3.1 创建github仓库新建一个仓库，Repository name必须是username.github.io,其中username是你的用户名，顺带初始化README.md文件。仓库创建成功不会立即生效，需要过一段时间，大概10-30分钟，或者更久。之后浏览器访问就会显示README.md文件的内容。以后你网站所有的代码都放这。 3.2 绑定域名域名的购买我就不在这里提了，不过建议买国外的，国内的既要实名认证还有提交审核等个好几天。我是在dynadot购买的，.top一年5美刀~。随后进入manage domains 点击DNS Settings管理DNS添加CNAME或A解析记录CNAME类型只需填写username.github.ioA类型则需要IP，IP可通过ping username.github.io得到接着在github仓库中添加CNAME文件，其中填入域名。或者在仓库的settings中设置Custom Domain为域名，github会自动添加CNAME文件ps.这里有个问题，设置Custom Domain完成点击save后，下面的选项会有警告，这是https带来的问题下面我会解决 3.3 通过HTTPS访问域名在完成上述操作以后，只能通过HTTP协议传输(明文传输),于是在通过域名访问自己的username.github.io时，发现浏览器提示该网址不安全，没有合格的安全证书，不能通过https(密文传输)访问。 3.3.1 HTTP与HTTPSHTTP是明文传输协议，传输内容容易被嗅探和篡改。而HTTPS，即HTTP over SSL&#x2F;TLS,是添加了一层SSL(Secure Sockets Layer，安全套接层)，或者是TLS(Transport Layer Security,传输层安全协议)，所以HTTPS就可以视为HTTP和SSL&#x2F;TLS协议的组合。HTTPS能做到良好的保密性(防嗅探)，真实性(防篡改)，完整性(防域名劫持和域名欺骗)。 3.3.2 申请SSL证书SSL证书由你的NS(Name Server，域名服务商)颁发，像阿里云这样的通常是需要钱滴~，所以我们最好迁移到免费提供SSL的NS处，比如国内的DNSpod(国内都需要备案),还有国外的Netlify和Cloudflare，从速度和操作性考虑，本人选择了Cloudflare。 到Cloudflare官网注册 根据指引点击Add Site，添加你的域名，会自动开始扫描DNS解析记录 选择免费的那个计划 扫描完成后，Cloudflare会选择给我们分配两个NS地址，将这两个地址替换原NS地址，等待生效；至此就可以使用域名访问仓库了 4. 从本地到远程4.1 配置SSH key提交代码到github仓库中需要有github的权限，但直接使用账号密码则不安全，所以我们使用SSH Key来解决本地和github的连接问题 ps.第一次使用git连接的，还需要配置用户账号账号 我们先检查本机是否已存在ssh密钥 如果提示：No such file or directory 说明没有，则我们自己生成 然后连续3次回车，最终会生成一个文件在用户目录下，打开用户目录，找到.ssh\\id_rsa.pub文件，记事本打开并复制里面的内容，打开你的github主页，进入个人设置 -&gt; SSH and GPG keys -&gt; New SSH key：测试一下 第一次连接会提示 Are you sure you want to continue connecting (yes&#x2F;no)?，输入yes，成功会看到 4.1 站点配置修改_config.yml（在站点目录下）。文件末尾修改为： 注意：上面仓库地址写ssh地址，不写http地址。 推送命令： 返回INFO Deploy done: git即成功推送 等待1分钟左右，浏览器访问网址： 或域名 ​ "}]